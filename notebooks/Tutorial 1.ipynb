{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todor/miniconda3/envs/testd/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils.data_tools as data_tools\n",
    "import utils.visualisation as visualisation\n",
    "import utils.distributions as distributions\n",
    "\n",
    "from models.lstm import BasicLSTM\n",
    "from models.lstm import reset_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['../data/eth/univ',\n",
    "               '../data/ucy/zara/zara01',\n",
    "               '../data/ucy/zara/zara02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 100\n",
    "DECAY_RATE = 0.95\n",
    "SEQUENCE_LENGTH = 8\n",
    "SAVE_PATH = \"../save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentsData, dicto, dataset_indices = data_tools.preprocess(directories)\n",
    "loaded_data, num_batches = data_tools.load_preprocessed(agentsData, BATCH_SIZE, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfully reset\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "lstm = BasicLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3300 (epoch 0), train_loss = 10.991, time/batch = 0.083\n",
      "1/3300 (epoch 0), train_loss = 11.012, time/batch = 0.011\n",
      "2/3300 (epoch 0), train_loss = 10.983, time/batch = 0.011\n",
      "3/3300 (epoch 0), train_loss = 10.994, time/batch = 0.011\n",
      "4/3300 (epoch 0), train_loss = 10.964, time/batch = 0.010\n",
      "5/3300 (epoch 0), train_loss = 10.993, time/batch = 0.010\n",
      "6/3300 (epoch 0), train_loss = 10.940, time/batch = 0.009\n",
      "7/3300 (epoch 0), train_loss = 10.894, time/batch = 0.009\n",
      "8/3300 (epoch 0), train_loss = 10.876, time/batch = 0.009\n",
      "9/3300 (epoch 0), train_loss = 10.919, time/batch = 0.009\n",
      "10/3300 (epoch 0), train_loss = 10.908, time/batch = 0.013\n",
      "11/3300 (epoch 0), train_loss = 10.938, time/batch = 0.010\n",
      "12/3300 (epoch 0), train_loss = 10.872, time/batch = 0.009\n",
      "13/3300 (epoch 0), train_loss = 10.846, time/batch = 0.009\n",
      "14/3300 (epoch 0), train_loss = 10.825, time/batch = 0.008\n",
      "15/3300 (epoch 0), train_loss = 10.810, time/batch = 0.008\n",
      "16/3300 (epoch 0), train_loss = 10.769, time/batch = 0.008\n",
      "17/3300 (epoch 0), train_loss = 10.768, time/batch = 0.008\n",
      "18/3300 (epoch 0), train_loss = 10.703, time/batch = 0.008\n",
      "19/3300 (epoch 0), train_loss = 10.711, time/batch = 0.008\n",
      "20/3300 (epoch 0), train_loss = 10.598, time/batch = 0.007\n",
      "21/3300 (epoch 0), train_loss = 10.596, time/batch = 0.007\n",
      "22/3300 (epoch 0), train_loss = 10.572, time/batch = 0.007\n",
      "23/3300 (epoch 0), train_loss = 10.531, time/batch = 0.008\n",
      "24/3300 (epoch 0), train_loss = 10.553, time/batch = 0.008\n",
      "25/3300 (epoch 0), train_loss = 10.520, time/batch = 0.007\n",
      "26/3300 (epoch 0), train_loss = 10.464, time/batch = 0.006\n",
      "27/3300 (epoch 0), train_loss = 10.420, time/batch = 0.006\n",
      "28/3300 (epoch 0), train_loss = 10.368, time/batch = 0.007\n",
      "29/3300 (epoch 0), train_loss = 10.351, time/batch = 0.007\n",
      "30/3300 (epoch 0), train_loss = 10.327, time/batch = 0.007\n",
      "31/3300 (epoch 0), train_loss = 10.290, time/batch = 0.006\n",
      "32/3300 (epoch 0), train_loss = 10.208, time/batch = 0.006\n",
      "33/3300 (epoch 1), train_loss = 10.430, time/batch = 0.006\n",
      "34/3300 (epoch 1), train_loss = 10.360, time/batch = 0.007\n",
      "35/3300 (epoch 1), train_loss = 10.245, time/batch = 0.007\n",
      "36/3300 (epoch 1), train_loss = 10.177, time/batch = 0.007\n",
      "37/3300 (epoch 1), train_loss = 10.079, time/batch = 0.006\n",
      "38/3300 (epoch 1), train_loss = 10.039, time/batch = 0.007\n",
      "39/3300 (epoch 1), train_loss = 9.947, time/batch = 0.007\n",
      "40/3300 (epoch 1), train_loss = 9.812, time/batch = 0.006\n",
      "41/3300 (epoch 1), train_loss = 9.784, time/batch = 0.006\n",
      "42/3300 (epoch 1), train_loss = 9.733, time/batch = 0.007\n",
      "43/3300 (epoch 1), train_loss = 9.623, time/batch = 0.007\n",
      "44/3300 (epoch 1), train_loss = 9.531, time/batch = 0.007\n",
      "45/3300 (epoch 1), train_loss = 9.513, time/batch = 0.006\n",
      "46/3300 (epoch 1), train_loss = 9.415, time/batch = 0.009\n",
      "47/3300 (epoch 1), train_loss = 9.262, time/batch = 0.007\n",
      "48/3300 (epoch 1), train_loss = 9.128, time/batch = 0.006\n",
      "49/3300 (epoch 1), train_loss = 8.969, time/batch = 0.006\n",
      "50/3300 (epoch 1), train_loss = 8.836, time/batch = 0.007\n",
      "51/3300 (epoch 1), train_loss = 8.726, time/batch = 0.007\n",
      "52/3300 (epoch 1), train_loss = 8.567, time/batch = 0.007\n",
      "53/3300 (epoch 1), train_loss = 8.505, time/batch = 0.007\n",
      "54/3300 (epoch 1), train_loss = 8.338, time/batch = 0.006\n",
      "55/3300 (epoch 1), train_loss = 8.099, time/batch = 0.006\n",
      "56/3300 (epoch 1), train_loss = 7.752, time/batch = 0.006\n",
      "57/3300 (epoch 1), train_loss = 7.444, time/batch = 0.006\n",
      "58/3300 (epoch 1), train_loss = 7.168, time/batch = 0.006\n",
      "59/3300 (epoch 1), train_loss = 6.754, time/batch = 0.006\n",
      "60/3300 (epoch 1), train_loss = 6.384, time/batch = 0.006\n",
      "61/3300 (epoch 1), train_loss = 7.608, time/batch = 0.006\n",
      "62/3300 (epoch 1), train_loss = 6.328, time/batch = 0.006\n",
      "63/3300 (epoch 1), train_loss = 13.164, time/batch = 0.006\n",
      "64/3300 (epoch 1), train_loss = 8.832, time/batch = 0.006\n",
      "65/3300 (epoch 1), train_loss = 7.534, time/batch = 0.006\n",
      "66/3300 (epoch 2), train_loss = 8.874, time/batch = 0.006\n",
      "67/3300 (epoch 2), train_loss = 8.453, time/batch = 0.006\n",
      "68/3300 (epoch 2), train_loss = 7.909, time/batch = 0.006\n",
      "69/3300 (epoch 2), train_loss = 7.517, time/batch = 0.006\n",
      "70/3300 (epoch 2), train_loss = 7.166, time/batch = 0.006\n",
      "71/3300 (epoch 2), train_loss = 6.947, time/batch = 0.006\n",
      "72/3300 (epoch 2), train_loss = 6.632, time/batch = 0.006\n",
      "73/3300 (epoch 2), train_loss = 6.457, time/batch = 0.006\n",
      "74/3300 (epoch 2), train_loss = 7.412, time/batch = 0.006\n",
      "75/3300 (epoch 2), train_loss = 6.448, time/batch = 0.006\n",
      "76/3300 (epoch 2), train_loss = 6.122, time/batch = 0.006\n",
      "77/3300 (epoch 2), train_loss = 6.295, time/batch = 0.006\n",
      "78/3300 (epoch 2), train_loss = 5.813, time/batch = 0.006\n",
      "79/3300 (epoch 2), train_loss = 5.974, time/batch = 0.006\n",
      "80/3300 (epoch 2), train_loss = 5.677, time/batch = 0.007\n",
      "81/3300 (epoch 2), train_loss = 5.784, time/batch = 0.006\n",
      "82/3300 (epoch 2), train_loss = 5.377, time/batch = 0.007\n",
      "83/3300 (epoch 2), train_loss = 6.319, time/batch = 0.008\n",
      "84/3300 (epoch 2), train_loss = 5.325, time/batch = 0.007\n",
      "85/3300 (epoch 2), train_loss = 6.010, time/batch = 0.006\n",
      "86/3300 (epoch 2), train_loss = 5.621, time/batch = 0.006\n",
      "87/3300 (epoch 2), train_loss = 5.207, time/batch = 0.006\n",
      "88/3300 (epoch 2), train_loss = 5.365, time/batch = 0.006\n",
      "89/3300 (epoch 2), train_loss = 4.509, time/batch = 0.006\n",
      "90/3300 (epoch 2), train_loss = 3.957, time/batch = 0.007\n",
      "91/3300 (epoch 2), train_loss = 3.356, time/batch = 0.007\n",
      "92/3300 (epoch 2), train_loss = 2.657, time/batch = 0.006\n",
      "93/3300 (epoch 2), train_loss = 5.885, time/batch = 0.006\n",
      "94/3300 (epoch 2), train_loss = 2.746, time/batch = 0.006\n",
      "95/3300 (epoch 2), train_loss = 10.589, time/batch = 0.006\n",
      "96/3300 (epoch 2), train_loss = 5.924, time/batch = 0.006\n",
      "97/3300 (epoch 2), train_loss = 3.999, time/batch = 0.006\n",
      "98/3300 (epoch 2), train_loss = 2.757, time/batch = 0.006\n",
      "99/3300 (epoch 3), train_loss = 5.547, time/batch = 0.006\n",
      "100/3300 (epoch 3), train_loss = 4.640, time/batch = 0.007\n",
      "101/3300 (epoch 3), train_loss = 4.084, time/batch = 0.007\n",
      "102/3300 (epoch 3), train_loss = 4.318, time/batch = 0.006\n",
      "103/3300 (epoch 3), train_loss = 3.320, time/batch = 0.006\n",
      "104/3300 (epoch 3), train_loss = 2.951, time/batch = 0.006\n",
      "105/3300 (epoch 3), train_loss = 2.406, time/batch = 0.007\n",
      "106/3300 (epoch 3), train_loss = 2.394, time/batch = 0.008\n",
      "107/3300 (epoch 3), train_loss = 3.241, time/batch = 0.006\n",
      "108/3300 (epoch 3), train_loss = 2.474, time/batch = 0.007\n",
      "109/3300 (epoch 3), train_loss = 2.031, time/batch = 0.007\n",
      "110/3300 (epoch 3), train_loss = 1.926, time/batch = 0.006\n",
      "111/3300 (epoch 3), train_loss = 1.472, time/batch = 0.008\n",
      "112/3300 (epoch 3), train_loss = 1.600, time/batch = 0.007\n",
      "113/3300 (epoch 3), train_loss = 1.578, time/batch = 0.008\n",
      "114/3300 (epoch 3), train_loss = 1.151, time/batch = 0.007\n",
      "115/3300 (epoch 3), train_loss = 1.193, time/batch = 0.007\n",
      "116/3300 (epoch 3), train_loss = 1.067, time/batch = 0.007\n",
      "117/3300 (epoch 3), train_loss = 1.830, time/batch = 0.006\n",
      "118/3300 (epoch 3), train_loss = 0.933, time/batch = 0.006\n",
      "119/3300 (epoch 3), train_loss = 1.223, time/batch = 0.007\n",
      "120/3300 (epoch 3), train_loss = 1.107, time/batch = 0.006\n",
      "121/3300 (epoch 3), train_loss = 0.707, time/batch = 0.007\n",
      "122/3300 (epoch 3), train_loss = 0.089, time/batch = 0.006\n",
      "123/3300 (epoch 3), train_loss = 0.432, time/batch = 0.006\n",
      "124/3300 (epoch 3), train_loss = -0.027, time/batch = 0.006\n",
      "125/3300 (epoch 3), train_loss = 1.974, time/batch = 0.006\n",
      "126/3300 (epoch 3), train_loss = 0.529, time/batch = 0.007\n",
      "127/3300 (epoch 3), train_loss = -0.135, time/batch = 0.006\n",
      "128/3300 (epoch 3), train_loss = -0.250, time/batch = 0.006\n",
      "129/3300 (epoch 3), train_loss = 1.163, time/batch = 0.006\n",
      "130/3300 (epoch 3), train_loss = -0.261, time/batch = 0.006\n",
      "131/3300 (epoch 3), train_loss = -0.323, time/batch = 0.006\n",
      "132/3300 (epoch 4), train_loss = 1.870, time/batch = 0.006\n",
      "133/3300 (epoch 4), train_loss = 1.247, time/batch = 0.006\n",
      "134/3300 (epoch 4), train_loss = 0.724, time/batch = 0.007\n",
      "135/3300 (epoch 4), train_loss = -0.148, time/batch = 0.006\n",
      "136/3300 (epoch 4), train_loss = 1.066, time/batch = 0.006\n",
      "137/3300 (epoch 4), train_loss = -0.546, time/batch = 0.006\n",
      "138/3300 (epoch 4), train_loss = 0.895, time/batch = 0.006\n",
      "139/3300 (epoch 4), train_loss = -0.371, time/batch = 0.006\n",
      "140/3300 (epoch 4), train_loss = 1.881, time/batch = 0.007\n",
      "141/3300 (epoch 4), train_loss = 0.446, time/batch = 0.006\n",
      "142/3300 (epoch 4), train_loss = -0.232, time/batch = 0.006\n",
      "143/3300 (epoch 4), train_loss = -0.524, time/batch = 0.006\n",
      "144/3300 (epoch 4), train_loss = -0.666, time/batch = 0.006\n",
      "145/3300 (epoch 4), train_loss = -0.751, time/batch = 0.006\n",
      "146/3300 (epoch 4), train_loss = 0.115, time/batch = 0.006\n",
      "147/3300 (epoch 4), train_loss = 0.203, time/batch = 0.006\n",
      "148/3300 (epoch 4), train_loss = -1.036, time/batch = 0.006\n",
      "149/3300 (epoch 4), train_loss = -0.660, time/batch = 0.006\n",
      "150/3300 (epoch 4), train_loss = 1.445, time/batch = 0.009\n",
      "151/3300 (epoch 4), train_loss = -0.926, time/batch = 0.007\n",
      "152/3300 (epoch 4), train_loss = -0.270, time/batch = 0.006\n",
      "153/3300 (epoch 4), train_loss = -0.244, time/batch = 0.008\n",
      "154/3300 (epoch 4), train_loss = -0.834, time/batch = 0.007\n",
      "155/3300 (epoch 4), train_loss = -1.026, time/batch = 0.007\n",
      "156/3300 (epoch 4), train_loss = -0.773, time/batch = 0.007\n",
      "157/3300 (epoch 4), train_loss = -0.957, time/batch = 0.007\n",
      "158/3300 (epoch 4), train_loss = -0.502, time/batch = 0.011\n",
      "159/3300 (epoch 4), train_loss = -0.946, time/batch = 0.007\n",
      "160/3300 (epoch 4), train_loss = -1.741, time/batch = 0.007\n",
      "161/3300 (epoch 4), train_loss = 4.662, time/batch = 0.008\n",
      "162/3300 (epoch 4), train_loss = -1.134, time/batch = 0.006\n",
      "163/3300 (epoch 4), train_loss = 0.277, time/batch = 0.007\n",
      "164/3300 (epoch 4), train_loss = -0.380, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/3300 (epoch 5), train_loss = 1.408, time/batch = 0.009\n",
      "166/3300 (epoch 5), train_loss = 0.660, time/batch = 0.007\n",
      "167/3300 (epoch 5), train_loss = 0.138, time/batch = 0.006\n",
      "168/3300 (epoch 5), train_loss = 0.623, time/batch = 0.006\n",
      "169/3300 (epoch 5), train_loss = -0.781, time/batch = 0.008\n",
      "170/3300 (epoch 5), train_loss = -0.321, time/batch = 0.008\n",
      "171/3300 (epoch 5), train_loss = 0.569, time/batch = 0.007\n",
      "172/3300 (epoch 5), train_loss = -0.823, time/batch = 0.009\n",
      "173/3300 (epoch 5), train_loss = -0.101, time/batch = 0.006\n",
      "174/3300 (epoch 5), train_loss = -0.843, time/batch = 0.007\n",
      "175/3300 (epoch 5), train_loss = 0.991, time/batch = 0.007\n",
      "176/3300 (epoch 5), train_loss = -0.832, time/batch = 0.007\n",
      "177/3300 (epoch 5), train_loss = -1.168, time/batch = 0.008\n",
      "178/3300 (epoch 5), train_loss = -0.052, time/batch = 0.007\n",
      "179/3300 (epoch 5), train_loss = -0.862, time/batch = 0.006\n",
      "180/3300 (epoch 5), train_loss = -1.019, time/batch = 0.006\n",
      "181/3300 (epoch 5), train_loss = -1.266, time/batch = 0.006\n",
      "182/3300 (epoch 5), train_loss = 0.415, time/batch = 0.006\n",
      "183/3300 (epoch 5), train_loss = -1.390, time/batch = 0.006\n",
      "184/3300 (epoch 5), train_loss = 0.131, time/batch = 0.006\n",
      "185/3300 (epoch 5), train_loss = -1.308, time/batch = 0.006\n",
      "186/3300 (epoch 5), train_loss = 0.985, time/batch = 0.006\n",
      "187/3300 (epoch 5), train_loss = -1.124, time/batch = 0.009\n",
      "188/3300 (epoch 5), train_loss = -0.342, time/batch = 0.006\n",
      "189/3300 (epoch 5), train_loss = 1.065, time/batch = 0.006\n",
      "190/3300 (epoch 5), train_loss = -1.141, time/batch = 0.006\n",
      "191/3300 (epoch 5), train_loss = -0.596, time/batch = 0.006\n",
      "192/3300 (epoch 5), train_loss = -1.510, time/batch = 0.006\n",
      "193/3300 (epoch 5), train_loss = -1.238, time/batch = 0.006\n",
      "194/3300 (epoch 5), train_loss = -0.920, time/batch = 0.006\n",
      "195/3300 (epoch 5), train_loss = -0.791, time/batch = 0.006\n",
      "196/3300 (epoch 5), train_loss = 0.285, time/batch = 0.007\n",
      "197/3300 (epoch 5), train_loss = -1.793, time/batch = 0.006\n",
      "198/3300 (epoch 6), train_loss = 1.068, time/batch = 0.006\n",
      "199/3300 (epoch 6), train_loss = 0.107, time/batch = 0.006\n",
      "200/3300 (epoch 6), train_loss = 0.668, time/batch = 0.006\n",
      "201/3300 (epoch 6), train_loss = 0.979, time/batch = 0.006\n",
      "202/3300 (epoch 6), train_loss = -0.582, time/batch = 0.006\n",
      "203/3300 (epoch 6), train_loss = -0.275, time/batch = 0.006\n",
      "204/3300 (epoch 6), train_loss = 0.186, time/batch = 0.006\n",
      "205/3300 (epoch 6), train_loss = -1.170, time/batch = 0.006\n",
      "206/3300 (epoch 6), train_loss = -0.220, time/batch = 0.006\n",
      "207/3300 (epoch 6), train_loss = -1.073, time/batch = 0.006\n",
      "208/3300 (epoch 6), train_loss = -0.189, time/batch = 0.006\n",
      "209/3300 (epoch 6), train_loss = -0.485, time/batch = 0.006\n",
      "210/3300 (epoch 6), train_loss = -1.186, time/batch = 0.006\n",
      "211/3300 (epoch 6), train_loss = -0.372, time/batch = 0.006\n",
      "212/3300 (epoch 6), train_loss = -0.984, time/batch = 0.006\n",
      "213/3300 (epoch 6), train_loss = -0.772, time/batch = 0.006\n",
      "214/3300 (epoch 6), train_loss = -1.298, time/batch = 0.006\n",
      "215/3300 (epoch 6), train_loss = -0.645, time/batch = 0.006\n",
      "216/3300 (epoch 6), train_loss = -1.159, time/batch = 0.006\n",
      "217/3300 (epoch 6), train_loss = -0.998, time/batch = 0.006\n",
      "218/3300 (epoch 6), train_loss = -1.358, time/batch = 0.006\n",
      "219/3300 (epoch 6), train_loss = -0.569, time/batch = 0.006\n",
      "220/3300 (epoch 6), train_loss = -1.016, time/batch = 0.006\n",
      "221/3300 (epoch 6), train_loss = -0.286, time/batch = 0.006\n",
      "222/3300 (epoch 6), train_loss = -1.370, time/batch = 0.007\n",
      "223/3300 (epoch 6), train_loss = -0.464, time/batch = 0.008\n",
      "224/3300 (epoch 6), train_loss = -1.850, time/batch = 0.007\n",
      "225/3300 (epoch 6), train_loss = -1.331, time/batch = 0.006\n",
      "226/3300 (epoch 6), train_loss = -0.390, time/batch = 0.006\n",
      "227/3300 (epoch 6), train_loss = -0.791, time/batch = 0.007\n",
      "228/3300 (epoch 6), train_loss = -2.528, time/batch = 0.007\n",
      "229/3300 (epoch 6), train_loss = -0.507, time/batch = 0.006\n",
      "230/3300 (epoch 6), train_loss = -1.719, time/batch = 0.006\n",
      "231/3300 (epoch 7), train_loss = 1.120, time/batch = 0.006\n",
      "232/3300 (epoch 7), train_loss = 0.447, time/batch = 0.006\n",
      "233/3300 (epoch 7), train_loss = -0.474, time/batch = 0.006\n",
      "234/3300 (epoch 7), train_loss = -0.949, time/batch = 0.006\n",
      "235/3300 (epoch 7), train_loss = 0.222, time/batch = 0.006\n",
      "236/3300 (epoch 7), train_loss = 0.164, time/batch = 0.006\n",
      "237/3300 (epoch 7), train_loss = -0.036, time/batch = 0.006\n",
      "238/3300 (epoch 7), train_loss = -0.747, time/batch = 0.006\n",
      "239/3300 (epoch 7), train_loss = 0.663, time/batch = 0.006\n",
      "240/3300 (epoch 7), train_loss = -1.211, time/batch = 0.006\n",
      "241/3300 (epoch 7), train_loss = -0.775, time/batch = 0.006\n",
      "242/3300 (epoch 7), train_loss = -1.449, time/batch = 0.006\n",
      "243/3300 (epoch 7), train_loss = -0.144, time/batch = 0.006\n",
      "244/3300 (epoch 7), train_loss = -1.494, time/batch = 0.006\n",
      "245/3300 (epoch 7), train_loss = -0.740, time/batch = 0.006\n",
      "246/3300 (epoch 7), train_loss = -1.111, time/batch = 0.006\n",
      "247/3300 (epoch 7), train_loss = -1.077, time/batch = 0.006\n",
      "248/3300 (epoch 7), train_loss = -1.462, time/batch = 0.006\n",
      "249/3300 (epoch 7), train_loss = -0.754, time/batch = 0.006\n",
      "250/3300 (epoch 7), train_loss = -1.393, time/batch = 0.006\n",
      "251/3300 (epoch 7), train_loss = -0.886, time/batch = 0.006\n",
      "252/3300 (epoch 7), train_loss = -1.115, time/batch = 0.006\n",
      "253/3300 (epoch 7), train_loss = -0.277, time/batch = 0.006\n",
      "254/3300 (epoch 7), train_loss = -1.665, time/batch = 0.006\n",
      "255/3300 (epoch 7), train_loss = -1.371, time/batch = 0.006\n",
      "256/3300 (epoch 7), train_loss = -1.196, time/batch = 0.006\n",
      "257/3300 (epoch 7), train_loss = -0.642, time/batch = 0.006\n",
      "258/3300 (epoch 7), train_loss = -0.954, time/batch = 0.006\n",
      "259/3300 (epoch 7), train_loss = -0.161, time/batch = 0.006\n",
      "260/3300 (epoch 7), train_loss = -2.246, time/batch = 0.006\n",
      "261/3300 (epoch 7), train_loss = -1.723, time/batch = 0.006\n",
      "262/3300 (epoch 7), train_loss = -1.763, time/batch = 0.006\n",
      "263/3300 (epoch 7), train_loss = -1.988, time/batch = 0.006\n",
      "264/3300 (epoch 8), train_loss = 1.043, time/batch = 0.006\n",
      "265/3300 (epoch 8), train_loss = 0.047, time/batch = 0.006\n",
      "266/3300 (epoch 8), train_loss = -0.962, time/batch = 0.007\n",
      "267/3300 (epoch 8), train_loss = -1.443, time/batch = 0.007\n",
      "268/3300 (epoch 8), train_loss = 8.554, time/batch = 0.007\n",
      "269/3300 (epoch 8), train_loss = -0.230, time/batch = 0.006\n",
      "270/3300 (epoch 8), train_loss = 5.042, time/batch = 0.006\n",
      "271/3300 (epoch 8), train_loss = -1.186, time/batch = 0.007\n",
      "272/3300 (epoch 8), train_loss = 0.303, time/batch = 0.007\n",
      "273/3300 (epoch 8), train_loss = -0.824, time/batch = 0.007\n",
      "274/3300 (epoch 8), train_loss = -0.514, time/batch = 0.006\n",
      "275/3300 (epoch 8), train_loss = -1.584, time/batch = 0.007\n",
      "276/3300 (epoch 8), train_loss = -0.794, time/batch = 0.006\n",
      "277/3300 (epoch 8), train_loss = -1.574, time/batch = 0.006\n",
      "278/3300 (epoch 8), train_loss = -0.280, time/batch = 0.006\n",
      "279/3300 (epoch 8), train_loss = -0.877, time/batch = 0.006\n",
      "280/3300 (epoch 8), train_loss = -1.297, time/batch = 0.006\n",
      "281/3300 (epoch 8), train_loss = -1.300, time/batch = 0.006\n",
      "282/3300 (epoch 8), train_loss = -0.450, time/batch = 0.006\n",
      "283/3300 (epoch 8), train_loss = -1.299, time/batch = 0.006\n",
      "284/3300 (epoch 8), train_loss = -1.120, time/batch = 0.006\n",
      "285/3300 (epoch 8), train_loss = -0.954, time/batch = 0.006\n",
      "286/3300 (epoch 8), train_loss = -1.294, time/batch = 0.006\n",
      "287/3300 (epoch 8), train_loss = -1.435, time/batch = 0.006\n",
      "288/3300 (epoch 8), train_loss = -0.510, time/batch = 0.006\n",
      "289/3300 (epoch 8), train_loss = -2.200, time/batch = 0.007\n",
      "290/3300 (epoch 8), train_loss = -0.195, time/batch = 0.007\n",
      "291/3300 (epoch 8), train_loss = -2.541, time/batch = 0.006\n",
      "292/3300 (epoch 8), train_loss = -0.454, time/batch = 0.006\n",
      "293/3300 (epoch 8), train_loss = -1.810, time/batch = 0.006\n",
      "294/3300 (epoch 8), train_loss = 3.347, time/batch = 0.006\n",
      "295/3300 (epoch 8), train_loss = -2.112, time/batch = 0.006\n",
      "296/3300 (epoch 8), train_loss = -0.064, time/batch = 0.006\n",
      "297/3300 (epoch 9), train_loss = 0.872, time/batch = 0.006\n",
      "298/3300 (epoch 9), train_loss = -0.137, time/batch = 0.006\n",
      "299/3300 (epoch 9), train_loss = -0.445, time/batch = 0.007\n",
      "300/3300 (epoch 9), train_loss = -1.245, time/batch = 0.007\n",
      "301/3300 (epoch 9), train_loss = -0.899, time/batch = 0.007\n",
      "302/3300 (epoch 9), train_loss = -0.922, time/batch = 0.006\n",
      "303/3300 (epoch 9), train_loss = -1.208, time/batch = 0.007\n",
      "304/3300 (epoch 9), train_loss = 1.840, time/batch = 0.006\n",
      "305/3300 (epoch 9), train_loss = -1.235, time/batch = 0.006\n",
      "306/3300 (epoch 9), train_loss = 0.915, time/batch = 0.006\n",
      "307/3300 (epoch 9), train_loss = -1.553, time/batch = 0.006\n",
      "308/3300 (epoch 9), train_loss = -1.096, time/batch = 0.006\n",
      "309/3300 (epoch 9), train_loss = -0.993, time/batch = 0.006\n",
      "310/3300 (epoch 9), train_loss = -1.094, time/batch = 0.006\n",
      "311/3300 (epoch 9), train_loss = -1.391, time/batch = 0.011\n",
      "312/3300 (epoch 9), train_loss = -1.158, time/batch = 0.007\n",
      "313/3300 (epoch 9), train_loss = -1.622, time/batch = 0.007\n",
      "314/3300 (epoch 9), train_loss = -1.176, time/batch = 0.007\n",
      "315/3300 (epoch 9), train_loss = -1.664, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/3300 (epoch 9), train_loss = -1.785, time/batch = 0.006\n",
      "317/3300 (epoch 9), train_loss = -1.430, time/batch = 0.011\n",
      "318/3300 (epoch 9), train_loss = -2.230, time/batch = 0.006\n",
      "319/3300 (epoch 9), train_loss = -0.087, time/batch = 0.006\n",
      "320/3300 (epoch 9), train_loss = -0.696, time/batch = 0.006\n",
      "321/3300 (epoch 9), train_loss = 0.251, time/batch = 0.006\n",
      "322/3300 (epoch 9), train_loss = -1.596, time/batch = 0.006\n",
      "323/3300 (epoch 9), train_loss = -1.088, time/batch = 0.006\n",
      "324/3300 (epoch 9), train_loss = -1.948, time/batch = 0.006\n",
      "325/3300 (epoch 9), train_loss = -1.269, time/batch = 0.007\n",
      "326/3300 (epoch 9), train_loss = -1.481, time/batch = 0.006\n",
      "327/3300 (epoch 9), train_loss = -1.429, time/batch = 0.006\n",
      "328/3300 (epoch 9), train_loss = -1.388, time/batch = 0.006\n",
      "329/3300 (epoch 9), train_loss = -1.955, time/batch = 0.006\n",
      "330/3300 (epoch 10), train_loss = 0.597, time/batch = 0.006\n",
      "331/3300 (epoch 10), train_loss = -0.318, time/batch = 0.006\n",
      "332/3300 (epoch 10), train_loss = -0.647, time/batch = 0.006\n",
      "333/3300 (epoch 10), train_loss = -1.226, time/batch = 0.006\n",
      "334/3300 (epoch 10), train_loss = -0.960, time/batch = 0.006\n",
      "335/3300 (epoch 10), train_loss = 0.965, time/batch = 0.006\n",
      "336/3300 (epoch 10), train_loss = -0.922, time/batch = 0.006\n",
      "337/3300 (epoch 10), train_loss = 0.222, time/batch = 0.006\n",
      "338/3300 (epoch 10), train_loss = -1.426, time/batch = 0.007\n",
      "339/3300 (epoch 10), train_loss = -0.827, time/batch = 0.006\n",
      "340/3300 (epoch 10), train_loss = -1.182, time/batch = 0.006\n",
      "341/3300 (epoch 10), train_loss = -1.353, time/batch = 0.006\n",
      "342/3300 (epoch 10), train_loss = -1.487, time/batch = 0.006\n",
      "343/3300 (epoch 10), train_loss = -1.539, time/batch = 0.006\n",
      "344/3300 (epoch 10), train_loss = -1.540, time/batch = 0.006\n",
      "345/3300 (epoch 10), train_loss = -0.742, time/batch = 0.006\n",
      "346/3300 (epoch 10), train_loss = -0.222, time/batch = 0.007\n",
      "347/3300 (epoch 10), train_loss = -1.794, time/batch = 0.007\n",
      "348/3300 (epoch 10), train_loss = -1.215, time/batch = 0.007\n",
      "349/3300 (epoch 10), train_loss = -1.734, time/batch = 0.006\n",
      "350/3300 (epoch 10), train_loss = -1.701, time/batch = 0.006\n",
      "351/3300 (epoch 10), train_loss = -1.714, time/batch = 0.006\n",
      "352/3300 (epoch 10), train_loss = -1.137, time/batch = 0.006\n",
      "353/3300 (epoch 10), train_loss = -1.807, time/batch = 0.006\n",
      "354/3300 (epoch 10), train_loss = -1.868, time/batch = 0.006\n",
      "355/3300 (epoch 10), train_loss = -2.274, time/batch = 0.006\n",
      "356/3300 (epoch 10), train_loss = -2.091, time/batch = 0.006\n",
      "357/3300 (epoch 10), train_loss = -2.324, time/batch = 0.006\n",
      "358/3300 (epoch 10), train_loss = -0.796, time/batch = 0.006\n",
      "359/3300 (epoch 10), train_loss = -0.801, time/batch = 0.006\n",
      "360/3300 (epoch 10), train_loss = -0.997, time/batch = 0.006\n",
      "361/3300 (epoch 10), train_loss = -1.157, time/batch = 0.006\n",
      "362/3300 (epoch 10), train_loss = -2.454, time/batch = 0.006\n",
      "363/3300 (epoch 11), train_loss = 0.570, time/batch = 0.005\n",
      "364/3300 (epoch 11), train_loss = -0.524, time/batch = 0.006\n",
      "365/3300 (epoch 11), train_loss = -1.127, time/batch = 0.006\n",
      "366/3300 (epoch 11), train_loss = -1.298, time/batch = 0.006\n",
      "367/3300 (epoch 11), train_loss = -1.521, time/batch = 0.006\n",
      "368/3300 (epoch 11), train_loss = 4.543, time/batch = 0.006\n",
      "369/3300 (epoch 11), train_loss = -1.943, time/batch = 0.006\n",
      "370/3300 (epoch 11), train_loss = 2.483, time/batch = 0.006\n",
      "371/3300 (epoch 11), train_loss = -1.819, time/batch = 0.006\n",
      "372/3300 (epoch 11), train_loss = -0.348, time/batch = 0.006\n",
      "373/3300 (epoch 11), train_loss = -1.482, time/batch = 0.006\n",
      "374/3300 (epoch 11), train_loss = -1.075, time/batch = 0.006\n",
      "375/3300 (epoch 11), train_loss = -1.469, time/batch = 0.006\n",
      "376/3300 (epoch 11), train_loss = -0.987, time/batch = 0.006\n",
      "377/3300 (epoch 11), train_loss = -1.795, time/batch = 0.007\n",
      "378/3300 (epoch 11), train_loss = -1.519, time/batch = 0.011\n",
      "379/3300 (epoch 11), train_loss = -1.812, time/batch = 0.008\n",
      "380/3300 (epoch 11), train_loss = -1.328, time/batch = 0.006\n",
      "381/3300 (epoch 11), train_loss = -1.613, time/batch = 0.006\n",
      "382/3300 (epoch 11), train_loss = -1.912, time/batch = 0.006\n",
      "383/3300 (epoch 11), train_loss = -1.844, time/batch = 0.006\n",
      "384/3300 (epoch 11), train_loss = -0.820, time/batch = 0.006\n",
      "385/3300 (epoch 11), train_loss = -2.066, time/batch = 0.006\n",
      "386/3300 (epoch 11), train_loss = -1.259, time/batch = 0.006\n",
      "387/3300 (epoch 11), train_loss = -2.619, time/batch = 0.006\n",
      "388/3300 (epoch 11), train_loss = -0.368, time/batch = 0.006\n",
      "389/3300 (epoch 11), train_loss = -2.444, time/batch = 0.006\n",
      "390/3300 (epoch 11), train_loss = 0.942, time/batch = 0.006\n",
      "391/3300 (epoch 11), train_loss = -1.993, time/batch = 0.006\n",
      "392/3300 (epoch 11), train_loss = -0.315, time/batch = 0.006\n",
      "393/3300 (epoch 11), train_loss = -2.588, time/batch = 0.006\n",
      "394/3300 (epoch 11), train_loss = 5.165, time/batch = 0.006\n",
      "395/3300 (epoch 11), train_loss = -2.729, time/batch = 0.006\n",
      "396/3300 (epoch 12), train_loss = 0.515, time/batch = 0.005\n",
      "397/3300 (epoch 12), train_loss = -0.558, time/batch = 0.006\n",
      "398/3300 (epoch 12), train_loss = -1.399, time/batch = 0.006\n",
      "399/3300 (epoch 12), train_loss = -1.276, time/batch = 0.006\n",
      "400/3300 (epoch 12), train_loss = -0.409, time/batch = 0.006\n",
      "401/3300 (epoch 12), train_loss = -0.304, time/batch = 0.006\n",
      "402/3300 (epoch 12), train_loss = 2.650, time/batch = 0.006\n",
      "403/3300 (epoch 12), train_loss = -2.134, time/batch = 0.006\n",
      "404/3300 (epoch 12), train_loss = -0.364, time/batch = 0.006\n",
      "405/3300 (epoch 12), train_loss = -2.209, time/batch = 0.006\n",
      "406/3300 (epoch 12), train_loss = -0.731, time/batch = 0.006\n",
      "407/3300 (epoch 12), train_loss = -2.189, time/batch = 0.006\n",
      "408/3300 (epoch 12), train_loss = -0.872, time/batch = 0.007\n",
      "409/3300 (epoch 12), train_loss = -2.326, time/batch = 0.006\n",
      "410/3300 (epoch 12), train_loss = -1.271, time/batch = 0.006\n",
      "411/3300 (epoch 12), train_loss = -2.474, time/batch = 0.006\n",
      "412/3300 (epoch 12), train_loss = -0.681, time/batch = 0.006\n",
      "413/3300 (epoch 12), train_loss = -2.063, time/batch = 0.006\n",
      "414/3300 (epoch 12), train_loss = -0.594, time/batch = 0.006\n",
      "415/3300 (epoch 12), train_loss = -2.146, time/batch = 0.006\n",
      "416/3300 (epoch 12), train_loss = -1.109, time/batch = 0.007\n",
      "417/3300 (epoch 12), train_loss = -1.894, time/batch = 0.006\n",
      "418/3300 (epoch 12), train_loss = -1.642, time/batch = 0.007\n",
      "419/3300 (epoch 12), train_loss = -2.049, time/batch = 0.006\n",
      "420/3300 (epoch 12), train_loss = -1.353, time/batch = 0.007\n",
      "421/3300 (epoch 12), train_loss = -2.468, time/batch = 0.006\n",
      "422/3300 (epoch 12), train_loss = -1.945, time/batch = 0.006\n",
      "423/3300 (epoch 12), train_loss = -2.694, time/batch = 0.007\n",
      "424/3300 (epoch 12), train_loss = -1.828, time/batch = 0.006\n",
      "425/3300 (epoch 12), train_loss = -2.516, time/batch = 0.006\n",
      "426/3300 (epoch 12), train_loss = 1.285, time/batch = 0.006\n",
      "427/3300 (epoch 12), train_loss = -1.967, time/batch = 0.006\n",
      "428/3300 (epoch 12), train_loss = -0.835, time/batch = 0.006\n",
      "429/3300 (epoch 13), train_loss = 0.396, time/batch = 0.006\n",
      "430/3300 (epoch 13), train_loss = -0.617, time/batch = 0.006\n",
      "431/3300 (epoch 13), train_loss = -1.428, time/batch = 0.007\n",
      "432/3300 (epoch 13), train_loss = -1.645, time/batch = 0.006\n",
      "433/3300 (epoch 13), train_loss = -1.834, time/batch = 0.006\n",
      "434/3300 (epoch 13), train_loss = 4.301, time/batch = 0.007\n",
      "435/3300 (epoch 13), train_loss = -1.275, time/batch = 0.006\n",
      "436/3300 (epoch 13), train_loss = 1.005, time/batch = 0.007\n",
      "437/3300 (epoch 13), train_loss = -1.012, time/batch = 0.006\n",
      "438/3300 (epoch 13), train_loss = -1.378, time/batch = 0.007\n",
      "439/3300 (epoch 13), train_loss = -1.892, time/batch = 0.007\n",
      "440/3300 (epoch 13), train_loss = -2.124, time/batch = 0.006\n",
      "441/3300 (epoch 13), train_loss = -1.599, time/batch = 0.007\n",
      "442/3300 (epoch 13), train_loss = -1.840, time/batch = 0.010\n",
      "443/3300 (epoch 13), train_loss = -1.240, time/batch = 0.006\n",
      "444/3300 (epoch 13), train_loss = -2.293, time/batch = 0.007\n",
      "445/3300 (epoch 13), train_loss = 0.109, time/batch = 0.006\n",
      "446/3300 (epoch 13), train_loss = -1.981, time/batch = 0.009\n",
      "447/3300 (epoch 13), train_loss = -1.498, time/batch = 0.006\n",
      "448/3300 (epoch 13), train_loss = -1.971, time/batch = 0.007\n",
      "449/3300 (epoch 13), train_loss = -0.834, time/batch = 0.006\n",
      "450/3300 (epoch 13), train_loss = -2.287, time/batch = 0.007\n",
      "451/3300 (epoch 13), train_loss = 0.179, time/batch = 0.007\n",
      "452/3300 (epoch 13), train_loss = -2.986, time/batch = 0.008\n",
      "453/3300 (epoch 13), train_loss = 0.328, time/batch = 0.012\n",
      "454/3300 (epoch 13), train_loss = -2.565, time/batch = 0.009\n",
      "455/3300 (epoch 13), train_loss = 1.086, time/batch = 0.012\n",
      "456/3300 (epoch 13), train_loss = -2.828, time/batch = 0.008\n",
      "457/3300 (epoch 13), train_loss = -0.873, time/batch = 0.009\n",
      "458/3300 (epoch 13), train_loss = -2.447, time/batch = 0.008\n",
      "459/3300 (epoch 13), train_loss = 0.276, time/batch = 0.007\n",
      "460/3300 (epoch 13), train_loss = -2.502, time/batch = 0.009\n",
      "461/3300 (epoch 13), train_loss = -1.337, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/3300 (epoch 14), train_loss = 0.270, time/batch = 0.006\n",
      "463/3300 (epoch 14), train_loss = -0.865, time/batch = 0.006\n",
      "464/3300 (epoch 14), train_loss = -1.608, time/batch = 0.006\n",
      "465/3300 (epoch 14), train_loss = -0.846, time/batch = 0.006\n",
      "466/3300 (epoch 14), train_loss = -1.660, time/batch = 0.006\n",
      "467/3300 (epoch 14), train_loss = 0.690, time/batch = 0.007\n",
      "468/3300 (epoch 14), train_loss = -2.024, time/batch = 0.007\n",
      "469/3300 (epoch 14), train_loss = -0.641, time/batch = 0.007\n",
      "470/3300 (epoch 14), train_loss = -2.440, time/batch = 0.008\n",
      "471/3300 (epoch 14), train_loss = -1.975, time/batch = 0.006\n",
      "472/3300 (epoch 14), train_loss = -2.002, time/batch = 0.006\n",
      "473/3300 (epoch 14), train_loss = -1.760, time/batch = 0.006\n",
      "474/3300 (epoch 14), train_loss = -1.315, time/batch = 0.006\n",
      "475/3300 (epoch 14), train_loss = -1.692, time/batch = 0.006\n",
      "476/3300 (epoch 14), train_loss = -1.412, time/batch = 0.006\n",
      "477/3300 (epoch 14), train_loss = -2.009, time/batch = 0.006\n",
      "478/3300 (epoch 14), train_loss = -1.666, time/batch = 0.006\n",
      "479/3300 (epoch 14), train_loss = -1.960, time/batch = 0.006\n",
      "480/3300 (epoch 14), train_loss = -2.019, time/batch = 0.006\n",
      "481/3300 (epoch 14), train_loss = -1.909, time/batch = 0.006\n",
      "482/3300 (epoch 14), train_loss = -2.068, time/batch = 0.006\n",
      "483/3300 (epoch 14), train_loss = -1.597, time/batch = 0.006\n",
      "484/3300 (epoch 14), train_loss = -1.945, time/batch = 0.006\n",
      "485/3300 (epoch 14), train_loss = -1.835, time/batch = 0.006\n",
      "486/3300 (epoch 14), train_loss = -2.529, time/batch = 0.006\n",
      "487/3300 (epoch 14), train_loss = -2.584, time/batch = 0.007\n",
      "488/3300 (epoch 14), train_loss = -2.396, time/batch = 0.006\n",
      "489/3300 (epoch 14), train_loss = -2.329, time/batch = 0.007\n",
      "490/3300 (epoch 14), train_loss = -1.062, time/batch = 0.006\n",
      "491/3300 (epoch 14), train_loss = -1.678, time/batch = 0.006\n",
      "492/3300 (epoch 14), train_loss = -0.833, time/batch = 0.006\n",
      "493/3300 (epoch 14), train_loss = -2.530, time/batch = 0.006\n",
      "494/3300 (epoch 14), train_loss = -1.902, time/batch = 0.006\n",
      "495/3300 (epoch 15), train_loss = 0.141, time/batch = 0.006\n",
      "496/3300 (epoch 15), train_loss = -0.572, time/batch = 0.007\n",
      "497/3300 (epoch 15), train_loss = -1.563, time/batch = 0.006\n",
      "498/3300 (epoch 15), train_loss = -1.541, time/batch = 0.006\n",
      "499/3300 (epoch 15), train_loss = -1.930, time/batch = 0.007\n",
      "500/3300 (epoch 15), train_loss = 2.445, time/batch = 0.007\n",
      "501/3300 (epoch 15), train_loss = -1.845, time/batch = 0.008\n",
      "502/3300 (epoch 15), train_loss = 1.123, time/batch = 0.007\n",
      "503/3300 (epoch 15), train_loss = -2.325, time/batch = 0.006\n",
      "504/3300 (epoch 15), train_loss = -0.649, time/batch = 0.006\n",
      "505/3300 (epoch 15), train_loss = -2.220, time/batch = 0.006\n",
      "506/3300 (epoch 15), train_loss = -1.332, time/batch = 0.006\n",
      "507/3300 (epoch 15), train_loss = -2.309, time/batch = 0.006\n",
      "508/3300 (epoch 15), train_loss = -1.101, time/batch = 0.006\n",
      "509/3300 (epoch 15), train_loss = -2.387, time/batch = 0.006\n",
      "510/3300 (epoch 15), train_loss = -1.259, time/batch = 0.006\n",
      "511/3300 (epoch 15), train_loss = -2.358, time/batch = 0.006\n",
      "512/3300 (epoch 15), train_loss = -1.590, time/batch = 0.006\n",
      "513/3300 (epoch 15), train_loss = -2.618, time/batch = 0.006\n",
      "514/3300 (epoch 15), train_loss = -2.018, time/batch = 0.006\n",
      "515/3300 (epoch 15), train_loss = -2.274, time/batch = 0.006\n",
      "516/3300 (epoch 15), train_loss = -1.831, time/batch = 0.006\n",
      "517/3300 (epoch 15), train_loss = -2.602, time/batch = 0.006\n",
      "518/3300 (epoch 15), train_loss = -2.210, time/batch = 0.006\n",
      "519/3300 (epoch 15), train_loss = -1.242, time/batch = 0.006\n",
      "520/3300 (epoch 15), train_loss = -2.326, time/batch = 0.006\n",
      "521/3300 (epoch 15), train_loss = -0.059, time/batch = 0.006\n",
      "522/3300 (epoch 15), train_loss = -2.434, time/batch = 0.006\n",
      "523/3300 (epoch 15), train_loss = -1.224, time/batch = 0.007\n",
      "524/3300 (epoch 15), train_loss = -2.889, time/batch = 0.006\n",
      "525/3300 (epoch 15), train_loss = -2.265, time/batch = 0.007\n",
      "526/3300 (epoch 15), train_loss = -2.728, time/batch = 0.007\n",
      "527/3300 (epoch 15), train_loss = -1.227, time/batch = 0.006\n",
      "528/3300 (epoch 16), train_loss = 0.077, time/batch = 0.006\n",
      "529/3300 (epoch 16), train_loss = -1.166, time/batch = 0.006\n",
      "530/3300 (epoch 16), train_loss = -1.736, time/batch = 0.006\n",
      "531/3300 (epoch 16), train_loss = -0.018, time/batch = 0.006\n",
      "532/3300 (epoch 16), train_loss = -2.029, time/batch = 0.006\n",
      "533/3300 (epoch 16), train_loss = -1.641, time/batch = 0.006\n",
      "534/3300 (epoch 16), train_loss = -2.495, time/batch = 0.007\n",
      "535/3300 (epoch 16), train_loss = -1.081, time/batch = 0.006\n",
      "536/3300 (epoch 16), train_loss = -1.375, time/batch = 0.006\n",
      "537/3300 (epoch 16), train_loss = 0.139, time/batch = 0.006\n",
      "538/3300 (epoch 16), train_loss = -2.550, time/batch = 0.007\n",
      "539/3300 (epoch 16), train_loss = 0.329, time/batch = 0.006\n",
      "540/3300 (epoch 16), train_loss = -2.882, time/batch = 0.006\n",
      "541/3300 (epoch 16), train_loss = -0.751, time/batch = 0.006\n",
      "542/3300 (epoch 16), train_loss = -2.818, time/batch = 0.006\n",
      "543/3300 (epoch 16), train_loss = -0.353, time/batch = 0.006\n",
      "544/3300 (epoch 16), train_loss = -3.076, time/batch = 0.006\n",
      "545/3300 (epoch 16), train_loss = -0.073, time/batch = 0.006\n",
      "546/3300 (epoch 16), train_loss = -2.572, time/batch = 0.006\n",
      "547/3300 (epoch 16), train_loss = -1.484, time/batch = 0.006\n",
      "548/3300 (epoch 16), train_loss = -2.766, time/batch = 0.006\n",
      "549/3300 (epoch 16), train_loss = -2.712, time/batch = 0.006\n",
      "550/3300 (epoch 16), train_loss = -0.532, time/batch = 0.006\n",
      "551/3300 (epoch 16), train_loss = -3.098, time/batch = 0.006\n",
      "552/3300 (epoch 16), train_loss = -0.894, time/batch = 0.006\n",
      "553/3300 (epoch 16), train_loss = -3.154, time/batch = 0.006\n",
      "554/3300 (epoch 16), train_loss = 0.326, time/batch = 0.006\n",
      "555/3300 (epoch 16), train_loss = -2.809, time/batch = 0.006\n",
      "556/3300 (epoch 16), train_loss = 0.447, time/batch = 0.006\n",
      "557/3300 (epoch 16), train_loss = -2.818, time/batch = 0.006\n",
      "558/3300 (epoch 16), train_loss = 0.156, time/batch = 0.007\n",
      "559/3300 (epoch 16), train_loss = -2.735, time/batch = 0.006\n",
      "560/3300 (epoch 16), train_loss = 0.301, time/batch = 0.006\n",
      "561/3300 (epoch 17), train_loss = 0.029, time/batch = 0.005\n",
      "562/3300 (epoch 17), train_loss = -0.863, time/batch = 0.006\n",
      "563/3300 (epoch 17), train_loss = -1.785, time/batch = 0.007\n",
      "564/3300 (epoch 17), train_loss = -2.153, time/batch = 0.007\n",
      "565/3300 (epoch 17), train_loss = 2.380, time/batch = 0.006\n",
      "566/3300 (epoch 17), train_loss = -2.657, time/batch = 0.006\n",
      "567/3300 (epoch 17), train_loss = 0.727, time/batch = 0.007\n",
      "568/3300 (epoch 17), train_loss = -2.626, time/batch = 0.006\n",
      "569/3300 (epoch 17), train_loss = -0.185, time/batch = 0.008\n",
      "570/3300 (epoch 17), train_loss = -2.692, time/batch = 0.006\n",
      "571/3300 (epoch 17), train_loss = 0.575, time/batch = 0.007\n",
      "572/3300 (epoch 17), train_loss = -3.152, time/batch = 0.007\n",
      "573/3300 (epoch 17), train_loss = 0.797, time/batch = 0.006\n",
      "574/3300 (epoch 17), train_loss = -3.194, time/batch = 0.006\n",
      "575/3300 (epoch 17), train_loss = 2.283, time/batch = 0.006\n",
      "576/3300 (epoch 17), train_loss = -3.166, time/batch = 0.006\n",
      "577/3300 (epoch 17), train_loss = 1.475, time/batch = 0.007\n",
      "578/3300 (epoch 17), train_loss = -3.168, time/batch = 0.006\n",
      "579/3300 (epoch 17), train_loss = 0.527, time/batch = 0.006\n",
      "580/3300 (epoch 17), train_loss = -2.919, time/batch = 0.007\n",
      "581/3300 (epoch 17), train_loss = 0.456, time/batch = 0.006\n",
      "582/3300 (epoch 17), train_loss = -3.092, time/batch = 0.006\n",
      "583/3300 (epoch 17), train_loss = 1.214, time/batch = 0.006\n",
      "584/3300 (epoch 17), train_loss = -3.307, time/batch = 0.007\n",
      "585/3300 (epoch 17), train_loss = -0.455, time/batch = 0.007\n",
      "586/3300 (epoch 17), train_loss = -3.414, time/batch = 0.008\n",
      "587/3300 (epoch 17), train_loss = -0.394, time/batch = 0.008\n",
      "588/3300 (epoch 17), train_loss = -3.309, time/batch = 0.007\n",
      "589/3300 (epoch 17), train_loss = -2.598, time/batch = 0.006\n",
      "590/3300 (epoch 17), train_loss = -3.025, time/batch = 0.006\n",
      "591/3300 (epoch 17), train_loss = 1.237, time/batch = 0.006\n",
      "592/3300 (epoch 17), train_loss = -2.873, time/batch = 0.007\n",
      "593/3300 (epoch 17), train_loss = 0.246, time/batch = 0.007\n",
      "594/3300 (epoch 18), train_loss = -0.057, time/batch = 0.006\n",
      "595/3300 (epoch 18), train_loss = -1.005, time/batch = 0.007\n",
      "596/3300 (epoch 18), train_loss = -1.910, time/batch = 0.006\n",
      "597/3300 (epoch 18), train_loss = -1.266, time/batch = 0.008\n",
      "598/3300 (epoch 18), train_loss = -2.416, time/batch = 0.007\n",
      "599/3300 (epoch 18), train_loss = -0.790, time/batch = 0.006\n",
      "600/3300 (epoch 18), train_loss = -1.235, time/batch = 0.007\n",
      "601/3300 (epoch 18), train_loss = -1.524, time/batch = 0.007\n",
      "602/3300 (epoch 18), train_loss = -2.148, time/batch = 0.007\n",
      "603/3300 (epoch 18), train_loss = -2.328, time/batch = 0.006\n",
      "604/3300 (epoch 18), train_loss = -1.756, time/batch = 0.007\n",
      "605/3300 (epoch 18), train_loss = -2.892, time/batch = 0.007\n",
      "606/3300 (epoch 18), train_loss = -0.978, time/batch = 0.007\n",
      "607/3300 (epoch 18), train_loss = -2.533, time/batch = 0.007\n",
      "608/3300 (epoch 18), train_loss = -0.650, time/batch = 0.006\n",
      "609/3300 (epoch 18), train_loss = -1.707, time/batch = 0.006\n",
      "610/3300 (epoch 18), train_loss = -0.042, time/batch = 0.007\n",
      "611/3300 (epoch 18), train_loss = -2.481, time/batch = 0.006\n",
      "612/3300 (epoch 18), train_loss = -1.236, time/batch = 0.006\n",
      "613/3300 (epoch 18), train_loss = -2.002, time/batch = 0.007\n",
      "614/3300 (epoch 18), train_loss = -2.107, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615/3300 (epoch 18), train_loss = -2.455, time/batch = 0.007\n",
      "616/3300 (epoch 18), train_loss = -2.269, time/batch = 0.006\n",
      "617/3300 (epoch 18), train_loss = -2.196, time/batch = 0.008\n",
      "618/3300 (epoch 18), train_loss = -2.653, time/batch = 0.006\n",
      "619/3300 (epoch 18), train_loss = -2.447, time/batch = 0.006\n",
      "620/3300 (epoch 18), train_loss = -3.043, time/batch = 0.007\n",
      "621/3300 (epoch 18), train_loss = -1.431, time/batch = 0.006\n",
      "622/3300 (epoch 18), train_loss = -2.525, time/batch = 0.006\n",
      "623/3300 (epoch 18), train_loss = -1.558, time/batch = 0.007\n",
      "624/3300 (epoch 18), train_loss = -2.780, time/batch = 0.006\n",
      "625/3300 (epoch 18), train_loss = -2.420, time/batch = 0.007\n",
      "626/3300 (epoch 18), train_loss = -3.142, time/batch = 0.006\n",
      "627/3300 (epoch 19), train_loss = -0.249, time/batch = 0.006\n",
      "628/3300 (epoch 19), train_loss = -1.041, time/batch = 0.007\n",
      "629/3300 (epoch 19), train_loss = -2.173, time/batch = 0.006\n",
      "630/3300 (epoch 19), train_loss = -2.012, time/batch = 0.007\n",
      "631/3300 (epoch 19), train_loss = -2.403, time/batch = 0.007\n",
      "632/3300 (epoch 19), train_loss = 4.477, time/batch = 0.006\n",
      "633/3300 (epoch 19), train_loss = -1.921, time/batch = 0.006\n",
      "634/3300 (epoch 19), train_loss = 0.137, time/batch = 0.006\n",
      "635/3300 (epoch 19), train_loss = -3.037, time/batch = 0.006\n",
      "636/3300 (epoch 19), train_loss = 1.493, time/batch = 0.007\n",
      "637/3300 (epoch 19), train_loss = -3.028, time/batch = 0.006\n",
      "638/3300 (epoch 19), train_loss = 0.705, time/batch = 0.008\n",
      "639/3300 (epoch 19), train_loss = -3.110, time/batch = 0.006\n",
      "640/3300 (epoch 19), train_loss = 2.253, time/batch = 0.006\n",
      "641/3300 (epoch 19), train_loss = -2.810, time/batch = 0.007\n",
      "642/3300 (epoch 19), train_loss = 0.296, time/batch = 0.006\n",
      "643/3300 (epoch 19), train_loss = -3.074, time/batch = 0.006\n",
      "644/3300 (epoch 19), train_loss = 1.273, time/batch = 0.007\n",
      "645/3300 (epoch 19), train_loss = -2.942, time/batch = 0.006\n",
      "646/3300 (epoch 19), train_loss = -1.443, time/batch = 0.006\n",
      "647/3300 (epoch 19), train_loss = -2.772, time/batch = 0.006\n",
      "648/3300 (epoch 19), train_loss = -0.792, time/batch = 0.008\n",
      "649/3300 (epoch 19), train_loss = -2.803, time/batch = 0.006\n",
      "650/3300 (epoch 19), train_loss = -1.619, time/batch = 0.006\n",
      "651/3300 (epoch 19), train_loss = -3.186, time/batch = 0.007\n",
      "652/3300 (epoch 19), train_loss = -0.489, time/batch = 0.007\n",
      "653/3300 (epoch 19), train_loss = -3.285, time/batch = 0.007\n",
      "654/3300 (epoch 19), train_loss = 0.565, time/batch = 0.006\n",
      "655/3300 (epoch 19), train_loss = -3.818, time/batch = 0.006\n",
      "656/3300 (epoch 19), train_loss = 4.031, time/batch = 0.006\n",
      "657/3300 (epoch 19), train_loss = -3.211, time/batch = 0.006\n",
      "658/3300 (epoch 19), train_loss = -0.298, time/batch = 0.006\n",
      "659/3300 (epoch 19), train_loss = -3.145, time/batch = 0.006\n",
      "660/3300 (epoch 20), train_loss = -0.223, time/batch = 0.006\n",
      "661/3300 (epoch 20), train_loss = -0.842, time/batch = 0.006\n",
      "662/3300 (epoch 20), train_loss = -2.068, time/batch = 0.006\n",
      "663/3300 (epoch 20), train_loss = -1.292, time/batch = 0.006\n",
      "664/3300 (epoch 20), train_loss = -2.668, time/batch = 0.007\n",
      "665/3300 (epoch 20), train_loss = 5.102, time/batch = 0.006\n",
      "666/3300 (epoch 20), train_loss = -3.226, time/batch = 0.007\n",
      "667/3300 (epoch 20), train_loss = 1.945, time/batch = 0.006\n",
      "668/3300 (epoch 20), train_loss = -3.240, time/batch = 0.006\n",
      "669/3300 (epoch 20), train_loss = -0.128, time/batch = 0.006\n",
      "670/3300 (epoch 20), train_loss = -2.898, time/batch = 0.006\n",
      "671/3300 (epoch 20), train_loss = 0.354, time/batch = 0.006\n",
      "672/3300 (epoch 20), train_loss = -2.791, time/batch = 0.007\n",
      "673/3300 (epoch 20), train_loss = -0.718, time/batch = 0.008\n",
      "674/3300 (epoch 20), train_loss = -2.903, time/batch = 0.007\n",
      "675/3300 (epoch 20), train_loss = -1.299, time/batch = 0.006\n",
      "676/3300 (epoch 20), train_loss = -2.913, time/batch = 0.006\n",
      "677/3300 (epoch 20), train_loss = -1.572, time/batch = 0.007\n",
      "678/3300 (epoch 20), train_loss = -2.456, time/batch = 0.006\n",
      "679/3300 (epoch 20), train_loss = -1.991, time/batch = 0.007\n",
      "680/3300 (epoch 20), train_loss = -2.841, time/batch = 0.007\n",
      "681/3300 (epoch 20), train_loss = -2.082, time/batch = 0.006\n",
      "682/3300 (epoch 20), train_loss = -3.090, time/batch = 0.006\n",
      "683/3300 (epoch 20), train_loss = -2.775, time/batch = 0.006\n",
      "684/3300 (epoch 20), train_loss = -2.935, time/batch = 0.006\n",
      "685/3300 (epoch 20), train_loss = -2.768, time/batch = 0.007\n",
      "686/3300 (epoch 20), train_loss = -2.488, time/batch = 0.006\n",
      "687/3300 (epoch 20), train_loss = -2.627, time/batch = 0.006\n",
      "688/3300 (epoch 20), train_loss = -2.257, time/batch = 0.006\n",
      "689/3300 (epoch 20), train_loss = -2.818, time/batch = 0.006\n",
      "690/3300 (epoch 20), train_loss = -2.683, time/batch = 0.006\n",
      "691/3300 (epoch 20), train_loss = -2.644, time/batch = 0.006\n",
      "692/3300 (epoch 20), train_loss = -2.812, time/batch = 0.006\n",
      "693/3300 (epoch 21), train_loss = -0.211, time/batch = 0.006\n",
      "694/3300 (epoch 21), train_loss = -1.091, time/batch = 0.006\n",
      "695/3300 (epoch 21), train_loss = -2.098, time/batch = 0.006\n",
      "696/3300 (epoch 21), train_loss = -2.399, time/batch = 0.006\n",
      "697/3300 (epoch 21), train_loss = -2.607, time/batch = 0.006\n",
      "698/3300 (epoch 21), train_loss = 0.451, time/batch = 0.006\n",
      "699/3300 (epoch 21), train_loss = -1.824, time/batch = 0.006\n",
      "700/3300 (epoch 21), train_loss = -1.184, time/batch = 0.006\n",
      "701/3300 (epoch 21), train_loss = -2.500, time/batch = 0.006\n",
      "702/3300 (epoch 21), train_loss = 0.824, time/batch = 0.006\n",
      "703/3300 (epoch 21), train_loss = -2.900, time/batch = 0.006\n",
      "704/3300 (epoch 21), train_loss = 0.452, time/batch = 0.006\n",
      "705/3300 (epoch 21), train_loss = -3.067, time/batch = 0.006\n",
      "706/3300 (epoch 21), train_loss = -0.886, time/batch = 0.006\n",
      "707/3300 (epoch 21), train_loss = -2.958, time/batch = 0.006\n",
      "708/3300 (epoch 21), train_loss = 0.218, time/batch = 0.006\n",
      "709/3300 (epoch 21), train_loss = -2.876, time/batch = 0.006\n",
      "710/3300 (epoch 21), train_loss = -1.803, time/batch = 0.007\n",
      "711/3300 (epoch 21), train_loss = -3.067, time/batch = 0.006\n",
      "712/3300 (epoch 21), train_loss = -0.802, time/batch = 0.007\n",
      "713/3300 (epoch 21), train_loss = -3.322, time/batch = 0.006\n",
      "714/3300 (epoch 21), train_loss = -0.670, time/batch = 0.006\n",
      "715/3300 (epoch 21), train_loss = -3.314, time/batch = 0.006\n",
      "716/3300 (epoch 21), train_loss = 1.978, time/batch = 0.006\n",
      "717/3300 (epoch 21), train_loss = -3.788, time/batch = 0.006\n",
      "718/3300 (epoch 21), train_loss = 0.627, time/batch = 0.006\n",
      "719/3300 (epoch 21), train_loss = -3.394, time/batch = 0.006\n",
      "720/3300 (epoch 21), train_loss = -0.463, time/batch = 0.006\n",
      "721/3300 (epoch 21), train_loss = -4.087, time/batch = 0.006\n",
      "722/3300 (epoch 21), train_loss = 6.275, time/batch = 0.006\n",
      "723/3300 (epoch 21), train_loss = -3.068, time/batch = 0.007\n",
      "724/3300 (epoch 21), train_loss = -1.546, time/batch = 0.006\n",
      "725/3300 (epoch 21), train_loss = -3.318, time/batch = 0.007\n",
      "726/3300 (epoch 22), train_loss = -0.323, time/batch = 0.007\n",
      "727/3300 (epoch 22), train_loss = -0.941, time/batch = 0.006\n",
      "728/3300 (epoch 22), train_loss = -2.037, time/batch = 0.007\n",
      "729/3300 (epoch 22), train_loss = -0.605, time/batch = 0.007\n",
      "730/3300 (epoch 22), train_loss = -2.419, time/batch = 0.007\n",
      "731/3300 (epoch 22), train_loss = -1.145, time/batch = 0.010\n",
      "732/3300 (epoch 22), train_loss = -2.526, time/batch = 0.007\n",
      "733/3300 (epoch 22), train_loss = -1.406, time/batch = 0.008\n",
      "734/3300 (epoch 22), train_loss = -2.874, time/batch = 0.007\n",
      "735/3300 (epoch 22), train_loss = -0.381, time/batch = 0.007\n",
      "736/3300 (epoch 22), train_loss = -3.153, time/batch = 0.006\n",
      "737/3300 (epoch 22), train_loss = -1.741, time/batch = 0.006\n",
      "738/3300 (epoch 22), train_loss = -2.677, time/batch = 0.006\n",
      "739/3300 (epoch 22), train_loss = -2.293, time/batch = 0.006\n",
      "740/3300 (epoch 22), train_loss = -3.090, time/batch = 0.007\n",
      "741/3300 (epoch 22), train_loss = -1.320, time/batch = 0.006\n",
      "742/3300 (epoch 22), train_loss = -1.731, time/batch = 0.006\n",
      "743/3300 (epoch 22), train_loss = -2.315, time/batch = 0.007\n",
      "744/3300 (epoch 22), train_loss = -1.917, time/batch = 0.006\n",
      "745/3300 (epoch 22), train_loss = -2.198, time/batch = 0.006\n",
      "746/3300 (epoch 22), train_loss = -2.116, time/batch = 0.006\n",
      "747/3300 (epoch 22), train_loss = -2.768, time/batch = 0.006\n",
      "748/3300 (epoch 22), train_loss = -2.727, time/batch = 0.006\n",
      "749/3300 (epoch 22), train_loss = -2.201, time/batch = 0.006\n",
      "750/3300 (epoch 22), train_loss = -2.759, time/batch = 0.006\n",
      "751/3300 (epoch 22), train_loss = -3.340, time/batch = 0.006\n",
      "752/3300 (epoch 22), train_loss = -2.457, time/batch = 0.008\n",
      "753/3300 (epoch 22), train_loss = -3.472, time/batch = 0.006\n",
      "754/3300 (epoch 22), train_loss = -2.563, time/batch = 0.006\n",
      "755/3300 (epoch 22), train_loss = -3.516, time/batch = 0.006\n",
      "756/3300 (epoch 22), train_loss = -2.262, time/batch = 0.006\n",
      "757/3300 (epoch 22), train_loss = -3.097, time/batch = 0.006\n",
      "758/3300 (epoch 22), train_loss = -0.694, time/batch = 0.006\n",
      "759/3300 (epoch 23), train_loss = -0.279, time/batch = 0.006\n",
      "760/3300 (epoch 23), train_loss = -1.492, time/batch = 0.006\n",
      "761/3300 (epoch 23), train_loss = -2.106, time/batch = 0.006\n",
      "762/3300 (epoch 23), train_loss = -1.260, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/3300 (epoch 23), train_loss = -2.420, time/batch = 0.007\n",
      "764/3300 (epoch 23), train_loss = -1.362, time/batch = 0.006\n",
      "765/3300 (epoch 23), train_loss = -2.316, time/batch = 0.009\n",
      "766/3300 (epoch 23), train_loss = -1.568, time/batch = 0.006\n",
      "767/3300 (epoch 23), train_loss = -2.601, time/batch = 0.006\n",
      "768/3300 (epoch 23), train_loss = -1.829, time/batch = 0.006\n",
      "769/3300 (epoch 23), train_loss = -2.821, time/batch = 0.006\n",
      "770/3300 (epoch 23), train_loss = -0.325, time/batch = 0.006\n",
      "771/3300 (epoch 23), train_loss = -2.131, time/batch = 0.006\n",
      "772/3300 (epoch 23), train_loss = -2.008, time/batch = 0.006\n",
      "773/3300 (epoch 23), train_loss = -2.662, time/batch = 0.006\n",
      "774/3300 (epoch 23), train_loss = -1.769, time/batch = 0.006\n",
      "775/3300 (epoch 23), train_loss = -3.106, time/batch = 0.006\n",
      "776/3300 (epoch 23), train_loss = -2.079, time/batch = 0.006\n",
      "777/3300 (epoch 23), train_loss = -3.053, time/batch = 0.006\n",
      "778/3300 (epoch 23), train_loss = -1.922, time/batch = 0.006\n",
      "779/3300 (epoch 23), train_loss = -2.778, time/batch = 0.006\n",
      "780/3300 (epoch 23), train_loss = -2.606, time/batch = 0.006\n",
      "781/3300 (epoch 23), train_loss = -2.726, time/batch = 0.006\n",
      "782/3300 (epoch 23), train_loss = -2.025, time/batch = 0.006\n",
      "783/3300 (epoch 23), train_loss = -3.251, time/batch = 0.006\n",
      "784/3300 (epoch 23), train_loss = -2.968, time/batch = 0.006\n",
      "785/3300 (epoch 23), train_loss = -3.371, time/batch = 0.006\n",
      "786/3300 (epoch 23), train_loss = -2.724, time/batch = 0.006\n",
      "787/3300 (epoch 23), train_loss = -2.143, time/batch = 0.007\n",
      "788/3300 (epoch 23), train_loss = -1.625, time/batch = 0.006\n",
      "789/3300 (epoch 23), train_loss = -2.630, time/batch = 0.006\n",
      "790/3300 (epoch 23), train_loss = -2.998, time/batch = 0.006\n",
      "791/3300 (epoch 23), train_loss = -3.101, time/batch = 0.006\n",
      "792/3300 (epoch 24), train_loss = -0.392, time/batch = 0.005\n",
      "793/3300 (epoch 24), train_loss = -1.286, time/batch = 0.006\n",
      "794/3300 (epoch 24), train_loss = -1.953, time/batch = 0.006\n",
      "795/3300 (epoch 24), train_loss = -1.408, time/batch = 0.006\n",
      "796/3300 (epoch 24), train_loss = -2.418, time/batch = 0.006\n",
      "797/3300 (epoch 24), train_loss = -0.948, time/batch = 0.006\n",
      "798/3300 (epoch 24), train_loss = -2.519, time/batch = 0.006\n",
      "799/3300 (epoch 24), train_loss = -1.283, time/batch = 0.006\n",
      "800/3300 (epoch 24), train_loss = -2.967, time/batch = 0.006\n",
      "801/3300 (epoch 24), train_loss = -2.471, time/batch = 0.007\n",
      "802/3300 (epoch 24), train_loss = -2.923, time/batch = 0.006\n",
      "803/3300 (epoch 24), train_loss = -2.300, time/batch = 0.006\n",
      "804/3300 (epoch 24), train_loss = -3.069, time/batch = 0.006\n",
      "805/3300 (epoch 24), train_loss = -1.875, time/batch = 0.006\n",
      "806/3300 (epoch 24), train_loss = -2.347, time/batch = 0.006\n",
      "807/3300 (epoch 24), train_loss = -2.044, time/batch = 0.006\n",
      "808/3300 (epoch 24), train_loss = -2.669, time/batch = 0.006\n",
      "809/3300 (epoch 24), train_loss = -2.056, time/batch = 0.006\n",
      "810/3300 (epoch 24), train_loss = -2.651, time/batch = 0.006\n",
      "811/3300 (epoch 24), train_loss = -2.406, time/batch = 0.006\n",
      "812/3300 (epoch 24), train_loss = -2.695, time/batch = 0.006\n",
      "813/3300 (epoch 24), train_loss = -2.497, time/batch = 0.006\n",
      "814/3300 (epoch 24), train_loss = -2.870, time/batch = 0.006\n",
      "815/3300 (epoch 24), train_loss = -2.909, time/batch = 0.006\n",
      "816/3300 (epoch 24), train_loss = -3.264, time/batch = 0.008\n",
      "817/3300 (epoch 24), train_loss = -2.938, time/batch = 0.006\n",
      "818/3300 (epoch 24), train_loss = -3.542, time/batch = 0.006\n",
      "819/3300 (epoch 24), train_loss = -2.668, time/batch = 0.006\n",
      "820/3300 (epoch 24), train_loss = -2.833, time/batch = 0.006\n",
      "821/3300 (epoch 24), train_loss = -2.649, time/batch = 0.007\n",
      "822/3300 (epoch 24), train_loss = -3.160, time/batch = 0.006\n",
      "823/3300 (epoch 24), train_loss = -2.744, time/batch = 0.006\n",
      "824/3300 (epoch 24), train_loss = -3.071, time/batch = 0.006\n",
      "825/3300 (epoch 25), train_loss = -0.348, time/batch = 0.006\n",
      "826/3300 (epoch 25), train_loss = -1.676, time/batch = 0.007\n",
      "827/3300 (epoch 25), train_loss = -2.251, time/batch = 0.007\n",
      "828/3300 (epoch 25), train_loss = -1.709, time/batch = 0.006\n",
      "829/3300 (epoch 25), train_loss = -2.664, time/batch = 0.006\n",
      "830/3300 (epoch 25), train_loss = -0.040, time/batch = 0.006\n",
      "831/3300 (epoch 25), train_loss = -2.713, time/batch = 0.007\n",
      "832/3300 (epoch 25), train_loss = -1.049, time/batch = 0.006\n",
      "833/3300 (epoch 25), train_loss = -3.036, time/batch = 0.006\n",
      "834/3300 (epoch 25), train_loss = -1.537, time/batch = 0.006\n",
      "835/3300 (epoch 25), train_loss = -2.875, time/batch = 0.006\n",
      "836/3300 (epoch 25), train_loss = -2.383, time/batch = 0.006\n",
      "837/3300 (epoch 25), train_loss = -3.172, time/batch = 0.006\n",
      "838/3300 (epoch 25), train_loss = -0.706, time/batch = 0.006\n",
      "839/3300 (epoch 25), train_loss = -2.841, time/batch = 0.006\n",
      "840/3300 (epoch 25), train_loss = -2.048, time/batch = 0.006\n",
      "841/3300 (epoch 25), train_loss = -3.324, time/batch = 0.006\n",
      "842/3300 (epoch 25), train_loss = -0.326, time/batch = 0.006\n",
      "843/3300 (epoch 25), train_loss = -3.147, time/batch = 0.006\n",
      "844/3300 (epoch 25), train_loss = -1.649, time/batch = 0.006\n",
      "845/3300 (epoch 25), train_loss = -3.278, time/batch = 0.006\n",
      "846/3300 (epoch 25), train_loss = -1.745, time/batch = 0.006\n",
      "847/3300 (epoch 25), train_loss = -3.306, time/batch = 0.006\n",
      "848/3300 (epoch 25), train_loss = -2.717, time/batch = 0.006\n",
      "849/3300 (epoch 25), train_loss = -3.724, time/batch = 0.006\n",
      "850/3300 (epoch 25), train_loss = -2.223, time/batch = 0.006\n",
      "851/3300 (epoch 25), train_loss = -3.904, time/batch = 0.006\n",
      "852/3300 (epoch 25), train_loss = -2.042, time/batch = 0.006\n",
      "853/3300 (epoch 25), train_loss = -4.023, time/batch = 0.006\n",
      "854/3300 (epoch 25), train_loss = -1.216, time/batch = 0.006\n",
      "855/3300 (epoch 25), train_loss = -3.522, time/batch = 0.006\n",
      "856/3300 (epoch 25), train_loss = -1.579, time/batch = 0.006\n",
      "857/3300 (epoch 25), train_loss = -3.965, time/batch = 0.007\n",
      "858/3300 (epoch 26), train_loss = -0.555, time/batch = 0.005\n",
      "859/3300 (epoch 26), train_loss = -0.978, time/batch = 0.006\n",
      "860/3300 (epoch 26), train_loss = -2.183, time/batch = 0.006\n",
      "861/3300 (epoch 26), train_loss = -1.697, time/batch = 0.006\n",
      "862/3300 (epoch 26), train_loss = -2.357, time/batch = 0.006\n",
      "863/3300 (epoch 26), train_loss = -1.177, time/batch = 0.006\n",
      "864/3300 (epoch 26), train_loss = -2.967, time/batch = 0.007\n",
      "865/3300 (epoch 26), train_loss = -1.252, time/batch = 0.007\n",
      "866/3300 (epoch 26), train_loss = -2.154, time/batch = 0.006\n",
      "867/3300 (epoch 26), train_loss = -1.448, time/batch = 0.006\n",
      "868/3300 (epoch 26), train_loss = -3.139, time/batch = 0.006\n",
      "869/3300 (epoch 26), train_loss = -1.243, time/batch = 0.006\n",
      "870/3300 (epoch 26), train_loss = -3.450, time/batch = 0.006\n",
      "871/3300 (epoch 26), train_loss = -0.486, time/batch = 0.006\n",
      "872/3300 (epoch 26), train_loss = -3.316, time/batch = 0.007\n",
      "873/3300 (epoch 26), train_loss = -1.489, time/batch = 0.006\n",
      "874/3300 (epoch 26), train_loss = -3.206, time/batch = 0.006\n",
      "875/3300 (epoch 26), train_loss = -0.752, time/batch = 0.006\n",
      "876/3300 (epoch 26), train_loss = -3.584, time/batch = 0.006\n",
      "877/3300 (epoch 26), train_loss = 0.260, time/batch = 0.006\n",
      "878/3300 (epoch 26), train_loss = -3.216, time/batch = 0.006\n",
      "879/3300 (epoch 26), train_loss = -2.024, time/batch = 0.007\n",
      "880/3300 (epoch 26), train_loss = -3.259, time/batch = 0.006\n",
      "881/3300 (epoch 26), train_loss = -3.121, time/batch = 0.006\n",
      "882/3300 (epoch 26), train_loss = -3.106, time/batch = 0.007\n",
      "883/3300 (epoch 26), train_loss = -3.592, time/batch = 0.006\n",
      "884/3300 (epoch 26), train_loss = -3.155, time/batch = 0.009\n",
      "885/3300 (epoch 26), train_loss = -3.183, time/batch = 0.006\n",
      "886/3300 (epoch 26), train_loss = -2.061, time/batch = 0.006\n",
      "887/3300 (epoch 26), train_loss = -2.683, time/batch = 0.006\n",
      "888/3300 (epoch 26), train_loss = -2.964, time/batch = 0.006\n",
      "889/3300 (epoch 26), train_loss = -3.468, time/batch = 0.007\n",
      "890/3300 (epoch 26), train_loss = -3.015, time/batch = 0.007\n",
      "891/3300 (epoch 27), train_loss = -0.503, time/batch = 0.006\n",
      "892/3300 (epoch 27), train_loss = -1.554, time/batch = 0.007\n",
      "893/3300 (epoch 27), train_loss = -2.421, time/batch = 0.018\n",
      "894/3300 (epoch 27), train_loss = -1.475, time/batch = 0.008\n",
      "895/3300 (epoch 27), train_loss = -2.708, time/batch = 0.007\n",
      "896/3300 (epoch 27), train_loss = -1.502, time/batch = 0.007\n",
      "897/3300 (epoch 27), train_loss = -2.586, time/batch = 0.006\n",
      "898/3300 (epoch 27), train_loss = -0.701, time/batch = 0.006\n",
      "899/3300 (epoch 27), train_loss = -3.353, time/batch = 0.007\n",
      "900/3300 (epoch 27), train_loss = -2.172, time/batch = 0.007\n",
      "901/3300 (epoch 27), train_loss = -3.143, time/batch = 0.006\n",
      "902/3300 (epoch 27), train_loss = -2.684, time/batch = 0.006\n",
      "903/3300 (epoch 27), train_loss = -2.999, time/batch = 0.006\n",
      "904/3300 (epoch 27), train_loss = -1.737, time/batch = 0.006\n",
      "905/3300 (epoch 27), train_loss = -3.537, time/batch = 0.006\n",
      "906/3300 (epoch 27), train_loss = -2.593, time/batch = 0.006\n",
      "907/3300 (epoch 27), train_loss = -2.895, time/batch = 0.006\n",
      "908/3300 (epoch 27), train_loss = -1.572, time/batch = 0.006\n",
      "909/3300 (epoch 27), train_loss = -3.019, time/batch = 0.006\n",
      "910/3300 (epoch 27), train_loss = -2.629, time/batch = 0.006\n",
      "911/3300 (epoch 27), train_loss = -3.047, time/batch = 0.006\n",
      "912/3300 (epoch 27), train_loss = -1.946, time/batch = 0.006\n",
      "913/3300 (epoch 27), train_loss = -3.362, time/batch = 0.006\n",
      "914/3300 (epoch 27), train_loss = -2.259, time/batch = 0.006\n",
      "915/3300 (epoch 27), train_loss = -3.646, time/batch = 0.006\n",
      "916/3300 (epoch 27), train_loss = -3.123, time/batch = 0.006\n",
      "917/3300 (epoch 27), train_loss = -3.616, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918/3300 (epoch 27), train_loss = -2.945, time/batch = 0.006\n",
      "919/3300 (epoch 27), train_loss = -2.792, time/batch = 0.006\n",
      "920/3300 (epoch 27), train_loss = -1.964, time/batch = 0.006\n",
      "921/3300 (epoch 27), train_loss = -3.418, time/batch = 0.006\n",
      "922/3300 (epoch 27), train_loss = -2.991, time/batch = 0.006\n",
      "923/3300 (epoch 27), train_loss = -3.465, time/batch = 0.006\n",
      "924/3300 (epoch 28), train_loss = -0.526, time/batch = 0.006\n",
      "925/3300 (epoch 28), train_loss = -1.519, time/batch = 0.006\n",
      "926/3300 (epoch 28), train_loss = -2.318, time/batch = 0.006\n",
      "927/3300 (epoch 28), train_loss = -1.470, time/batch = 0.006\n",
      "928/3300 (epoch 28), train_loss = -2.259, time/batch = 0.007\n",
      "929/3300 (epoch 28), train_loss = -1.505, time/batch = 0.006\n",
      "930/3300 (epoch 28), train_loss = -2.860, time/batch = 0.006\n",
      "931/3300 (epoch 28), train_loss = -1.704, time/batch = 0.007\n",
      "932/3300 (epoch 28), train_loss = -3.458, time/batch = 0.007\n",
      "933/3300 (epoch 28), train_loss = -2.724, time/batch = 0.007\n",
      "934/3300 (epoch 28), train_loss = -2.704, time/batch = 0.006\n",
      "935/3300 (epoch 28), train_loss = -2.072, time/batch = 0.006\n",
      "936/3300 (epoch 28), train_loss = -2.397, time/batch = 0.006\n",
      "937/3300 (epoch 28), train_loss = -3.243, time/batch = 0.007\n",
      "938/3300 (epoch 28), train_loss = -3.525, time/batch = 0.007\n",
      "939/3300 (epoch 28), train_loss = -2.360, time/batch = 0.007\n",
      "940/3300 (epoch 28), train_loss = -2.998, time/batch = 0.007\n",
      "941/3300 (epoch 28), train_loss = -2.104, time/batch = 0.006\n",
      "942/3300 (epoch 28), train_loss = -3.285, time/batch = 0.007\n",
      "943/3300 (epoch 28), train_loss = -2.653, time/batch = 0.006\n",
      "944/3300 (epoch 28), train_loss = -2.969, time/batch = 0.006\n",
      "945/3300 (epoch 28), train_loss = -2.947, time/batch = 0.006\n",
      "946/3300 (epoch 28), train_loss = -3.311, time/batch = 0.006\n",
      "947/3300 (epoch 28), train_loss = -3.787, time/batch = 0.006\n",
      "948/3300 (epoch 28), train_loss = -3.264, time/batch = 0.008\n",
      "949/3300 (epoch 28), train_loss = -3.455, time/batch = 0.007\n",
      "950/3300 (epoch 28), train_loss = -3.771, time/batch = 0.006\n",
      "951/3300 (epoch 28), train_loss = -3.586, time/batch = 0.006\n",
      "952/3300 (epoch 28), train_loss = -3.934, time/batch = 0.006\n",
      "953/3300 (epoch 28), train_loss = -3.563, time/batch = 0.009\n",
      "954/3300 (epoch 28), train_loss = -3.147, time/batch = 0.008\n",
      "955/3300 (epoch 28), train_loss = -2.581, time/batch = 0.007\n",
      "956/3300 (epoch 28), train_loss = -1.343, time/batch = 0.007\n",
      "957/3300 (epoch 29), train_loss = -0.657, time/batch = 0.006\n",
      "958/3300 (epoch 29), train_loss = -1.518, time/batch = 0.006\n",
      "959/3300 (epoch 29), train_loss = -2.555, time/batch = 0.007\n",
      "960/3300 (epoch 29), train_loss = -2.730, time/batch = 0.006\n",
      "961/3300 (epoch 29), train_loss = -1.514, time/batch = 0.006\n",
      "962/3300 (epoch 29), train_loss = -2.569, time/batch = 0.006\n",
      "963/3300 (epoch 29), train_loss = -1.334, time/batch = 0.006\n",
      "964/3300 (epoch 29), train_loss = -2.621, time/batch = 0.009\n",
      "965/3300 (epoch 29), train_loss = 1.417, time/batch = 0.008\n",
      "966/3300 (epoch 29), train_loss = -2.741, time/batch = 0.006\n",
      "967/3300 (epoch 29), train_loss = -0.921, time/batch = 0.007\n",
      "968/3300 (epoch 29), train_loss = -2.764, time/batch = 0.007\n",
      "969/3300 (epoch 29), train_loss = -0.531, time/batch = 0.006\n",
      "970/3300 (epoch 29), train_loss = -2.987, time/batch = 0.006\n",
      "971/3300 (epoch 29), train_loss = -1.004, time/batch = 0.006\n",
      "972/3300 (epoch 29), train_loss = -3.114, time/batch = 0.006\n",
      "973/3300 (epoch 29), train_loss = -1.944, time/batch = 0.006\n",
      "974/3300 (epoch 29), train_loss = -3.491, time/batch = 0.008\n",
      "975/3300 (epoch 29), train_loss = -1.871, time/batch = 0.006\n",
      "976/3300 (epoch 29), train_loss = -3.043, time/batch = 0.007\n",
      "977/3300 (epoch 29), train_loss = -3.032, time/batch = 0.007\n",
      "978/3300 (epoch 29), train_loss = -2.688, time/batch = 0.006\n",
      "979/3300 (epoch 29), train_loss = -3.555, time/batch = 0.006\n",
      "980/3300 (epoch 29), train_loss = -3.206, time/batch = 0.007\n",
      "981/3300 (epoch 29), train_loss = -3.141, time/batch = 0.006\n",
      "982/3300 (epoch 29), train_loss = -3.045, time/batch = 0.006\n",
      "983/3300 (epoch 29), train_loss = -3.800, time/batch = 0.007\n",
      "984/3300 (epoch 29), train_loss = -3.066, time/batch = 0.010\n",
      "985/3300 (epoch 29), train_loss = -3.330, time/batch = 0.008\n",
      "986/3300 (epoch 29), train_loss = -2.806, time/batch = 0.007\n",
      "987/3300 (epoch 29), train_loss = -3.414, time/batch = 0.008\n",
      "988/3300 (epoch 29), train_loss = -2.914, time/batch = 0.006\n",
      "989/3300 (epoch 29), train_loss = -3.452, time/batch = 0.006\n",
      "990/3300 (epoch 30), train_loss = -0.587, time/batch = 0.006\n",
      "991/3300 (epoch 30), train_loss = -1.873, time/batch = 0.006\n",
      "992/3300 (epoch 30), train_loss = -2.402, time/batch = 0.006\n",
      "993/3300 (epoch 30), train_loss = -1.717, time/batch = 0.006\n",
      "994/3300 (epoch 30), train_loss = -2.217, time/batch = 0.006\n",
      "995/3300 (epoch 30), train_loss = -2.260, time/batch = 0.006\n",
      "996/3300 (epoch 30), train_loss = -1.362, time/batch = 0.006\n",
      "997/3300 (epoch 30), train_loss = -2.037, time/batch = 0.006\n",
      "998/3300 (epoch 30), train_loss = -2.834, time/batch = 0.006\n",
      "999/3300 (epoch 30), train_loss = -2.790, time/batch = 0.006\n",
      "1000/3300 (epoch 30), train_loss = -1.321, time/batch = 0.006\n",
      "1001/3300 (epoch 30), train_loss = -3.448, time/batch = 0.006\n",
      "1002/3300 (epoch 30), train_loss = -0.434, time/batch = 0.006\n",
      "1003/3300 (epoch 30), train_loss = -3.213, time/batch = 0.007\n",
      "1004/3300 (epoch 30), train_loss = -2.114, time/batch = 0.007\n",
      "1005/3300 (epoch 30), train_loss = -3.335, time/batch = 0.006\n",
      "1006/3300 (epoch 30), train_loss = -1.546, time/batch = 0.006\n",
      "1007/3300 (epoch 30), train_loss = -3.629, time/batch = 0.006\n",
      "1008/3300 (epoch 30), train_loss = -3.116, time/batch = 0.006\n",
      "1009/3300 (epoch 30), train_loss = -3.392, time/batch = 0.006\n",
      "1010/3300 (epoch 30), train_loss = -0.856, time/batch = 0.007\n",
      "1011/3300 (epoch 30), train_loss = -3.206, time/batch = 0.008\n",
      "1012/3300 (epoch 30), train_loss = -3.024, time/batch = 0.006\n",
      "1013/3300 (epoch 30), train_loss = -2.990, time/batch = 0.006\n",
      "1014/3300 (epoch 30), train_loss = -3.190, time/batch = 0.006\n",
      "1015/3300 (epoch 30), train_loss = -3.598, time/batch = 0.006\n",
      "1016/3300 (epoch 30), train_loss = -3.480, time/batch = 0.006\n",
      "1017/3300 (epoch 30), train_loss = -3.098, time/batch = 0.006\n",
      "1018/3300 (epoch 30), train_loss = -2.727, time/batch = 0.006\n",
      "1019/3300 (epoch 30), train_loss = -3.435, time/batch = 0.006\n",
      "1020/3300 (epoch 30), train_loss = -3.473, time/batch = 0.006\n",
      "1021/3300 (epoch 30), train_loss = -3.203, time/batch = 0.006\n",
      "1022/3300 (epoch 30), train_loss = -3.337, time/batch = 0.006\n",
      "1023/3300 (epoch 31), train_loss = -0.648, time/batch = 0.006\n",
      "1024/3300 (epoch 31), train_loss = -1.890, time/batch = 0.006\n",
      "1025/3300 (epoch 31), train_loss = -1.994, time/batch = 0.006\n",
      "1026/3300 (epoch 31), train_loss = -2.199, time/batch = 0.007\n",
      "1027/3300 (epoch 31), train_loss = -2.942, time/batch = 0.006\n",
      "1028/3300 (epoch 31), train_loss = -1.794, time/batch = 0.006\n",
      "1029/3300 (epoch 31), train_loss = -2.888, time/batch = 0.006\n",
      "1030/3300 (epoch 31), train_loss = -1.712, time/batch = 0.006\n",
      "1031/3300 (epoch 31), train_loss = -2.952, time/batch = 0.006\n",
      "1032/3300 (epoch 31), train_loss = -2.695, time/batch = 0.006\n",
      "1033/3300 (epoch 31), train_loss = -2.897, time/batch = 0.006\n",
      "1034/3300 (epoch 31), train_loss = -2.798, time/batch = 0.006\n",
      "1035/3300 (epoch 31), train_loss = -2.820, time/batch = 0.007\n",
      "1036/3300 (epoch 31), train_loss = -2.968, time/batch = 0.007\n",
      "1037/3300 (epoch 31), train_loss = -2.463, time/batch = 0.006\n",
      "1038/3300 (epoch 31), train_loss = -3.490, time/batch = 0.006\n",
      "1039/3300 (epoch 31), train_loss = -3.436, time/batch = 0.006\n",
      "1040/3300 (epoch 31), train_loss = -3.531, time/batch = 0.006\n",
      "1041/3300 (epoch 31), train_loss = -2.875, time/batch = 0.006\n",
      "1042/3300 (epoch 31), train_loss = -3.160, time/batch = 0.006\n",
      "1043/3300 (epoch 31), train_loss = -3.324, time/batch = 0.006\n",
      "1044/3300 (epoch 31), train_loss = -3.118, time/batch = 0.006\n",
      "1045/3300 (epoch 31), train_loss = -2.324, time/batch = 0.006\n",
      "1046/3300 (epoch 31), train_loss = -3.535, time/batch = 0.006\n",
      "1047/3300 (epoch 31), train_loss = -3.438, time/batch = 0.006\n",
      "1048/3300 (epoch 31), train_loss = -3.415, time/batch = 0.006\n",
      "1049/3300 (epoch 31), train_loss = -2.909, time/batch = 0.007\n",
      "1050/3300 (epoch 31), train_loss = -3.320, time/batch = 0.006\n",
      "1051/3300 (epoch 31), train_loss = -3.551, time/batch = 0.006\n",
      "1052/3300 (epoch 31), train_loss = -3.589, time/batch = 0.007\n",
      "1053/3300 (epoch 31), train_loss = -3.215, time/batch = 0.006\n",
      "1054/3300 (epoch 31), train_loss = -3.548, time/batch = 0.006\n",
      "1055/3300 (epoch 31), train_loss = -3.365, time/batch = 0.006\n",
      "1056/3300 (epoch 32), train_loss = -0.851, time/batch = 0.006\n",
      "1057/3300 (epoch 32), train_loss = -1.421, time/batch = 0.006\n",
      "1058/3300 (epoch 32), train_loss = -2.342, time/batch = 0.006\n",
      "1059/3300 (epoch 32), train_loss = -1.901, time/batch = 0.006\n",
      "1060/3300 (epoch 32), train_loss = -2.511, time/batch = 0.006\n",
      "1061/3300 (epoch 32), train_loss = -0.956, time/batch = 0.006\n",
      "1062/3300 (epoch 32), train_loss = -3.013, time/batch = 0.006\n",
      "1063/3300 (epoch 32), train_loss = -1.627, time/batch = 0.006\n",
      "1064/3300 (epoch 32), train_loss = -3.620, time/batch = 0.006\n",
      "1065/3300 (epoch 32), train_loss = -1.946, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/3300 (epoch 32), train_loss = -3.457, time/batch = 0.007\n",
      "1067/3300 (epoch 32), train_loss = -2.754, time/batch = 0.006\n",
      "1068/3300 (epoch 32), train_loss = -3.051, time/batch = 0.006\n",
      "1069/3300 (epoch 32), train_loss = -2.261, time/batch = 0.006\n",
      "1070/3300 (epoch 32), train_loss = -3.662, time/batch = 0.006\n",
      "1071/3300 (epoch 32), train_loss = -2.516, time/batch = 0.006\n",
      "1072/3300 (epoch 32), train_loss = -3.793, time/batch = 0.006\n",
      "1073/3300 (epoch 32), train_loss = -2.209, time/batch = 0.006\n",
      "1074/3300 (epoch 32), train_loss = -3.588, time/batch = 0.006\n",
      "1075/3300 (epoch 32), train_loss = -1.703, time/batch = 0.013\n",
      "1076/3300 (epoch 32), train_loss = -3.570, time/batch = 0.007\n",
      "1077/3300 (epoch 32), train_loss = -1.869, time/batch = 0.007\n",
      "1078/3300 (epoch 32), train_loss = -3.702, time/batch = 0.006\n",
      "1079/3300 (epoch 32), train_loss = -2.305, time/batch = 0.006\n",
      "1080/3300 (epoch 32), train_loss = -3.940, time/batch = 0.006\n",
      "1081/3300 (epoch 32), train_loss = -3.548, time/batch = 0.006\n",
      "1082/3300 (epoch 32), train_loss = -4.122, time/batch = 0.006\n",
      "1083/3300 (epoch 32), train_loss = -2.162, time/batch = 0.006\n",
      "1084/3300 (epoch 32), train_loss = -3.715, time/batch = 0.006\n",
      "1085/3300 (epoch 32), train_loss = -1.907, time/batch = 0.006\n",
      "1086/3300 (epoch 32), train_loss = -3.904, time/batch = 0.006\n",
      "1087/3300 (epoch 32), train_loss = -1.989, time/batch = 0.006\n",
      "1088/3300 (epoch 32), train_loss = -3.408, time/batch = 0.006\n",
      "1089/3300 (epoch 33), train_loss = -0.759, time/batch = 0.005\n",
      "1090/3300 (epoch 33), train_loss = -1.690, time/batch = 0.006\n",
      "1091/3300 (epoch 33), train_loss = -2.437, time/batch = 0.006\n",
      "1092/3300 (epoch 33), train_loss = -2.422, time/batch = 0.007\n",
      "1093/3300 (epoch 33), train_loss = -2.416, time/batch = 0.007\n",
      "1094/3300 (epoch 33), train_loss = -2.795, time/batch = 0.006\n",
      "1095/3300 (epoch 33), train_loss = -2.332, time/batch = 0.007\n",
      "1096/3300 (epoch 33), train_loss = -2.621, time/batch = 0.007\n",
      "1097/3300 (epoch 33), train_loss = -2.603, time/batch = 0.006\n",
      "1098/3300 (epoch 33), train_loss = -3.522, time/batch = 0.007\n",
      "1099/3300 (epoch 33), train_loss = -2.577, time/batch = 0.006\n",
      "1100/3300 (epoch 33), train_loss = -2.968, time/batch = 0.011\n",
      "1101/3300 (epoch 33), train_loss = -2.590, time/batch = 0.006\n",
      "1102/3300 (epoch 33), train_loss = -3.583, time/batch = 0.007\n",
      "1103/3300 (epoch 33), train_loss = -2.846, time/batch = 0.006\n",
      "1104/3300 (epoch 33), train_loss = -3.221, time/batch = 0.009\n",
      "1105/3300 (epoch 33), train_loss = -2.395, time/batch = 0.006\n",
      "1106/3300 (epoch 33), train_loss = -3.510, time/batch = 0.006\n",
      "1107/3300 (epoch 33), train_loss = -2.745, time/batch = 0.006\n",
      "1108/3300 (epoch 33), train_loss = -3.403, time/batch = 0.006\n",
      "1109/3300 (epoch 33), train_loss = -3.336, time/batch = 0.006\n",
      "1110/3300 (epoch 33), train_loss = -3.433, time/batch = 0.007\n",
      "1111/3300 (epoch 33), train_loss = -3.409, time/batch = 0.006\n",
      "1112/3300 (epoch 33), train_loss = -3.489, time/batch = 0.007\n",
      "1113/3300 (epoch 33), train_loss = -2.846, time/batch = 0.006\n",
      "1114/3300 (epoch 33), train_loss = -4.154, time/batch = 0.006\n",
      "1115/3300 (epoch 33), train_loss = -2.884, time/batch = 0.007\n",
      "1116/3300 (epoch 33), train_loss = -3.776, time/batch = 0.006\n",
      "1117/3300 (epoch 33), train_loss = -2.090, time/batch = 0.006\n",
      "1118/3300 (epoch 33), train_loss = -3.748, time/batch = 0.006\n",
      "1119/3300 (epoch 33), train_loss = -2.937, time/batch = 0.006\n",
      "1120/3300 (epoch 33), train_loss = -3.414, time/batch = 0.006\n",
      "1121/3300 (epoch 33), train_loss = -2.502, time/batch = 0.006\n",
      "1122/3300 (epoch 34), train_loss = -0.784, time/batch = 0.006\n",
      "1123/3300 (epoch 34), train_loss = -1.790, time/batch = 0.007\n",
      "1124/3300 (epoch 34), train_loss = -2.461, time/batch = 0.006\n",
      "1125/3300 (epoch 34), train_loss = -1.943, time/batch = 0.007\n",
      "1126/3300 (epoch 34), train_loss = -2.886, time/batch = 0.006\n",
      "1127/3300 (epoch 34), train_loss = -1.900, time/batch = 0.006\n",
      "1128/3300 (epoch 34), train_loss = -2.907, time/batch = 0.006\n",
      "1129/3300 (epoch 34), train_loss = -2.634, time/batch = 0.006\n",
      "1130/3300 (epoch 34), train_loss = -3.543, time/batch = 0.006\n",
      "1131/3300 (epoch 34), train_loss = -1.118, time/batch = 0.006\n",
      "1132/3300 (epoch 34), train_loss = -3.409, time/batch = 0.006\n",
      "1133/3300 (epoch 34), train_loss = -2.296, time/batch = 0.006\n",
      "1134/3300 (epoch 34), train_loss = -3.803, time/batch = 0.006\n",
      "1135/3300 (epoch 34), train_loss = -2.736, time/batch = 0.006\n",
      "1136/3300 (epoch 34), train_loss = -3.568, time/batch = 0.006\n",
      "1137/3300 (epoch 34), train_loss = -3.240, time/batch = 0.006\n",
      "1138/3300 (epoch 34), train_loss = -2.805, time/batch = 0.006\n",
      "1139/3300 (epoch 34), train_loss = -3.431, time/batch = 0.006\n",
      "1140/3300 (epoch 34), train_loss = -3.610, time/batch = 0.006\n",
      "1141/3300 (epoch 34), train_loss = -2.883, time/batch = 0.006\n",
      "1142/3300 (epoch 34), train_loss = -3.840, time/batch = 0.006\n",
      "1143/3300 (epoch 34), train_loss = -2.824, time/batch = 0.006\n",
      "1144/3300 (epoch 34), train_loss = -4.133, time/batch = 0.006\n",
      "1145/3300 (epoch 34), train_loss = -3.904, time/batch = 0.006\n",
      "1146/3300 (epoch 34), train_loss = -4.162, time/batch = 0.006\n",
      "1147/3300 (epoch 34), train_loss = -3.952, time/batch = 0.006\n",
      "1148/3300 (epoch 34), train_loss = -4.204, time/batch = 0.006\n",
      "1149/3300 (epoch 34), train_loss = -4.024, time/batch = 0.006\n",
      "1150/3300 (epoch 34), train_loss = -4.203, time/batch = 0.006\n",
      "1151/3300 (epoch 34), train_loss = -3.480, time/batch = 0.006\n",
      "1152/3300 (epoch 34), train_loss = -2.993, time/batch = 0.006\n",
      "1153/3300 (epoch 34), train_loss = -3.042, time/batch = 0.006\n",
      "1154/3300 (epoch 34), train_loss = -3.829, time/batch = 0.006\n",
      "1155/3300 (epoch 35), train_loss = -0.871, time/batch = 0.006\n",
      "1156/3300 (epoch 35), train_loss = -1.607, time/batch = 0.006\n",
      "1157/3300 (epoch 35), train_loss = -2.510, time/batch = 0.006\n",
      "1158/3300 (epoch 35), train_loss = -1.883, time/batch = 0.006\n",
      "1159/3300 (epoch 35), train_loss = -2.159, time/batch = 0.006\n",
      "1160/3300 (epoch 35), train_loss = -2.478, time/batch = 0.006\n",
      "1161/3300 (epoch 35), train_loss = -2.427, time/batch = 0.007\n",
      "1162/3300 (epoch 35), train_loss = -3.280, time/batch = 0.006\n",
      "1163/3300 (epoch 35), train_loss = -2.383, time/batch = 0.006\n",
      "1164/3300 (epoch 35), train_loss = -3.011, time/batch = 0.006\n",
      "1165/3300 (epoch 35), train_loss = -2.774, time/batch = 0.006\n",
      "1166/3300 (epoch 35), train_loss = -2.592, time/batch = 0.006\n",
      "1167/3300 (epoch 35), train_loss = -2.957, time/batch = 0.006\n",
      "1168/3300 (epoch 35), train_loss = -3.237, time/batch = 0.006\n",
      "1169/3300 (epoch 35), train_loss = -3.317, time/batch = 0.006\n",
      "1170/3300 (epoch 35), train_loss = -2.545, time/batch = 0.006\n",
      "1171/3300 (epoch 35), train_loss = -3.338, time/batch = 0.006\n",
      "1172/3300 (epoch 35), train_loss = -2.719, time/batch = 0.006\n",
      "1173/3300 (epoch 35), train_loss = -3.481, time/batch = 0.006\n",
      "1174/3300 (epoch 35), train_loss = -3.538, time/batch = 0.006\n",
      "1175/3300 (epoch 35), train_loss = -3.347, time/batch = 0.006\n",
      "1176/3300 (epoch 35), train_loss = -3.657, time/batch = 0.006\n",
      "1177/3300 (epoch 35), train_loss = -3.923, time/batch = 0.006\n",
      "1178/3300 (epoch 35), train_loss = -3.917, time/batch = 0.006\n",
      "1179/3300 (epoch 35), train_loss = -2.976, time/batch = 0.006\n",
      "1180/3300 (epoch 35), train_loss = -3.069, time/batch = 0.006\n",
      "1181/3300 (epoch 35), train_loss = -3.756, time/batch = 0.006\n",
      "1182/3300 (epoch 35), train_loss = -2.958, time/batch = 0.007\n",
      "1183/3300 (epoch 35), train_loss = -4.252, time/batch = 0.007\n",
      "1184/3300 (epoch 35), train_loss = -3.063, time/batch = 0.006\n",
      "1185/3300 (epoch 35), train_loss = -4.408, time/batch = 0.006\n",
      "1186/3300 (epoch 35), train_loss = -2.563, time/batch = 0.006\n",
      "1187/3300 (epoch 35), train_loss = -3.608, time/batch = 0.006\n",
      "1188/3300 (epoch 36), train_loss = -0.865, time/batch = 0.006\n",
      "1189/3300 (epoch 36), train_loss = -1.703, time/batch = 0.006\n",
      "1190/3300 (epoch 36), train_loss = -2.413, time/batch = 0.006\n",
      "1191/3300 (epoch 36), train_loss = -1.884, time/batch = 0.006\n",
      "1192/3300 (epoch 36), train_loss = -2.607, time/batch = 0.006\n",
      "1193/3300 (epoch 36), train_loss = -3.101, time/batch = 0.006\n",
      "1194/3300 (epoch 36), train_loss = -0.890, time/batch = 0.007\n",
      "1195/3300 (epoch 36), train_loss = -2.728, time/batch = 0.006\n",
      "1196/3300 (epoch 36), train_loss = -2.416, time/batch = 0.006\n",
      "1197/3300 (epoch 36), train_loss = -3.324, time/batch = 0.006\n",
      "1198/3300 (epoch 36), train_loss = -1.106, time/batch = 0.007\n",
      "1199/3300 (epoch 36), train_loss = -3.273, time/batch = 0.006\n",
      "1200/3300 (epoch 36), train_loss = -1.978, time/batch = 0.007\n",
      "1201/3300 (epoch 36), train_loss = -3.894, time/batch = 0.006\n",
      "1202/3300 (epoch 36), train_loss = -2.695, time/batch = 0.007\n",
      "1203/3300 (epoch 36), train_loss = -3.531, time/batch = 0.007\n",
      "1204/3300 (epoch 36), train_loss = -2.725, time/batch = 0.007\n",
      "1205/3300 (epoch 36), train_loss = -3.597, time/batch = 0.006\n",
      "1206/3300 (epoch 36), train_loss = -3.018, time/batch = 0.008\n",
      "1207/3300 (epoch 36), train_loss = -3.625, time/batch = 0.006\n",
      "1208/3300 (epoch 36), train_loss = -2.873, time/batch = 0.006\n",
      "1209/3300 (epoch 36), train_loss = -3.756, time/batch = 0.007\n",
      "1210/3300 (epoch 36), train_loss = -3.370, time/batch = 0.006\n",
      "1211/3300 (epoch 36), train_loss = -2.862, time/batch = 0.006\n",
      "1212/3300 (epoch 36), train_loss = -3.949, time/batch = 0.007\n",
      "1213/3300 (epoch 36), train_loss = -3.990, time/batch = 0.007\n",
      "1214/3300 (epoch 36), train_loss = -3.536, time/batch = 0.006\n",
      "1215/3300 (epoch 36), train_loss = -3.879, time/batch = 0.006\n",
      "1216/3300 (epoch 36), train_loss = -2.964, time/batch = 0.006\n",
      "1217/3300 (epoch 36), train_loss = -3.792, time/batch = 0.006\n",
      "1218/3300 (epoch 36), train_loss = -3.589, time/batch = 0.006\n",
      "1219/3300 (epoch 36), train_loss = -4.157, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/3300 (epoch 36), train_loss = -3.521, time/batch = 0.006\n",
      "1221/3300 (epoch 37), train_loss = -0.914, time/batch = 0.006\n",
      "1222/3300 (epoch 37), train_loss = -1.855, time/batch = 0.006\n",
      "1223/3300 (epoch 37), train_loss = -2.532, time/batch = 0.006\n",
      "1224/3300 (epoch 37), train_loss = -1.986, time/batch = 0.006\n",
      "1225/3300 (epoch 37), train_loss = -2.519, time/batch = 0.006\n",
      "1226/3300 (epoch 37), train_loss = -2.393, time/batch = 0.006\n",
      "1227/3300 (epoch 37), train_loss = -2.827, time/batch = 0.006\n",
      "1228/3300 (epoch 37), train_loss = -2.426, time/batch = 0.006\n",
      "1229/3300 (epoch 37), train_loss = -3.305, time/batch = 0.006\n",
      "1230/3300 (epoch 37), train_loss = -2.487, time/batch = 0.006\n",
      "1231/3300 (epoch 37), train_loss = -2.377, time/batch = 0.006\n",
      "1232/3300 (epoch 37), train_loss = -3.367, time/batch = 0.006\n",
      "1233/3300 (epoch 37), train_loss = -3.080, time/batch = 0.006\n",
      "1234/3300 (epoch 37), train_loss = -3.327, time/batch = 0.006\n",
      "1235/3300 (epoch 37), train_loss = -2.852, time/batch = 0.006\n",
      "1236/3300 (epoch 37), train_loss = -4.124, time/batch = 0.006\n",
      "1237/3300 (epoch 37), train_loss = 0.091, time/batch = 0.006\n",
      "1238/3300 (epoch 37), train_loss = -3.575, time/batch = 0.006\n",
      "1239/3300 (epoch 37), train_loss = -2.700, time/batch = 0.007\n",
      "1240/3300 (epoch 37), train_loss = -3.679, time/batch = 0.006\n",
      "1241/3300 (epoch 37), train_loss = -2.497, time/batch = 0.006\n",
      "1242/3300 (epoch 37), train_loss = -3.608, time/batch = 0.006\n",
      "1243/3300 (epoch 37), train_loss = -3.154, time/batch = 0.006\n",
      "1244/3300 (epoch 37), train_loss = -4.092, time/batch = 0.006\n",
      "1245/3300 (epoch 37), train_loss = -3.623, time/batch = 0.006\n",
      "1246/3300 (epoch 37), train_loss = -3.582, time/batch = 0.006\n",
      "1247/3300 (epoch 37), train_loss = -3.068, time/batch = 0.006\n",
      "1248/3300 (epoch 37), train_loss = -3.883, time/batch = 0.006\n",
      "1249/3300 (epoch 37), train_loss = -3.832, time/batch = 0.006\n",
      "1250/3300 (epoch 37), train_loss = -3.595, time/batch = 0.006\n",
      "1251/3300 (epoch 37), train_loss = -3.488, time/batch = 0.006\n",
      "1252/3300 (epoch 37), train_loss = -2.625, time/batch = 0.006\n",
      "1253/3300 (epoch 37), train_loss = -3.623, time/batch = 0.006\n",
      "1254/3300 (epoch 38), train_loss = -0.930, time/batch = 0.006\n",
      "1255/3300 (epoch 38), train_loss = -1.696, time/batch = 0.006\n",
      "1256/3300 (epoch 38), train_loss = -2.509, time/batch = 0.006\n",
      "1257/3300 (epoch 38), train_loss = -2.663, time/batch = 0.006\n",
      "1258/3300 (epoch 38), train_loss = -1.561, time/batch = 0.007\n",
      "1259/3300 (epoch 38), train_loss = -3.205, time/batch = 0.006\n",
      "1260/3300 (epoch 38), train_loss = -1.488, time/batch = 0.006\n",
      "1261/3300 (epoch 38), train_loss = -3.417, time/batch = 0.006\n",
      "1262/3300 (epoch 38), train_loss = -1.274, time/batch = 0.006\n",
      "1263/3300 (epoch 38), train_loss = -3.762, time/batch = 0.006\n",
      "1264/3300 (epoch 38), train_loss = -3.255, time/batch = 0.006\n",
      "1265/3300 (epoch 38), train_loss = -3.302, time/batch = 0.006\n",
      "1266/3300 (epoch 38), train_loss = -2.911, time/batch = 0.006\n",
      "1267/3300 (epoch 38), train_loss = -2.870, time/batch = 0.006\n",
      "1268/3300 (epoch 38), train_loss = -3.557, time/batch = 0.006\n",
      "1269/3300 (epoch 38), train_loss = -3.121, time/batch = 0.006\n",
      "1270/3300 (epoch 38), train_loss = -2.710, time/batch = 0.006\n",
      "1271/3300 (epoch 38), train_loss = -2.514, time/batch = 0.006\n",
      "1272/3300 (epoch 38), train_loss = -2.621, time/batch = 0.006\n",
      "1273/3300 (epoch 38), train_loss = -3.801, time/batch = 0.006\n",
      "1274/3300 (epoch 38), train_loss = -2.430, time/batch = 0.006\n",
      "1275/3300 (epoch 38), train_loss = -3.764, time/batch = 0.006\n",
      "1276/3300 (epoch 38), train_loss = -2.814, time/batch = 0.006\n",
      "1277/3300 (epoch 38), train_loss = -3.309, time/batch = 0.006\n",
      "1278/3300 (epoch 38), train_loss = -3.775, time/batch = 0.006\n",
      "1279/3300 (epoch 38), train_loss = -3.854, time/batch = 0.007\n",
      "1280/3300 (epoch 38), train_loss = -3.300, time/batch = 0.006\n",
      "1281/3300 (epoch 38), train_loss = -3.595, time/batch = 0.006\n",
      "1282/3300 (epoch 38), train_loss = -3.228, time/batch = 0.006\n",
      "1283/3300 (epoch 38), train_loss = -3.836, time/batch = 0.006\n",
      "1284/3300 (epoch 38), train_loss = -3.016, time/batch = 0.006\n",
      "1285/3300 (epoch 38), train_loss = -3.785, time/batch = 0.006\n",
      "1286/3300 (epoch 38), train_loss = -2.658, time/batch = 0.006\n",
      "1287/3300 (epoch 39), train_loss = -0.869, time/batch = 0.006\n",
      "1288/3300 (epoch 39), train_loss = -1.851, time/batch = 0.007\n",
      "1289/3300 (epoch 39), train_loss = -2.591, time/batch = 0.006\n",
      "1290/3300 (epoch 39), train_loss = -1.425, time/batch = 0.006\n",
      "1291/3300 (epoch 39), train_loss = -1.454, time/batch = 0.006\n",
      "1292/3300 (epoch 39), train_loss = -2.942, time/batch = 0.006\n",
      "1293/3300 (epoch 39), train_loss = -2.947, time/batch = 0.006\n",
      "1294/3300 (epoch 39), train_loss = -3.016, time/batch = 0.006\n",
      "1295/3300 (epoch 39), train_loss = -1.644, time/batch = 0.006\n",
      "1296/3300 (epoch 39), train_loss = -3.643, time/batch = 0.006\n",
      "1297/3300 (epoch 39), train_loss = -2.846, time/batch = 0.006\n",
      "1298/3300 (epoch 39), train_loss = -2.835, time/batch = 0.006\n",
      "1299/3300 (epoch 39), train_loss = -2.920, time/batch = 0.006\n",
      "1300/3300 (epoch 39), train_loss = -3.476, time/batch = 0.006\n",
      "1301/3300 (epoch 39), train_loss = -2.768, time/batch = 0.006\n",
      "1302/3300 (epoch 39), train_loss = -3.222, time/batch = 0.006\n",
      "1303/3300 (epoch 39), train_loss = -3.413, time/batch = 0.006\n",
      "1304/3300 (epoch 39), train_loss = -3.927, time/batch = 0.006\n",
      "1305/3300 (epoch 39), train_loss = -2.515, time/batch = 0.006\n",
      "1306/3300 (epoch 39), train_loss = -3.613, time/batch = 0.006\n",
      "1307/3300 (epoch 39), train_loss = -3.454, time/batch = 0.006\n",
      "1308/3300 (epoch 39), train_loss = -3.741, time/batch = 0.006\n",
      "1309/3300 (epoch 39), train_loss = -3.495, time/batch = 0.006\n",
      "1310/3300 (epoch 39), train_loss = -3.644, time/batch = 0.006\n",
      "1311/3300 (epoch 39), train_loss = -4.069, time/batch = 0.006\n",
      "1312/3300 (epoch 39), train_loss = -3.973, time/batch = 0.006\n",
      "1313/3300 (epoch 39), train_loss = -3.517, time/batch = 0.007\n",
      "1314/3300 (epoch 39), train_loss = -3.093, time/batch = 0.006\n",
      "1315/3300 (epoch 39), train_loss = -3.956, time/batch = 0.006\n",
      "1316/3300 (epoch 39), train_loss = -4.344, time/batch = 0.006\n",
      "1317/3300 (epoch 39), train_loss = -3.826, time/batch = 0.006\n",
      "1318/3300 (epoch 39), train_loss = -3.231, time/batch = 0.006\n",
      "1319/3300 (epoch 39), train_loss = -3.733, time/batch = 0.007\n",
      "1320/3300 (epoch 40), train_loss = -0.901, time/batch = 0.006\n",
      "1321/3300 (epoch 40), train_loss = -2.020, time/batch = 0.008\n",
      "1322/3300 (epoch 40), train_loss = -2.636, time/batch = 0.007\n",
      "1323/3300 (epoch 40), train_loss = -1.564, time/batch = 0.007\n",
      "1324/3300 (epoch 40), train_loss = -2.311, time/batch = 0.007\n",
      "1325/3300 (epoch 40), train_loss = -2.940, time/batch = 0.006\n",
      "1326/3300 (epoch 40), train_loss = -2.165, time/batch = 0.006\n",
      "1327/3300 (epoch 40), train_loss = -3.010, time/batch = 0.006\n",
      "1328/3300 (epoch 40), train_loss = -2.772, time/batch = 0.006\n",
      "1329/3300 (epoch 40), train_loss = -3.476, time/batch = 0.006\n",
      "1330/3300 (epoch 40), train_loss = -2.346, time/batch = 0.006\n",
      "1331/3300 (epoch 40), train_loss = -3.515, time/batch = 0.006\n",
      "1332/3300 (epoch 40), train_loss = -2.788, time/batch = 0.006\n",
      "1333/3300 (epoch 40), train_loss = -3.866, time/batch = 0.006\n",
      "1334/3300 (epoch 40), train_loss = -2.264, time/batch = 0.006\n",
      "1335/3300 (epoch 40), train_loss = -3.210, time/batch = 0.006\n",
      "1336/3300 (epoch 40), train_loss = -2.543, time/batch = 0.006\n",
      "1337/3300 (epoch 40), train_loss = -3.638, time/batch = 0.006\n",
      "1338/3300 (epoch 40), train_loss = -3.611, time/batch = 0.006\n",
      "1339/3300 (epoch 40), train_loss = -3.340, time/batch = 0.006\n",
      "1340/3300 (epoch 40), train_loss = -3.665, time/batch = 0.007\n",
      "1341/3300 (epoch 40), train_loss = -3.738, time/batch = 0.006\n",
      "1342/3300 (epoch 40), train_loss = -3.356, time/batch = 0.006\n",
      "1343/3300 (epoch 40), train_loss = -3.791, time/batch = 0.006\n",
      "1344/3300 (epoch 40), train_loss = -4.092, time/batch = 0.006\n",
      "1345/3300 (epoch 40), train_loss = -4.180, time/batch = 0.006\n",
      "1346/3300 (epoch 40), train_loss = -4.246, time/batch = 0.006\n",
      "1347/3300 (epoch 40), train_loss = -4.237, time/batch = 0.006\n",
      "1348/3300 (epoch 40), train_loss = -3.651, time/batch = 0.006\n",
      "1349/3300 (epoch 40), train_loss = -3.231, time/batch = 0.006\n",
      "1350/3300 (epoch 40), train_loss = -3.771, time/batch = 0.006\n",
      "1351/3300 (epoch 40), train_loss = -4.114, time/batch = 0.006\n",
      "1352/3300 (epoch 40), train_loss = -3.153, time/batch = 0.006\n",
      "1353/3300 (epoch 41), train_loss = -0.952, time/batch = 0.006\n",
      "1354/3300 (epoch 41), train_loss = -1.643, time/batch = 0.007\n",
      "1355/3300 (epoch 41), train_loss = -2.615, time/batch = 0.007\n",
      "1356/3300 (epoch 41), train_loss = -2.332, time/batch = 0.006\n",
      "1357/3300 (epoch 41), train_loss = -2.459, time/batch = 0.006\n",
      "1358/3300 (epoch 41), train_loss = -2.900, time/batch = 0.006\n",
      "1359/3300 (epoch 41), train_loss = -2.663, time/batch = 0.006\n",
      "1360/3300 (epoch 41), train_loss = -3.114, time/batch = 0.007\n",
      "1361/3300 (epoch 41), train_loss = -3.476, time/batch = 0.007\n",
      "1362/3300 (epoch 41), train_loss = -3.634, time/batch = 0.006\n",
      "1363/3300 (epoch 41), train_loss = -3.262, time/batch = 0.006\n",
      "1364/3300 (epoch 41), train_loss = -3.361, time/batch = 0.006\n",
      "1365/3300 (epoch 41), train_loss = -3.243, time/batch = 0.007\n",
      "1366/3300 (epoch 41), train_loss = -3.708, time/batch = 0.006\n",
      "1367/3300 (epoch 41), train_loss = -2.767, time/batch = 0.006\n",
      "1368/3300 (epoch 41), train_loss = -3.089, time/batch = 0.007\n",
      "1369/3300 (epoch 41), train_loss = -3.824, time/batch = 0.006\n",
      "1370/3300 (epoch 41), train_loss = -3.645, time/batch = 0.006\n",
      "1371/3300 (epoch 41), train_loss = -3.109, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372/3300 (epoch 41), train_loss = -3.730, time/batch = 0.006\n",
      "1373/3300 (epoch 41), train_loss = -3.047, time/batch = 0.006\n",
      "1374/3300 (epoch 41), train_loss = -3.523, time/batch = 0.008\n",
      "1375/3300 (epoch 41), train_loss = -3.428, time/batch = 0.008\n",
      "1376/3300 (epoch 41), train_loss = -4.339, time/batch = 0.008\n",
      "1377/3300 (epoch 41), train_loss = -3.573, time/batch = 0.008\n",
      "1378/3300 (epoch 41), train_loss = -4.535, time/batch = 0.007\n",
      "1379/3300 (epoch 41), train_loss = -3.500, time/batch = 0.006\n",
      "1380/3300 (epoch 41), train_loss = -4.631, time/batch = 0.006\n",
      "1381/3300 (epoch 41), train_loss = -3.518, time/batch = 0.006\n",
      "1382/3300 (epoch 41), train_loss = -3.896, time/batch = 0.006\n",
      "1383/3300 (epoch 41), train_loss = -3.698, time/batch = 0.006\n",
      "1384/3300 (epoch 41), train_loss = -4.286, time/batch = 0.006\n",
      "1385/3300 (epoch 41), train_loss = -4.229, time/batch = 0.006\n",
      "1386/3300 (epoch 42), train_loss = -0.976, time/batch = 0.006\n",
      "1387/3300 (epoch 42), train_loss = -2.099, time/batch = 0.006\n",
      "1388/3300 (epoch 42), train_loss = -2.496, time/batch = 0.006\n",
      "1389/3300 (epoch 42), train_loss = -1.654, time/batch = 0.007\n",
      "1390/3300 (epoch 42), train_loss = -2.802, time/batch = 0.006\n",
      "1391/3300 (epoch 42), train_loss = -2.362, time/batch = 0.007\n",
      "1392/3300 (epoch 42), train_loss = -2.496, time/batch = 0.006\n",
      "1393/3300 (epoch 42), train_loss = -3.497, time/batch = 0.006\n",
      "1394/3300 (epoch 42), train_loss = -4.059, time/batch = 0.006\n",
      "1395/3300 (epoch 42), train_loss = -3.471, time/batch = 0.006\n",
      "1396/3300 (epoch 42), train_loss = -3.426, time/batch = 0.006\n",
      "1397/3300 (epoch 42), train_loss = -3.294, time/batch = 0.006\n",
      "1398/3300 (epoch 42), train_loss = -3.124, time/batch = 0.006\n",
      "1399/3300 (epoch 42), train_loss = -3.942, time/batch = 0.006\n",
      "1400/3300 (epoch 42), train_loss = -2.792, time/batch = 0.006\n",
      "1401/3300 (epoch 42), train_loss = -3.733, time/batch = 0.006\n",
      "1402/3300 (epoch 42), train_loss = -2.576, time/batch = 0.006\n",
      "1403/3300 (epoch 42), train_loss = -4.049, time/batch = 0.006\n",
      "1404/3300 (epoch 42), train_loss = -3.192, time/batch = 0.008\n",
      "1405/3300 (epoch 42), train_loss = -3.748, time/batch = 0.006\n",
      "1406/3300 (epoch 42), train_loss = -3.204, time/batch = 0.006\n",
      "1407/3300 (epoch 42), train_loss = -3.960, time/batch = 0.006\n",
      "1408/3300 (epoch 42), train_loss = -3.472, time/batch = 0.006\n",
      "1409/3300 (epoch 42), train_loss = -4.390, time/batch = 0.006\n",
      "1410/3300 (epoch 42), train_loss = -4.020, time/batch = 0.006\n",
      "1411/3300 (epoch 42), train_loss = -4.563, time/batch = 0.006\n",
      "1412/3300 (epoch 42), train_loss = -4.059, time/batch = 0.006\n",
      "1413/3300 (epoch 42), train_loss = -4.488, time/batch = 0.006\n",
      "1414/3300 (epoch 42), train_loss = -2.706, time/batch = 0.006\n",
      "1415/3300 (epoch 42), train_loss = -3.774, time/batch = 0.006\n",
      "1416/3300 (epoch 42), train_loss = -3.681, time/batch = 0.006\n",
      "1417/3300 (epoch 42), train_loss = -4.044, time/batch = 0.006\n",
      "1418/3300 (epoch 42), train_loss = -3.879, time/batch = 0.006\n",
      "1419/3300 (epoch 43), train_loss = -1.053, time/batch = 0.005\n",
      "1420/3300 (epoch 43), train_loss = -1.837, time/batch = 0.007\n",
      "1421/3300 (epoch 43), train_loss = -2.573, time/batch = 0.006\n",
      "1422/3300 (epoch 43), train_loss = -1.973, time/batch = 0.006\n",
      "1423/3300 (epoch 43), train_loss = -2.453, time/batch = 0.006\n",
      "1424/3300 (epoch 43), train_loss = -2.795, time/batch = 0.006\n",
      "1425/3300 (epoch 43), train_loss = -1.734, time/batch = 0.006\n",
      "1426/3300 (epoch 43), train_loss = -2.946, time/batch = 0.006\n",
      "1427/3300 (epoch 43), train_loss = -3.587, time/batch = 0.006\n",
      "1428/3300 (epoch 43), train_loss = -3.621, time/batch = 0.006\n",
      "1429/3300 (epoch 43), train_loss = -3.435, time/batch = 0.006\n",
      "1430/3300 (epoch 43), train_loss = -3.780, time/batch = 0.007\n",
      "1431/3300 (epoch 43), train_loss = -2.873, time/batch = 0.006\n",
      "1432/3300 (epoch 43), train_loss = -3.713, time/batch = 0.007\n",
      "1433/3300 (epoch 43), train_loss = -3.191, time/batch = 0.006\n",
      "1434/3300 (epoch 43), train_loss = -4.052, time/batch = 0.007\n",
      "1435/3300 (epoch 43), train_loss = -2.952, time/batch = 0.006\n",
      "1436/3300 (epoch 43), train_loss = -3.809, time/batch = 0.006\n",
      "1437/3300 (epoch 43), train_loss = -1.800, time/batch = 0.006\n",
      "1438/3300 (epoch 43), train_loss = -3.888, time/batch = 0.006\n",
      "1439/3300 (epoch 43), train_loss = -3.181, time/batch = 0.006\n",
      "1440/3300 (epoch 43), train_loss = -3.759, time/batch = 0.006\n",
      "1441/3300 (epoch 43), train_loss = -3.658, time/batch = 0.006\n",
      "1442/3300 (epoch 43), train_loss = -3.236, time/batch = 0.006\n",
      "1443/3300 (epoch 43), train_loss = -4.101, time/batch = 0.006\n",
      "1444/3300 (epoch 43), train_loss = -3.721, time/batch = 0.006\n",
      "1445/3300 (epoch 43), train_loss = -3.822, time/batch = 0.006\n",
      "1446/3300 (epoch 43), train_loss = -3.179, time/batch = 0.006\n",
      "1447/3300 (epoch 43), train_loss = -3.864, time/batch = 0.006\n",
      "1448/3300 (epoch 43), train_loss = -3.411, time/batch = 0.006\n",
      "1449/3300 (epoch 43), train_loss = -3.926, time/batch = 0.006\n",
      "1450/3300 (epoch 43), train_loss = -3.803, time/batch = 0.006\n",
      "1451/3300 (epoch 43), train_loss = -2.781, time/batch = 0.006\n",
      "1452/3300 (epoch 44), train_loss = -0.924, time/batch = 0.005\n",
      "1453/3300 (epoch 44), train_loss = -2.190, time/batch = 0.006\n",
      "1454/3300 (epoch 44), train_loss = -2.458, time/batch = 0.009\n",
      "1455/3300 (epoch 44), train_loss = -1.654, time/batch = 0.007\n",
      "1456/3300 (epoch 44), train_loss = -2.176, time/batch = 0.008\n",
      "1457/3300 (epoch 44), train_loss = -2.849, time/batch = 0.007\n",
      "1458/3300 (epoch 44), train_loss = -2.442, time/batch = 0.007\n",
      "1459/3300 (epoch 44), train_loss = -3.264, time/batch = 0.007\n",
      "1460/3300 (epoch 44), train_loss = -2.780, time/batch = 0.006\n",
      "1461/3300 (epoch 44), train_loss = -3.606, time/batch = 0.006\n",
      "1462/3300 (epoch 44), train_loss = -3.589, time/batch = 0.006\n",
      "1463/3300 (epoch 44), train_loss = -3.390, time/batch = 0.006\n",
      "1464/3300 (epoch 44), train_loss = -3.497, time/batch = 0.006\n",
      "1465/3300 (epoch 44), train_loss = -3.575, time/batch = 0.007\n",
      "1466/3300 (epoch 44), train_loss = -3.630, time/batch = 0.007\n",
      "1467/3300 (epoch 44), train_loss = -3.486, time/batch = 0.006\n",
      "1468/3300 (epoch 44), train_loss = -2.813, time/batch = 0.008\n",
      "1469/3300 (epoch 44), train_loss = -3.794, time/batch = 0.007\n",
      "1470/3300 (epoch 44), train_loss = -3.731, time/batch = 0.007\n",
      "1471/3300 (epoch 44), train_loss = -3.385, time/batch = 0.006\n",
      "1472/3300 (epoch 44), train_loss = -3.381, time/batch = 0.006\n",
      "1473/3300 (epoch 44), train_loss = -3.681, time/batch = 0.006\n",
      "1474/3300 (epoch 44), train_loss = -3.916, time/batch = 0.006\n",
      "1475/3300 (epoch 44), train_loss = -3.469, time/batch = 0.006\n",
      "1476/3300 (epoch 44), train_loss = -4.420, time/batch = 0.006\n",
      "1477/3300 (epoch 44), train_loss = -3.298, time/batch = 0.006\n",
      "1478/3300 (epoch 44), train_loss = -3.438, time/batch = 0.007\n",
      "1479/3300 (epoch 44), train_loss = -3.977, time/batch = 0.006\n",
      "1480/3300 (epoch 44), train_loss = -3.609, time/batch = 0.006\n",
      "1481/3300 (epoch 44), train_loss = -3.322, time/batch = 0.006\n",
      "1482/3300 (epoch 44), train_loss = -3.942, time/batch = 0.006\n",
      "1483/3300 (epoch 44), train_loss = -3.356, time/batch = 0.006\n",
      "1484/3300 (epoch 44), train_loss = -3.656, time/batch = 0.006\n",
      "1485/3300 (epoch 45), train_loss = -0.947, time/batch = 0.006\n",
      "1486/3300 (epoch 45), train_loss = -1.845, time/batch = 0.006\n",
      "1487/3300 (epoch 45), train_loss = -2.440, time/batch = 0.006\n",
      "1488/3300 (epoch 45), train_loss = -2.158, time/batch = 0.006\n",
      "1489/3300 (epoch 45), train_loss = -2.241, time/batch = 0.007\n",
      "1490/3300 (epoch 45), train_loss = -3.107, time/batch = 0.007\n",
      "1491/3300 (epoch 45), train_loss = -2.966, time/batch = 0.007\n",
      "1492/3300 (epoch 45), train_loss = -2.849, time/batch = 0.007\n",
      "1493/3300 (epoch 45), train_loss = -3.051, time/batch = 0.006\n",
      "1494/3300 (epoch 45), train_loss = -3.962, time/batch = 0.007\n",
      "1495/3300 (epoch 45), train_loss = -2.736, time/batch = 0.007\n",
      "1496/3300 (epoch 45), train_loss = -3.380, time/batch = 0.006\n",
      "1497/3300 (epoch 45), train_loss = -2.528, time/batch = 0.006\n",
      "1498/3300 (epoch 45), train_loss = -3.601, time/batch = 0.006\n",
      "1499/3300 (epoch 45), train_loss = -2.864, time/batch = 0.007\n",
      "1500/3300 (epoch 45), train_loss = -3.604, time/batch = 0.012\n",
      "1501/3300 (epoch 45), train_loss = -3.486, time/batch = 0.009\n",
      "1502/3300 (epoch 45), train_loss = -3.168, time/batch = 0.007\n",
      "1503/3300 (epoch 45), train_loss = -3.442, time/batch = 0.008\n",
      "1504/3300 (epoch 45), train_loss = -3.726, time/batch = 0.009\n",
      "1505/3300 (epoch 45), train_loss = -3.747, time/batch = 0.007\n",
      "1506/3300 (epoch 45), train_loss = -4.098, time/batch = 0.007\n",
      "1507/3300 (epoch 45), train_loss = -4.029, time/batch = 0.006\n",
      "1508/3300 (epoch 45), train_loss = -3.310, time/batch = 0.006\n",
      "1509/3300 (epoch 45), train_loss = -4.404, time/batch = 0.006\n",
      "1510/3300 (epoch 45), train_loss = -4.479, time/batch = 0.007\n",
      "1511/3300 (epoch 45), train_loss = -4.422, time/batch = 0.007\n",
      "1512/3300 (epoch 45), train_loss = -3.884, time/batch = 0.007\n",
      "1513/3300 (epoch 45), train_loss = -3.540, time/batch = 0.008\n",
      "1514/3300 (epoch 45), train_loss = -3.700, time/batch = 0.007\n",
      "1515/3300 (epoch 45), train_loss = -4.054, time/batch = 0.006\n",
      "1516/3300 (epoch 45), train_loss = -3.578, time/batch = 0.006\n",
      "1517/3300 (epoch 45), train_loss = -4.026, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1518/3300 (epoch 46), train_loss = -1.057, time/batch = 0.006\n",
      "1519/3300 (epoch 46), train_loss = -2.029, time/batch = 0.006\n",
      "1520/3300 (epoch 46), train_loss = -2.625, time/batch = 0.006\n",
      "1521/3300 (epoch 46), train_loss = -2.753, time/batch = 0.006\n",
      "1522/3300 (epoch 46), train_loss = -2.440, time/batch = 0.006\n",
      "1523/3300 (epoch 46), train_loss = -2.492, time/batch = 0.006\n",
      "1524/3300 (epoch 46), train_loss = -2.457, time/batch = 0.006\n",
      "1525/3300 (epoch 46), train_loss = -3.364, time/batch = 0.006\n",
      "1526/3300 (epoch 46), train_loss = -1.861, time/batch = 0.006\n",
      "1527/3300 (epoch 46), train_loss = -3.732, time/batch = 0.006\n",
      "1528/3300 (epoch 46), train_loss = -3.322, time/batch = 0.006\n",
      "1529/3300 (epoch 46), train_loss = -2.572, time/batch = 0.006\n",
      "1530/3300 (epoch 46), train_loss = -3.170, time/batch = 0.006\n",
      "1531/3300 (epoch 46), train_loss = -3.601, time/batch = 0.006\n",
      "1532/3300 (epoch 46), train_loss = -3.486, time/batch = 0.006\n",
      "1533/3300 (epoch 46), train_loss = -3.504, time/batch = 0.006\n",
      "1534/3300 (epoch 46), train_loss = -3.713, time/batch = 0.006\n",
      "1535/3300 (epoch 46), train_loss = -3.900, time/batch = 0.006\n",
      "1536/3300 (epoch 46), train_loss = -3.004, time/batch = 0.006\n",
      "1537/3300 (epoch 46), train_loss = -3.769, time/batch = 0.006\n",
      "1538/3300 (epoch 46), train_loss = -3.914, time/batch = 0.006\n",
      "1539/3300 (epoch 46), train_loss = -3.635, time/batch = 0.006\n",
      "1540/3300 (epoch 46), train_loss = -3.970, time/batch = 0.006\n",
      "1541/3300 (epoch 46), train_loss = -3.448, time/batch = 0.006\n",
      "1542/3300 (epoch 46), train_loss = -3.971, time/batch = 0.006\n",
      "1543/3300 (epoch 46), train_loss = -4.375, time/batch = 0.006\n",
      "1544/3300 (epoch 46), train_loss = -4.037, time/batch = 0.006\n",
      "1545/3300 (epoch 46), train_loss = -3.778, time/batch = 0.006\n",
      "1546/3300 (epoch 46), train_loss = -3.939, time/batch = 0.006\n",
      "1547/3300 (epoch 46), train_loss = -3.821, time/batch = 0.006\n",
      "1548/3300 (epoch 46), train_loss = -3.597, time/batch = 0.006\n",
      "1549/3300 (epoch 46), train_loss = -3.719, time/batch = 0.006\n",
      "1550/3300 (epoch 46), train_loss = -3.769, time/batch = 0.007\n",
      "1551/3300 (epoch 47), train_loss = -0.985, time/batch = 0.006\n",
      "1552/3300 (epoch 47), train_loss = -2.007, time/batch = 0.006\n",
      "1553/3300 (epoch 47), train_loss = -2.735, time/batch = 0.006\n",
      "1554/3300 (epoch 47), train_loss = -1.776, time/batch = 0.006\n",
      "1555/3300 (epoch 47), train_loss = -2.451, time/batch = 0.006\n",
      "1556/3300 (epoch 47), train_loss = -0.423, time/batch = 0.006\n",
      "1557/3300 (epoch 47), train_loss = -2.671, time/batch = 0.006\n",
      "1558/3300 (epoch 47), train_loss = -2.747, time/batch = 0.006\n",
      "1559/3300 (epoch 47), train_loss = -2.827, time/batch = 0.006\n",
      "1560/3300 (epoch 47), train_loss = -4.197, time/batch = 0.006\n",
      "1561/3300 (epoch 47), train_loss = -3.433, time/batch = 0.006\n",
      "1562/3300 (epoch 47), train_loss = -3.567, time/batch = 0.006\n",
      "1563/3300 (epoch 47), train_loss = -2.809, time/batch = 0.006\n",
      "1564/3300 (epoch 47), train_loss = -4.287, time/batch = 0.006\n",
      "1565/3300 (epoch 47), train_loss = -3.260, time/batch = 0.005\n",
      "1566/3300 (epoch 47), train_loss = -3.582, time/batch = 0.006\n",
      "1567/3300 (epoch 47), train_loss = -3.613, time/batch = 0.006\n",
      "1568/3300 (epoch 47), train_loss = -3.296, time/batch = 0.006\n",
      "1569/3300 (epoch 47), train_loss = -3.747, time/batch = 0.006\n",
      "1570/3300 (epoch 47), train_loss = -3.295, time/batch = 0.006\n",
      "1571/3300 (epoch 47), train_loss = -3.862, time/batch = 0.006\n",
      "1572/3300 (epoch 47), train_loss = -3.138, time/batch = 0.006\n",
      "1573/3300 (epoch 47), train_loss = -3.709, time/batch = 0.006\n",
      "1574/3300 (epoch 47), train_loss = -3.890, time/batch = 0.006\n",
      "1575/3300 (epoch 47), train_loss = -4.507, time/batch = 0.007\n",
      "1576/3300 (epoch 47), train_loss = -4.445, time/batch = 0.007\n",
      "1577/3300 (epoch 47), train_loss = -4.445, time/batch = 0.006\n",
      "1578/3300 (epoch 47), train_loss = -4.408, time/batch = 0.006\n",
      "1579/3300 (epoch 47), train_loss = -4.300, time/batch = 0.006\n",
      "1580/3300 (epoch 47), train_loss = -3.513, time/batch = 0.006\n",
      "1581/3300 (epoch 47), train_loss = -3.822, time/batch = 0.006\n",
      "1582/3300 (epoch 47), train_loss = -3.913, time/batch = 0.006\n",
      "1583/3300 (epoch 47), train_loss = -4.802, time/batch = 0.006\n",
      "1584/3300 (epoch 48), train_loss = -1.074, time/batch = 0.006\n",
      "1585/3300 (epoch 48), train_loss = -1.934, time/batch = 0.006\n",
      "1586/3300 (epoch 48), train_loss = -2.541, time/batch = 0.006\n",
      "1587/3300 (epoch 48), train_loss = -2.415, time/batch = 0.006\n",
      "1588/3300 (epoch 48), train_loss = -2.064, time/batch = 0.006\n",
      "1589/3300 (epoch 48), train_loss = -2.857, time/batch = 0.008\n",
      "1590/3300 (epoch 48), train_loss = -2.196, time/batch = 0.006\n",
      "1591/3300 (epoch 48), train_loss = -2.603, time/batch = 0.006\n",
      "1592/3300 (epoch 48), train_loss = -2.559, time/batch = 0.007\n",
      "1593/3300 (epoch 48), train_loss = -3.974, time/batch = 0.007\n",
      "1594/3300 (epoch 48), train_loss = -2.640, time/batch = 0.006\n",
      "1595/3300 (epoch 48), train_loss = -3.747, time/batch = 0.006\n",
      "1596/3300 (epoch 48), train_loss = -3.117, time/batch = 0.006\n",
      "1597/3300 (epoch 48), train_loss = -3.918, time/batch = 0.006\n",
      "1598/3300 (epoch 48), train_loss = -3.213, time/batch = 0.006\n",
      "1599/3300 (epoch 48), train_loss = -3.715, time/batch = 0.006\n",
      "1600/3300 (epoch 48), train_loss = -3.232, time/batch = 0.006\n",
      "1601/3300 (epoch 48), train_loss = -3.671, time/batch = 0.006\n",
      "1602/3300 (epoch 48), train_loss = -3.221, time/batch = 0.006\n",
      "1603/3300 (epoch 48), train_loss = -3.871, time/batch = 0.006\n",
      "1604/3300 (epoch 48), train_loss = -3.341, time/batch = 0.006\n",
      "1605/3300 (epoch 48), train_loss = -3.834, time/batch = 0.006\n",
      "1606/3300 (epoch 48), train_loss = -3.818, time/batch = 0.006\n",
      "1607/3300 (epoch 48), train_loss = -4.069, time/batch = 0.006\n",
      "1608/3300 (epoch 48), train_loss = -2.637, time/batch = 0.006\n",
      "1609/3300 (epoch 48), train_loss = -4.572, time/batch = 0.006\n",
      "1610/3300 (epoch 48), train_loss = -3.728, time/batch = 0.006\n",
      "1611/3300 (epoch 48), train_loss = -3.635, time/batch = 0.006\n",
      "1612/3300 (epoch 48), train_loss = -4.117, time/batch = 0.006\n",
      "1613/3300 (epoch 48), train_loss = -4.781, time/batch = 0.007\n",
      "1614/3300 (epoch 48), train_loss = -4.118, time/batch = 0.008\n",
      "1615/3300 (epoch 48), train_loss = -4.084, time/batch = 0.006\n",
      "1616/3300 (epoch 48), train_loss = -3.880, time/batch = 0.006\n",
      "1617/3300 (epoch 49), train_loss = -1.081, time/batch = 0.006\n",
      "1618/3300 (epoch 49), train_loss = -1.785, time/batch = 0.010\n",
      "1619/3300 (epoch 49), train_loss = -2.557, time/batch = 0.006\n",
      "1620/3300 (epoch 49), train_loss = -3.154, time/batch = 0.006\n",
      "1621/3300 (epoch 49), train_loss = -2.015, time/batch = 0.007\n",
      "1622/3300 (epoch 49), train_loss = -2.516, time/batch = 0.006\n",
      "1623/3300 (epoch 49), train_loss = -3.159, time/batch = 0.007\n",
      "1624/3300 (epoch 49), train_loss = -0.763, time/batch = 0.006\n",
      "1625/3300 (epoch 49), train_loss = -2.697, time/batch = 0.006\n",
      "1626/3300 (epoch 49), train_loss = -3.372, time/batch = 0.006\n",
      "1627/3300 (epoch 49), train_loss = -3.759, time/batch = 0.006\n",
      "1628/3300 (epoch 49), train_loss = -2.581, time/batch = 0.006\n",
      "1629/3300 (epoch 49), train_loss = -3.802, time/batch = 0.006\n",
      "1630/3300 (epoch 49), train_loss = -2.982, time/batch = 0.006\n",
      "1631/3300 (epoch 49), train_loss = -3.754, time/batch = 0.006\n",
      "1632/3300 (epoch 49), train_loss = -3.111, time/batch = 0.006\n",
      "1633/3300 (epoch 49), train_loss = -3.934, time/batch = 0.006\n",
      "1634/3300 (epoch 49), train_loss = -3.223, time/batch = 0.006\n",
      "1635/3300 (epoch 49), train_loss = -3.640, time/batch = 0.006\n",
      "1636/3300 (epoch 49), train_loss = -3.676, time/batch = 0.006\n",
      "1637/3300 (epoch 49), train_loss = -4.037, time/batch = 0.006\n",
      "1638/3300 (epoch 49), train_loss = -4.240, time/batch = 0.006\n",
      "1639/3300 (epoch 49), train_loss = -3.025, time/batch = 0.006\n",
      "1640/3300 (epoch 49), train_loss = -4.625, time/batch = 0.006\n",
      "1641/3300 (epoch 49), train_loss = -4.419, time/batch = 0.006\n",
      "1642/3300 (epoch 49), train_loss = -4.657, time/batch = 0.006\n",
      "1643/3300 (epoch 49), train_loss = -4.140, time/batch = 0.006\n",
      "1644/3300 (epoch 49), train_loss = -3.929, time/batch = 0.006\n",
      "1645/3300 (epoch 49), train_loss = -3.771, time/batch = 0.006\n",
      "1646/3300 (epoch 49), train_loss = -4.726, time/batch = 0.006\n",
      "1647/3300 (epoch 49), train_loss = -4.562, time/batch = 0.006\n",
      "1648/3300 (epoch 49), train_loss = -3.872, time/batch = 0.006\n",
      "1649/3300 (epoch 49), train_loss = -3.402, time/batch = 0.006\n",
      "1650/3300 (epoch 50), train_loss = -1.041, time/batch = 0.006\n",
      "1651/3300 (epoch 50), train_loss = -2.044, time/batch = 0.006\n",
      "1652/3300 (epoch 50), train_loss = -2.575, time/batch = 0.007\n",
      "1653/3300 (epoch 50), train_loss = -2.506, time/batch = 0.006\n",
      "1654/3300 (epoch 50), train_loss = -1.197, time/batch = 0.006\n",
      "1655/3300 (epoch 50), train_loss = -2.623, time/batch = 0.006\n",
      "1656/3300 (epoch 50), train_loss = -2.744, time/batch = 0.007\n",
      "1657/3300 (epoch 50), train_loss = -2.433, time/batch = 0.009\n",
      "1658/3300 (epoch 50), train_loss = -3.845, time/batch = 0.006\n",
      "1659/3300 (epoch 50), train_loss = -3.900, time/batch = 0.006\n",
      "1660/3300 (epoch 50), train_loss = -3.353, time/batch = 0.006\n",
      "1661/3300 (epoch 50), train_loss = -3.591, time/batch = 0.006\n",
      "1662/3300 (epoch 50), train_loss = -3.603, time/batch = 0.006\n",
      "1663/3300 (epoch 50), train_loss = -4.206, time/batch = 0.006\n",
      "1664/3300 (epoch 50), train_loss = -3.013, time/batch = 0.006\n",
      "1665/3300 (epoch 50), train_loss = -3.529, time/batch = 0.006\n",
      "1666/3300 (epoch 50), train_loss = -3.870, time/batch = 0.006\n",
      "1667/3300 (epoch 50), train_loss = -3.771, time/batch = 0.007\n",
      "1668/3300 (epoch 50), train_loss = -3.514, time/batch = 0.006\n",
      "1669/3300 (epoch 50), train_loss = -2.894, time/batch = 0.006\n",
      "1670/3300 (epoch 50), train_loss = -3.812, time/batch = 0.006\n",
      "1671/3300 (epoch 50), train_loss = -2.940, time/batch = 0.006\n",
      "1672/3300 (epoch 50), train_loss = -3.838, time/batch = 0.006\n",
      "1673/3300 (epoch 50), train_loss = -3.784, time/batch = 0.007\n",
      "1674/3300 (epoch 50), train_loss = -4.193, time/batch = 0.006\n",
      "1675/3300 (epoch 50), train_loss = -3.375, time/batch = 0.006\n",
      "1676/3300 (epoch 50), train_loss = -3.923, time/batch = 0.006\n",
      "1677/3300 (epoch 50), train_loss = -3.776, time/batch = 0.006\n",
      "1678/3300 (epoch 50), train_loss = -4.930, time/batch = 0.006\n",
      "1679/3300 (epoch 50), train_loss = -4.187, time/batch = 0.006\n",
      "1680/3300 (epoch 50), train_loss = -3.380, time/batch = 0.006\n",
      "1681/3300 (epoch 50), train_loss = -3.677, time/batch = 0.006\n",
      "1682/3300 (epoch 50), train_loss = -3.981, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683/3300 (epoch 51), train_loss = -1.122, time/batch = 0.006\n",
      "1684/3300 (epoch 51), train_loss = -2.102, time/batch = 0.006\n",
      "1685/3300 (epoch 51), train_loss = -2.491, time/batch = 0.006\n",
      "1686/3300 (epoch 51), train_loss = -2.127, time/batch = 0.006\n",
      "1687/3300 (epoch 51), train_loss = -2.613, time/batch = 0.006\n",
      "1688/3300 (epoch 51), train_loss = -2.611, time/batch = 0.006\n",
      "1689/3300 (epoch 51), train_loss = -1.770, time/batch = 0.006\n",
      "1690/3300 (epoch 51), train_loss = -2.455, time/batch = 0.006\n",
      "1691/3300 (epoch 51), train_loss = -3.647, time/batch = 0.006\n",
      "1692/3300 (epoch 51), train_loss = -3.713, time/batch = 0.006\n",
      "1693/3300 (epoch 51), train_loss = -3.154, time/batch = 0.007\n",
      "1694/3300 (epoch 51), train_loss = -3.712, time/batch = 0.009\n",
      "1695/3300 (epoch 51), train_loss = -3.000, time/batch = 0.007\n",
      "1696/3300 (epoch 51), train_loss = -4.238, time/batch = 0.007\n",
      "1697/3300 (epoch 51), train_loss = -3.185, time/batch = 0.007\n",
      "1698/3300 (epoch 51), train_loss = -3.824, time/batch = 0.007\n",
      "1699/3300 (epoch 51), train_loss = -3.072, time/batch = 0.006\n",
      "1700/3300 (epoch 51), train_loss = -3.484, time/batch = 0.007\n",
      "1701/3300 (epoch 51), train_loss = -3.425, time/batch = 0.006\n",
      "1702/3300 (epoch 51), train_loss = -3.663, time/batch = 0.006\n",
      "1703/3300 (epoch 51), train_loss = -4.271, time/batch = 0.006\n",
      "1704/3300 (epoch 51), train_loss = -3.883, time/batch = 0.006\n",
      "1705/3300 (epoch 51), train_loss = -3.203, time/batch = 0.007\n",
      "1706/3300 (epoch 51), train_loss = -4.782, time/batch = 0.006\n",
      "1707/3300 (epoch 51), train_loss = -4.557, time/batch = 0.006\n",
      "1708/3300 (epoch 51), train_loss = -4.873, time/batch = 0.006\n",
      "1709/3300 (epoch 51), train_loss = -3.957, time/batch = 0.006\n",
      "1710/3300 (epoch 51), train_loss = -4.213, time/batch = 0.009\n",
      "1711/3300 (epoch 51), train_loss = -3.734, time/batch = 0.007\n",
      "1712/3300 (epoch 51), train_loss = -3.749, time/batch = 0.008\n",
      "1713/3300 (epoch 51), train_loss = -4.850, time/batch = 0.007\n",
      "1714/3300 (epoch 51), train_loss = -4.112, time/batch = 0.007\n",
      "1715/3300 (epoch 51), train_loss = -3.908, time/batch = 0.006\n",
      "1716/3300 (epoch 52), train_loss = -1.106, time/batch = 0.006\n",
      "1717/3300 (epoch 52), train_loss = -2.024, time/batch = 0.006\n",
      "1718/3300 (epoch 52), train_loss = -2.644, time/batch = 0.006\n",
      "1719/3300 (epoch 52), train_loss = -1.878, time/batch = 0.006\n",
      "1720/3300 (epoch 52), train_loss = -1.699, time/batch = 0.006\n",
      "1721/3300 (epoch 52), train_loss = -1.681, time/batch = 0.006\n",
      "1722/3300 (epoch 52), train_loss = -2.035, time/batch = 0.007\n",
      "1723/3300 (epoch 52), train_loss = -2.099, time/batch = 0.006\n",
      "1724/3300 (epoch 52), train_loss = -3.681, time/batch = 0.006\n",
      "1725/3300 (epoch 52), train_loss = -3.537, time/batch = 0.006\n",
      "1726/3300 (epoch 52), train_loss = -3.715, time/batch = 0.006\n",
      "1727/3300 (epoch 52), train_loss = -3.644, time/batch = 0.006\n",
      "1728/3300 (epoch 52), train_loss = -3.954, time/batch = 0.006\n",
      "1729/3300 (epoch 52), train_loss = -4.016, time/batch = 0.006\n",
      "1730/3300 (epoch 52), train_loss = -4.007, time/batch = 0.006\n",
      "1731/3300 (epoch 52), train_loss = -3.228, time/batch = 0.006\n",
      "1732/3300 (epoch 52), train_loss = -4.008, time/batch = 0.006\n",
      "1733/3300 (epoch 52), train_loss = -3.409, time/batch = 0.006\n",
      "1734/3300 (epoch 52), train_loss = -3.141, time/batch = 0.006\n",
      "1735/3300 (epoch 52), train_loss = -3.754, time/batch = 0.006\n",
      "1736/3300 (epoch 52), train_loss = -3.905, time/batch = 0.006\n",
      "1737/3300 (epoch 52), train_loss = -4.101, time/batch = 0.006\n",
      "1738/3300 (epoch 52), train_loss = -3.700, time/batch = 0.007\n",
      "1739/3300 (epoch 52), train_loss = -4.759, time/batch = 0.006\n",
      "1740/3300 (epoch 52), train_loss = -4.280, time/batch = 0.006\n",
      "1741/3300 (epoch 52), train_loss = -4.093, time/batch = 0.006\n",
      "1742/3300 (epoch 52), train_loss = -3.080, time/batch = 0.006\n",
      "1743/3300 (epoch 52), train_loss = -4.610, time/batch = 0.006\n",
      "1744/3300 (epoch 52), train_loss = -4.557, time/batch = 0.006\n",
      "1745/3300 (epoch 52), train_loss = -4.947, time/batch = 0.007\n",
      "1746/3300 (epoch 52), train_loss = -3.754, time/batch = 0.006\n",
      "1747/3300 (epoch 52), train_loss = -3.972, time/batch = 0.006\n",
      "1748/3300 (epoch 52), train_loss = -3.714, time/batch = 0.006\n",
      "1749/3300 (epoch 53), train_loss = -1.070, time/batch = 0.006\n",
      "1750/3300 (epoch 53), train_loss = -1.889, time/batch = 0.006\n",
      "1751/3300 (epoch 53), train_loss = -2.660, time/batch = 0.006\n",
      "1752/3300 (epoch 53), train_loss = -2.022, time/batch = 0.006\n",
      "1753/3300 (epoch 53), train_loss = -1.672, time/batch = 0.006\n",
      "1754/3300 (epoch 53), train_loss = -1.843, time/batch = 0.006\n",
      "1755/3300 (epoch 53), train_loss = -2.481, time/batch = 0.006\n",
      "1756/3300 (epoch 53), train_loss = -2.100, time/batch = 0.006\n",
      "1757/3300 (epoch 53), train_loss = -2.890, time/batch = 0.006\n",
      "1758/3300 (epoch 53), train_loss = -4.065, time/batch = 0.006\n",
      "1759/3300 (epoch 53), train_loss = -3.880, time/batch = 0.006\n",
      "1760/3300 (epoch 53), train_loss = -3.746, time/batch = 0.007\n",
      "1761/3300 (epoch 53), train_loss = -3.972, time/batch = 0.007\n",
      "1762/3300 (epoch 53), train_loss = -3.570, time/batch = 0.006\n",
      "1763/3300 (epoch 53), train_loss = -3.637, time/batch = 0.006\n",
      "1764/3300 (epoch 53), train_loss = -4.179, time/batch = 0.006\n",
      "1765/3300 (epoch 53), train_loss = -3.516, time/batch = 0.006\n",
      "1766/3300 (epoch 53), train_loss = -3.918, time/batch = 0.006\n",
      "1767/3300 (epoch 53), train_loss = -2.810, time/batch = 0.006\n",
      "1768/3300 (epoch 53), train_loss = -3.502, time/batch = 0.006\n",
      "1769/3300 (epoch 53), train_loss = -2.702, time/batch = 0.006\n",
      "1770/3300 (epoch 53), train_loss = -3.893, time/batch = 0.005\n",
      "1771/3300 (epoch 53), train_loss = -3.562, time/batch = 0.006\n",
      "1772/3300 (epoch 53), train_loss = -4.247, time/batch = 0.007\n",
      "1773/3300 (epoch 53), train_loss = -4.050, time/batch = 0.006\n",
      "1774/3300 (epoch 53), train_loss = -3.908, time/batch = 0.006\n",
      "1775/3300 (epoch 53), train_loss = -4.789, time/batch = 0.006\n",
      "1776/3300 (epoch 53), train_loss = -4.571, time/batch = 0.007\n",
      "1777/3300 (epoch 53), train_loss = -4.803, time/batch = 0.006\n",
      "1778/3300 (epoch 53), train_loss = -4.721, time/batch = 0.006\n",
      "1779/3300 (epoch 53), train_loss = -4.768, time/batch = 0.006\n",
      "1780/3300 (epoch 53), train_loss = -3.315, time/batch = 0.006\n",
      "1781/3300 (epoch 53), train_loss = -3.929, time/batch = 0.006\n",
      "1782/3300 (epoch 54), train_loss = -1.129, time/batch = 0.005\n",
      "1783/3300 (epoch 54), train_loss = -1.644, time/batch = 0.006\n",
      "1784/3300 (epoch 54), train_loss = -2.523, time/batch = 0.006\n",
      "1785/3300 (epoch 54), train_loss = -2.538, time/batch = 0.006\n",
      "1786/3300 (epoch 54), train_loss = -2.144, time/batch = 0.006\n",
      "1787/3300 (epoch 54), train_loss = -1.675, time/batch = 0.006\n",
      "1788/3300 (epoch 54), train_loss = -2.269, time/batch = 0.006\n",
      "1789/3300 (epoch 54), train_loss = -1.711, time/batch = 0.006\n",
      "1790/3300 (epoch 54), train_loss = -3.962, time/batch = 0.006\n",
      "1791/3300 (epoch 54), train_loss = -3.570, time/batch = 0.006\n",
      "1792/3300 (epoch 54), train_loss = -3.809, time/batch = 0.006\n",
      "1793/3300 (epoch 54), train_loss = -3.879, time/batch = 0.006\n",
      "1794/3300 (epoch 54), train_loss = -3.998, time/batch = 0.006\n",
      "1795/3300 (epoch 54), train_loss = -3.935, time/batch = 0.006\n",
      "1796/3300 (epoch 54), train_loss = -3.271, time/batch = 0.006\n",
      "1797/3300 (epoch 54), train_loss = -3.763, time/batch = 0.005\n",
      "1798/3300 (epoch 54), train_loss = -3.930, time/batch = 0.006\n",
      "1799/3300 (epoch 54), train_loss = -3.851, time/batch = 0.006\n",
      "1800/3300 (epoch 54), train_loss = -2.990, time/batch = 0.006\n",
      "1801/3300 (epoch 54), train_loss = -4.114, time/batch = 0.006\n",
      "1802/3300 (epoch 54), train_loss = -3.312, time/batch = 0.006\n",
      "1803/3300 (epoch 54), train_loss = -3.765, time/batch = 0.006\n",
      "1804/3300 (epoch 54), train_loss = -4.647, time/batch = 0.006\n",
      "1805/3300 (epoch 54), train_loss = -4.426, time/batch = 0.006\n",
      "1806/3300 (epoch 54), train_loss = -2.772, time/batch = 0.006\n",
      "1807/3300 (epoch 54), train_loss = -4.352, time/batch = 0.006\n",
      "1808/3300 (epoch 54), train_loss = -4.178, time/batch = 0.006\n",
      "1809/3300 (epoch 54), train_loss = -3.858, time/batch = 0.006\n",
      "1810/3300 (epoch 54), train_loss = -4.033, time/batch = 0.006\n",
      "1811/3300 (epoch 54), train_loss = -4.119, time/batch = 0.006\n",
      "1812/3300 (epoch 54), train_loss = -3.583, time/batch = 0.007\n",
      "1813/3300 (epoch 54), train_loss = -4.337, time/batch = 0.007\n",
      "1814/3300 (epoch 54), train_loss = -4.198, time/batch = 0.006\n",
      "1815/3300 (epoch 55), train_loss = -1.049, time/batch = 0.006\n",
      "1816/3300 (epoch 55), train_loss = -1.962, time/batch = 0.006\n",
      "1817/3300 (epoch 55), train_loss = -2.614, time/batch = 0.006\n",
      "1818/3300 (epoch 55), train_loss = -2.520, time/batch = 0.006\n",
      "1819/3300 (epoch 55), train_loss = -1.844, time/batch = 0.006\n",
      "1820/3300 (epoch 55), train_loss = -2.257, time/batch = 0.006\n",
      "1821/3300 (epoch 55), train_loss = -2.769, time/batch = 0.006\n",
      "1822/3300 (epoch 55), train_loss = -2.731, time/batch = 0.006\n",
      "1823/3300 (epoch 55), train_loss = -2.713, time/batch = 0.006\n",
      "1824/3300 (epoch 55), train_loss = -4.054, time/batch = 0.006\n",
      "1825/3300 (epoch 55), train_loss = -4.016, time/batch = 0.006\n",
      "1826/3300 (epoch 55), train_loss = -3.720, time/batch = 0.006\n",
      "1827/3300 (epoch 55), train_loss = -3.888, time/batch = 0.006\n",
      "1828/3300 (epoch 55), train_loss = -4.090, time/batch = 0.006\n",
      "1829/3300 (epoch 55), train_loss = -3.955, time/batch = 0.006\n",
      "1830/3300 (epoch 55), train_loss = -3.868, time/batch = 0.006\n",
      "1831/3300 (epoch 55), train_loss = -3.708, time/batch = 0.006\n",
      "1832/3300 (epoch 55), train_loss = -3.547, time/batch = 0.006\n",
      "1833/3300 (epoch 55), train_loss = -3.897, time/batch = 0.006\n",
      "1834/3300 (epoch 55), train_loss = -4.129, time/batch = 0.006\n",
      "1835/3300 (epoch 55), train_loss = -2.974, time/batch = 0.006\n",
      "1836/3300 (epoch 55), train_loss = -4.715, time/batch = 0.006\n",
      "1837/3300 (epoch 55), train_loss = -4.661, time/batch = 0.006\n",
      "1838/3300 (epoch 55), train_loss = -4.792, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1839/3300 (epoch 55), train_loss = -3.748, time/batch = 0.007\n",
      "1840/3300 (epoch 55), train_loss = -4.134, time/batch = 0.006\n",
      "1841/3300 (epoch 55), train_loss = -4.056, time/batch = 0.006\n",
      "1842/3300 (epoch 55), train_loss = -4.320, time/batch = 0.006\n",
      "1843/3300 (epoch 55), train_loss = -3.483, time/batch = 0.006\n",
      "1844/3300 (epoch 55), train_loss = -4.116, time/batch = 0.006\n",
      "1845/3300 (epoch 55), train_loss = -3.359, time/batch = 0.006\n",
      "1846/3300 (epoch 55), train_loss = -4.230, time/batch = 0.006\n",
      "1847/3300 (epoch 55), train_loss = -3.609, time/batch = 0.006\n",
      "1848/3300 (epoch 56), train_loss = -1.177, time/batch = 0.007\n",
      "1849/3300 (epoch 56), train_loss = -1.954, time/batch = 0.006\n",
      "1850/3300 (epoch 56), train_loss = -2.533, time/batch = 0.006\n",
      "1851/3300 (epoch 56), train_loss = -1.921, time/batch = 0.006\n",
      "1852/3300 (epoch 56), train_loss = -1.259, time/batch = 0.006\n",
      "1853/3300 (epoch 56), train_loss = -2.496, time/batch = 0.006\n",
      "1854/3300 (epoch 56), train_loss = -2.340, time/batch = 0.006\n",
      "1855/3300 (epoch 56), train_loss = -2.920, time/batch = 0.006\n",
      "1856/3300 (epoch 56), train_loss = -3.817, time/batch = 0.007\n",
      "1857/3300 (epoch 56), train_loss = -3.913, time/batch = 0.006\n",
      "1858/3300 (epoch 56), train_loss = -3.669, time/batch = 0.006\n",
      "1859/3300 (epoch 56), train_loss = -3.927, time/batch = 0.006\n",
      "1860/3300 (epoch 56), train_loss = -4.277, time/batch = 0.006\n",
      "1861/3300 (epoch 56), train_loss = -3.384, time/batch = 0.006\n",
      "1862/3300 (epoch 56), train_loss = -3.855, time/batch = 0.006\n",
      "1863/3300 (epoch 56), train_loss = -3.944, time/batch = 0.006\n",
      "1864/3300 (epoch 56), train_loss = -4.320, time/batch = 0.006\n",
      "1865/3300 (epoch 56), train_loss = -3.494, time/batch = 0.006\n",
      "1866/3300 (epoch 56), train_loss = -3.474, time/batch = 0.006\n",
      "1867/3300 (epoch 56), train_loss = -4.030, time/batch = 0.006\n",
      "1868/3300 (epoch 56), train_loss = -3.679, time/batch = 0.006\n",
      "1869/3300 (epoch 56), train_loss = -3.890, time/batch = 0.006\n",
      "1870/3300 (epoch 56), train_loss = -3.848, time/batch = 0.007\n",
      "1871/3300 (epoch 56), train_loss = -4.754, time/batch = 0.006\n",
      "1872/3300 (epoch 56), train_loss = -4.165, time/batch = 0.006\n",
      "1873/3300 (epoch 56), train_loss = -3.492, time/batch = 0.006\n",
      "1874/3300 (epoch 56), train_loss = -4.065, time/batch = 0.006\n",
      "1875/3300 (epoch 56), train_loss = -4.650, time/batch = 0.006\n",
      "1876/3300 (epoch 56), train_loss = -4.854, time/batch = 0.007\n",
      "1877/3300 (epoch 56), train_loss = -4.192, time/batch = 0.006\n",
      "1878/3300 (epoch 56), train_loss = -3.864, time/batch = 0.006\n",
      "1879/3300 (epoch 56), train_loss = -3.801, time/batch = 0.005\n",
      "1880/3300 (epoch 56), train_loss = -3.944, time/batch = 0.006\n",
      "1881/3300 (epoch 57), train_loss = -1.082, time/batch = 0.005\n",
      "1882/3300 (epoch 57), train_loss = -1.950, time/batch = 0.006\n",
      "1883/3300 (epoch 57), train_loss = -2.406, time/batch = 0.007\n",
      "1884/3300 (epoch 57), train_loss = -2.390, time/batch = 0.006\n",
      "1885/3300 (epoch 57), train_loss = -1.478, time/batch = 0.006\n",
      "1886/3300 (epoch 57), train_loss = -2.526, time/batch = 0.007\n",
      "1887/3300 (epoch 57), train_loss = -2.475, time/batch = 0.008\n",
      "1888/3300 (epoch 57), train_loss = -3.148, time/batch = 0.008\n",
      "1889/3300 (epoch 57), train_loss = -3.872, time/batch = 0.008\n",
      "1890/3300 (epoch 57), train_loss = -3.860, time/batch = 0.006\n",
      "1891/3300 (epoch 57), train_loss = -3.904, time/batch = 0.009\n",
      "1892/3300 (epoch 57), train_loss = -3.464, time/batch = 0.006\n",
      "1893/3300 (epoch 57), train_loss = -4.269, time/batch = 0.007\n",
      "1894/3300 (epoch 57), train_loss = -3.382, time/batch = 0.006\n",
      "1895/3300 (epoch 57), train_loss = -4.074, time/batch = 0.006\n",
      "1896/3300 (epoch 57), train_loss = -3.813, time/batch = 0.006\n",
      "1897/3300 (epoch 57), train_loss = -3.550, time/batch = 0.006\n",
      "1898/3300 (epoch 57), train_loss = -4.044, time/batch = 0.010\n",
      "1899/3300 (epoch 57), train_loss = -3.682, time/batch = 0.006\n",
      "1900/3300 (epoch 57), train_loss = -4.220, time/batch = 0.006\n",
      "1901/3300 (epoch 57), train_loss = -3.839, time/batch = 0.006\n",
      "1902/3300 (epoch 57), train_loss = -4.666, time/batch = 0.006\n",
      "1903/3300 (epoch 57), train_loss = -4.548, time/batch = 0.006\n",
      "1904/3300 (epoch 57), train_loss = -4.441, time/batch = 0.007\n",
      "1905/3300 (epoch 57), train_loss = -3.344, time/batch = 0.007\n",
      "1906/3300 (epoch 57), train_loss = -4.008, time/batch = 0.006\n",
      "1907/3300 (epoch 57), train_loss = -4.403, time/batch = 0.007\n",
      "1908/3300 (epoch 57), train_loss = -4.844, time/batch = 0.006\n",
      "1909/3300 (epoch 57), train_loss = -4.191, time/batch = 0.007\n",
      "1910/3300 (epoch 57), train_loss = -3.968, time/batch = 0.007\n",
      "1911/3300 (epoch 57), train_loss = -4.013, time/batch = 0.006\n",
      "1912/3300 (epoch 57), train_loss = -3.626, time/batch = 0.006\n",
      "1913/3300 (epoch 57), train_loss = -4.024, time/batch = 0.006\n",
      "1914/3300 (epoch 58), train_loss = -1.087, time/batch = 0.006\n",
      "1915/3300 (epoch 58), train_loss = -2.042, time/batch = 0.006\n",
      "1916/3300 (epoch 58), train_loss = -2.533, time/batch = 0.007\n",
      "1917/3300 (epoch 58), train_loss = -2.082, time/batch = 0.011\n",
      "1918/3300 (epoch 58), train_loss = -1.138, time/batch = 0.007\n",
      "1919/3300 (epoch 58), train_loss = -2.129, time/batch = 0.007\n",
      "1920/3300 (epoch 58), train_loss = -2.691, time/batch = 0.007\n",
      "1921/3300 (epoch 58), train_loss = -3.155, time/batch = 0.006\n",
      "1922/3300 (epoch 58), train_loss = -3.716, time/batch = 0.007\n",
      "1923/3300 (epoch 58), train_loss = -3.533, time/batch = 0.007\n",
      "1924/3300 (epoch 58), train_loss = -3.805, time/batch = 0.010\n",
      "1925/3300 (epoch 58), train_loss = -3.702, time/batch = 0.007\n",
      "1926/3300 (epoch 58), train_loss = -3.851, time/batch = 0.007\n",
      "1927/3300 (epoch 58), train_loss = -4.129, time/batch = 0.007\n",
      "1928/3300 (epoch 58), train_loss = -3.192, time/batch = 0.006\n",
      "1929/3300 (epoch 58), train_loss = -3.930, time/batch = 0.006\n",
      "1930/3300 (epoch 58), train_loss = -3.710, time/batch = 0.006\n",
      "1931/3300 (epoch 58), train_loss = -3.748, time/batch = 0.006\n",
      "1932/3300 (epoch 58), train_loss = -3.518, time/batch = 0.006\n",
      "1933/3300 (epoch 58), train_loss = -3.959, time/batch = 0.006\n",
      "1934/3300 (epoch 58), train_loss = -4.240, time/batch = 0.006\n",
      "1935/3300 (epoch 58), train_loss = -4.038, time/batch = 0.006\n",
      "1936/3300 (epoch 58), train_loss = -4.200, time/batch = 0.006\n",
      "1937/3300 (epoch 58), train_loss = -4.827, time/batch = 0.006\n",
      "1938/3300 (epoch 58), train_loss = -4.578, time/batch = 0.006\n",
      "1939/3300 (epoch 58), train_loss = -4.664, time/batch = 0.006\n",
      "1940/3300 (epoch 58), train_loss = -4.309, time/batch = 0.006\n",
      "1941/3300 (epoch 58), train_loss = -3.813, time/batch = 0.006\n",
      "1942/3300 (epoch 58), train_loss = -4.694, time/batch = 0.006\n",
      "1943/3300 (epoch 58), train_loss = -4.550, time/batch = 0.006\n",
      "1944/3300 (epoch 58), train_loss = -3.784, time/batch = 0.006\n",
      "1945/3300 (epoch 58), train_loss = -4.065, time/batch = 0.006\n",
      "1946/3300 (epoch 58), train_loss = -4.224, time/batch = 0.006\n",
      "1947/3300 (epoch 59), train_loss = -1.107, time/batch = 0.008\n",
      "1948/3300 (epoch 59), train_loss = -1.880, time/batch = 0.006\n",
      "1949/3300 (epoch 59), train_loss = -2.603, time/batch = 0.006\n",
      "1950/3300 (epoch 59), train_loss = -1.997, time/batch = 0.006\n",
      "1951/3300 (epoch 59), train_loss = -1.795, time/batch = 0.007\n",
      "1952/3300 (epoch 59), train_loss = -2.224, time/batch = 0.006\n",
      "1953/3300 (epoch 59), train_loss = -2.598, time/batch = 0.006\n",
      "1954/3300 (epoch 59), train_loss = -2.253, time/batch = 0.007\n",
      "1955/3300 (epoch 59), train_loss = -3.300, time/batch = 0.006\n",
      "1956/3300 (epoch 59), train_loss = -3.773, time/batch = 0.006\n",
      "1957/3300 (epoch 59), train_loss = -3.971, time/batch = 0.007\n",
      "1958/3300 (epoch 59), train_loss = -3.561, time/batch = 0.006\n",
      "1959/3300 (epoch 59), train_loss = -3.874, time/batch = 0.007\n",
      "1960/3300 (epoch 59), train_loss = -4.259, time/batch = 0.007\n",
      "1961/3300 (epoch 59), train_loss = -3.834, time/batch = 0.006\n",
      "1962/3300 (epoch 59), train_loss = -3.892, time/batch = 0.006\n",
      "1963/3300 (epoch 59), train_loss = -3.696, time/batch = 0.006\n",
      "1964/3300 (epoch 59), train_loss = -4.007, time/batch = 0.006\n",
      "1965/3300 (epoch 59), train_loss = -3.326, time/batch = 0.007\n",
      "1966/3300 (epoch 59), train_loss = -3.965, time/batch = 0.007\n",
      "1967/3300 (epoch 59), train_loss = -4.087, time/batch = 0.006\n",
      "1968/3300 (epoch 59), train_loss = -3.940, time/batch = 0.006\n",
      "1969/3300 (epoch 59), train_loss = -3.831, time/batch = 0.007\n",
      "1970/3300 (epoch 59), train_loss = -4.815, time/batch = 0.007\n",
      "1971/3300 (epoch 59), train_loss = -4.555, time/batch = 0.006\n",
      "1972/3300 (epoch 59), train_loss = -4.160, time/batch = 0.006\n",
      "1973/3300 (epoch 59), train_loss = -3.938, time/batch = 0.006\n",
      "1974/3300 (epoch 59), train_loss = -4.388, time/batch = 0.006\n",
      "1975/3300 (epoch 59), train_loss = -4.607, time/batch = 0.007\n",
      "1976/3300 (epoch 59), train_loss = -4.059, time/batch = 0.006\n",
      "1977/3300 (epoch 59), train_loss = -4.092, time/batch = 0.006\n",
      "1978/3300 (epoch 59), train_loss = -3.467, time/batch = 0.006\n",
      "1979/3300 (epoch 59), train_loss = -3.885, time/batch = 0.006\n",
      "1980/3300 (epoch 60), train_loss = -1.121, time/batch = 0.006\n",
      "1981/3300 (epoch 60), train_loss = -1.891, time/batch = 0.006\n",
      "1982/3300 (epoch 60), train_loss = -2.430, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983/3300 (epoch 60), train_loss = -2.339, time/batch = 0.006\n",
      "1984/3300 (epoch 60), train_loss = -2.213, time/batch = 0.006\n",
      "1985/3300 (epoch 60), train_loss = -2.368, time/batch = 0.006\n",
      "1986/3300 (epoch 60), train_loss = -2.125, time/batch = 0.007\n",
      "1987/3300 (epoch 60), train_loss = -2.299, time/batch = 0.006\n",
      "1988/3300 (epoch 60), train_loss = -3.403, time/batch = 0.007\n",
      "1989/3300 (epoch 60), train_loss = -3.660, time/batch = 0.006\n",
      "1990/3300 (epoch 60), train_loss = -3.634, time/batch = 0.008\n",
      "1991/3300 (epoch 60), train_loss = -3.956, time/batch = 0.008\n",
      "1992/3300 (epoch 60), train_loss = -3.682, time/batch = 0.012\n",
      "1993/3300 (epoch 60), train_loss = -3.863, time/batch = 0.008\n",
      "1994/3300 (epoch 60), train_loss = -3.610, time/batch = 0.007\n",
      "1995/3300 (epoch 60), train_loss = -4.205, time/batch = 0.010\n",
      "1996/3300 (epoch 60), train_loss = -3.795, time/batch = 0.007\n",
      "1997/3300 (epoch 60), train_loss = -3.355, time/batch = 0.007\n",
      "1998/3300 (epoch 60), train_loss = -3.631, time/batch = 0.007\n",
      "1999/3300 (epoch 60), train_loss = -4.070, time/batch = 0.007\n",
      "2000/3300 (epoch 60), train_loss = -3.458, time/batch = 0.007\n",
      "2001/3300 (epoch 60), train_loss = -3.830, time/batch = 0.006\n",
      "2002/3300 (epoch 60), train_loss = -3.910, time/batch = 0.007\n",
      "2003/3300 (epoch 60), train_loss = -4.827, time/batch = 0.006\n",
      "2004/3300 (epoch 60), train_loss = -4.814, time/batch = 0.007\n",
      "2005/3300 (epoch 60), train_loss = -4.669, time/batch = 0.006\n",
      "2006/3300 (epoch 60), train_loss = -4.080, time/batch = 0.006\n",
      "2007/3300 (epoch 60), train_loss = -3.509, time/batch = 0.006\n",
      "2008/3300 (epoch 60), train_loss = -4.614, time/batch = 0.006\n",
      "2009/3300 (epoch 60), train_loss = -4.921, time/batch = 0.006\n",
      "2010/3300 (epoch 60), train_loss = -4.549, time/batch = 0.006\n",
      "2011/3300 (epoch 60), train_loss = -3.946, time/batch = 0.006\n",
      "2012/3300 (epoch 60), train_loss = -4.117, time/batch = 0.007\n",
      "2013/3300 (epoch 61), train_loss = -1.131, time/batch = 0.006\n",
      "2014/3300 (epoch 61), train_loss = -2.079, time/batch = 0.007\n",
      "2015/3300 (epoch 61), train_loss = -2.362, time/batch = 0.007\n",
      "2016/3300 (epoch 61), train_loss = -2.524, time/batch = 0.007\n",
      "2017/3300 (epoch 61), train_loss = -2.241, time/batch = 0.006\n",
      "2018/3300 (epoch 61), train_loss = -2.213, time/batch = 0.006\n",
      "2019/3300 (epoch 61), train_loss = -2.204, time/batch = 0.006\n",
      "2020/3300 (epoch 61), train_loss = -2.270, time/batch = 0.006\n",
      "2021/3300 (epoch 61), train_loss = -3.756, time/batch = 0.006\n",
      "2022/3300 (epoch 61), train_loss = -3.668, time/batch = 0.006\n",
      "2023/3300 (epoch 61), train_loss = -3.899, time/batch = 0.008\n",
      "2024/3300 (epoch 61), train_loss = -3.699, time/batch = 0.006\n",
      "2025/3300 (epoch 61), train_loss = -3.998, time/batch = 0.006\n",
      "2026/3300 (epoch 61), train_loss = -4.292, time/batch = 0.006\n",
      "2027/3300 (epoch 61), train_loss = -4.030, time/batch = 0.006\n",
      "2028/3300 (epoch 61), train_loss = -3.993, time/batch = 0.008\n",
      "2029/3300 (epoch 61), train_loss = -3.965, time/batch = 0.006\n",
      "2030/3300 (epoch 61), train_loss = -3.846, time/batch = 0.007\n",
      "2031/3300 (epoch 61), train_loss = -3.452, time/batch = 0.011\n",
      "2032/3300 (epoch 61), train_loss = -4.077, time/batch = 0.006\n",
      "2033/3300 (epoch 61), train_loss = -3.779, time/batch = 0.006\n",
      "2034/3300 (epoch 61), train_loss = -4.127, time/batch = 0.006\n",
      "2035/3300 (epoch 61), train_loss = -4.313, time/batch = 0.007\n",
      "2036/3300 (epoch 61), train_loss = -4.122, time/batch = 0.006\n",
      "2037/3300 (epoch 61), train_loss = -3.824, time/batch = 0.006\n",
      "2038/3300 (epoch 61), train_loss = -4.753, time/batch = 0.006\n",
      "2039/3300 (epoch 61), train_loss = -4.626, time/batch = 0.006\n",
      "2040/3300 (epoch 61), train_loss = -3.815, time/batch = 0.006\n",
      "2041/3300 (epoch 61), train_loss = -4.012, time/batch = 0.006\n",
      "2042/3300 (epoch 61), train_loss = -4.376, time/batch = 0.006\n",
      "2043/3300 (epoch 61), train_loss = -4.318, time/batch = 0.006\n",
      "2044/3300 (epoch 61), train_loss = -3.953, time/batch = 0.007\n",
      "2045/3300 (epoch 61), train_loss = -4.208, time/batch = 0.006\n",
      "2046/3300 (epoch 62), train_loss = -1.054, time/batch = 0.006\n",
      "2047/3300 (epoch 62), train_loss = -2.201, time/batch = 0.007\n",
      "2048/3300 (epoch 62), train_loss = -2.366, time/batch = 0.007\n",
      "2049/3300 (epoch 62), train_loss = -2.394, time/batch = 0.006\n",
      "2050/3300 (epoch 62), train_loss = -1.808, time/batch = 0.006\n",
      "2051/3300 (epoch 62), train_loss = -1.350, time/batch = 0.006\n",
      "2052/3300 (epoch 62), train_loss = -2.200, time/batch = 0.006\n",
      "2053/3300 (epoch 62), train_loss = -2.203, time/batch = 0.006\n",
      "2054/3300 (epoch 62), train_loss = -3.932, time/batch = 0.006\n",
      "2055/3300 (epoch 62), train_loss = -3.902, time/batch = 0.006\n",
      "2056/3300 (epoch 62), train_loss = -4.116, time/batch = 0.006\n",
      "2057/3300 (epoch 62), train_loss = -3.787, time/batch = 0.006\n",
      "2058/3300 (epoch 62), train_loss = -4.022, time/batch = 0.006\n",
      "2059/3300 (epoch 62), train_loss = -3.973, time/batch = 0.007\n",
      "2060/3300 (epoch 62), train_loss = -3.988, time/batch = 0.006\n",
      "2061/3300 (epoch 62), train_loss = -4.073, time/batch = 0.006\n",
      "2062/3300 (epoch 62), train_loss = -3.975, time/batch = 0.006\n",
      "2063/3300 (epoch 62), train_loss = -4.047, time/batch = 0.006\n",
      "2064/3300 (epoch 62), train_loss = -3.147, time/batch = 0.006\n",
      "2065/3300 (epoch 62), train_loss = -3.992, time/batch = 0.006\n",
      "2066/3300 (epoch 62), train_loss = -4.201, time/batch = 0.006\n",
      "2067/3300 (epoch 62), train_loss = -3.848, time/batch = 0.007\n",
      "2068/3300 (epoch 62), train_loss = -3.844, time/batch = 0.006\n",
      "2069/3300 (epoch 62), train_loss = -4.854, time/batch = 0.007\n",
      "2070/3300 (epoch 62), train_loss = -4.840, time/batch = 0.007\n",
      "2071/3300 (epoch 62), train_loss = -4.828, time/batch = 0.006\n",
      "2072/3300 (epoch 62), train_loss = -4.919, time/batch = 0.006\n",
      "2073/3300 (epoch 62), train_loss = -4.859, time/batch = 0.006\n",
      "2074/3300 (epoch 62), train_loss = -4.467, time/batch = 0.006\n",
      "2075/3300 (epoch 62), train_loss = -4.139, time/batch = 0.006\n",
      "2076/3300 (epoch 62), train_loss = -4.169, time/batch = 0.006\n",
      "2077/3300 (epoch 62), train_loss = -4.806, time/batch = 0.006\n",
      "2078/3300 (epoch 62), train_loss = -4.430, time/batch = 0.006\n",
      "2079/3300 (epoch 63), train_loss = -1.113, time/batch = 0.006\n",
      "2080/3300 (epoch 63), train_loss = -2.268, time/batch = 0.006\n",
      "2081/3300 (epoch 63), train_loss = -2.409, time/batch = 0.007\n",
      "2082/3300 (epoch 63), train_loss = -3.136, time/batch = 0.006\n",
      "2083/3300 (epoch 63), train_loss = -1.470, time/batch = 0.008\n",
      "2084/3300 (epoch 63), train_loss = -1.193, time/batch = 0.007\n",
      "2085/3300 (epoch 63), train_loss = -1.272, time/batch = 0.006\n",
      "2086/3300 (epoch 63), train_loss = -2.280, time/batch = 0.007\n",
      "2087/3300 (epoch 63), train_loss = -2.429, time/batch = 0.006\n",
      "2088/3300 (epoch 63), train_loss = -3.586, time/batch = 0.006\n",
      "2089/3300 (epoch 63), train_loss = -3.955, time/batch = 0.006\n",
      "2090/3300 (epoch 63), train_loss = -3.787, time/batch = 0.006\n",
      "2091/3300 (epoch 63), train_loss = -3.884, time/batch = 0.006\n",
      "2092/3300 (epoch 63), train_loss = -3.978, time/batch = 0.006\n",
      "2093/3300 (epoch 63), train_loss = -4.081, time/batch = 0.006\n",
      "2094/3300 (epoch 63), train_loss = -4.223, time/batch = 0.006\n",
      "2095/3300 (epoch 63), train_loss = -4.123, time/batch = 0.006\n",
      "2096/3300 (epoch 63), train_loss = -3.790, time/batch = 0.006\n",
      "2097/3300 (epoch 63), train_loss = -3.552, time/batch = 0.005\n",
      "2098/3300 (epoch 63), train_loss = -3.959, time/batch = 0.006\n",
      "2099/3300 (epoch 63), train_loss = -3.373, time/batch = 0.006\n",
      "2100/3300 (epoch 63), train_loss = -3.852, time/batch = 0.006\n",
      "2101/3300 (epoch 63), train_loss = -4.236, time/batch = 0.006\n",
      "2102/3300 (epoch 63), train_loss = -4.390, time/batch = 0.006\n",
      "2103/3300 (epoch 63), train_loss = -3.928, time/batch = 0.007\n",
      "2104/3300 (epoch 63), train_loss = -4.439, time/batch = 0.006\n",
      "2105/3300 (epoch 63), train_loss = -4.213, time/batch = 0.006\n",
      "2106/3300 (epoch 63), train_loss = -4.168, time/batch = 0.007\n",
      "2107/3300 (epoch 63), train_loss = -3.504, time/batch = 0.006\n",
      "2108/3300 (epoch 63), train_loss = -4.305, time/batch = 0.006\n",
      "2109/3300 (epoch 63), train_loss = -4.799, time/batch = 0.006\n",
      "2110/3300 (epoch 63), train_loss = -4.305, time/batch = 0.006\n",
      "2111/3300 (epoch 63), train_loss = -3.927, time/batch = 0.006\n",
      "2112/3300 (epoch 64), train_loss = -1.102, time/batch = 0.005\n",
      "2113/3300 (epoch 64), train_loss = -2.182, time/batch = 0.006\n",
      "2114/3300 (epoch 64), train_loss = -2.663, time/batch = 0.006\n",
      "2115/3300 (epoch 64), train_loss = -2.479, time/batch = 0.006\n",
      "2116/3300 (epoch 64), train_loss = -1.869, time/batch = 0.006\n",
      "2117/3300 (epoch 64), train_loss = -1.216, time/batch = 0.007\n",
      "2118/3300 (epoch 64), train_loss = -2.270, time/batch = 0.006\n",
      "2119/3300 (epoch 64), train_loss = -2.414, time/batch = 0.006\n",
      "2120/3300 (epoch 64), train_loss = -2.335, time/batch = 0.006\n",
      "2121/3300 (epoch 64), train_loss = -4.170, time/batch = 0.006\n",
      "2122/3300 (epoch 64), train_loss = -4.156, time/batch = 0.006\n",
      "2123/3300 (epoch 64), train_loss = -4.201, time/batch = 0.008\n",
      "2124/3300 (epoch 64), train_loss = -3.649, time/batch = 0.006\n",
      "2125/3300 (epoch 64), train_loss = -3.850, time/batch = 0.007\n",
      "2126/3300 (epoch 64), train_loss = -3.960, time/batch = 0.006\n",
      "2127/3300 (epoch 64), train_loss = -4.167, time/batch = 0.006\n",
      "2128/3300 (epoch 64), train_loss = -3.638, time/batch = 0.007\n",
      "2129/3300 (epoch 64), train_loss = -4.036, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/3300 (epoch 64), train_loss = -3.298, time/batch = 0.007\n",
      "2131/3300 (epoch 64), train_loss = -3.812, time/batch = 0.006\n",
      "2132/3300 (epoch 64), train_loss = -3.397, time/batch = 0.005\n",
      "2133/3300 (epoch 64), train_loss = -4.052, time/batch = 0.006\n",
      "2134/3300 (epoch 64), train_loss = -4.343, time/batch = 0.007\n",
      "2135/3300 (epoch 64), train_loss = -4.307, time/batch = 0.006\n",
      "2136/3300 (epoch 64), train_loss = -3.740, time/batch = 0.006\n",
      "2137/3300 (epoch 64), train_loss = -4.599, time/batch = 0.006\n",
      "2138/3300 (epoch 64), train_loss = -4.748, time/batch = 0.006\n",
      "2139/3300 (epoch 64), train_loss = -4.421, time/batch = 0.006\n",
      "2140/3300 (epoch 64), train_loss = -4.047, time/batch = 0.006\n",
      "2141/3300 (epoch 64), train_loss = -4.047, time/batch = 0.007\n",
      "2142/3300 (epoch 64), train_loss = -4.218, time/batch = 0.006\n",
      "2143/3300 (epoch 64), train_loss = -5.073, time/batch = 0.006\n",
      "2144/3300 (epoch 64), train_loss = -4.262, time/batch = 0.010\n",
      "2145/3300 (epoch 65), train_loss = -1.103, time/batch = 0.006\n",
      "2146/3300 (epoch 65), train_loss = -2.016, time/batch = 0.006\n",
      "2147/3300 (epoch 65), train_loss = -2.453, time/batch = 0.007\n",
      "2148/3300 (epoch 65), train_loss = -2.098, time/batch = 0.007\n",
      "2149/3300 (epoch 65), train_loss = -1.410, time/batch = 0.008\n",
      "2150/3300 (epoch 65), train_loss = -2.153, time/batch = 0.008\n",
      "2151/3300 (epoch 65), train_loss = -2.270, time/batch = 0.007\n",
      "2152/3300 (epoch 65), train_loss = -3.653, time/batch = 0.008\n",
      "2153/3300 (epoch 65), train_loss = -3.727, time/batch = 0.006\n",
      "2154/3300 (epoch 65), train_loss = -3.921, time/batch = 0.006\n",
      "2155/3300 (epoch 65), train_loss = -3.731, time/batch = 0.006\n",
      "2156/3300 (epoch 65), train_loss = -3.934, time/batch = 0.007\n",
      "2157/3300 (epoch 65), train_loss = -3.904, time/batch = 0.008\n",
      "2158/3300 (epoch 65), train_loss = -4.111, time/batch = 0.007\n",
      "2159/3300 (epoch 65), train_loss = -3.739, time/batch = 0.008\n",
      "2160/3300 (epoch 65), train_loss = -4.260, time/batch = 0.007\n",
      "2161/3300 (epoch 65), train_loss = -2.929, time/batch = 0.006\n",
      "2162/3300 (epoch 65), train_loss = -3.791, time/batch = 0.007\n",
      "2163/3300 (epoch 65), train_loss = -3.746, time/batch = 0.006\n",
      "2164/3300 (epoch 65), train_loss = -4.160, time/batch = 0.007\n",
      "2165/3300 (epoch 65), train_loss = -4.171, time/batch = 0.006\n",
      "2166/3300 (epoch 65), train_loss = -3.793, time/batch = 0.006\n",
      "2167/3300 (epoch 65), train_loss = -4.857, time/batch = 0.007\n",
      "2168/3300 (epoch 65), train_loss = -4.944, time/batch = 0.006\n",
      "2169/3300 (epoch 65), train_loss = -4.946, time/batch = 0.006\n",
      "2170/3300 (epoch 65), train_loss = -4.805, time/batch = 0.006\n",
      "2171/3300 (epoch 65), train_loss = -3.881, time/batch = 0.006\n",
      "2172/3300 (epoch 65), train_loss = -4.266, time/batch = 0.006\n",
      "2173/3300 (epoch 65), train_loss = -4.435, time/batch = 0.006\n",
      "2174/3300 (epoch 65), train_loss = -3.970, time/batch = 0.006\n",
      "2175/3300 (epoch 65), train_loss = -3.798, time/batch = 0.007\n",
      "2176/3300 (epoch 65), train_loss = -4.052, time/batch = 0.006\n",
      "2177/3300 (epoch 65), train_loss = -4.305, time/batch = 0.006\n",
      "2178/3300 (epoch 66), train_loss = -1.090, time/batch = 0.006\n",
      "2179/3300 (epoch 66), train_loss = -2.088, time/batch = 0.006\n",
      "2180/3300 (epoch 66), train_loss = -2.398, time/batch = 0.007\n",
      "2181/3300 (epoch 66), train_loss = -2.285, time/batch = 0.006\n",
      "2182/3300 (epoch 66), train_loss = -1.944, time/batch = 0.006\n",
      "2183/3300 (epoch 66), train_loss = -1.930, time/batch = 0.007\n",
      "2184/3300 (epoch 66), train_loss = -1.950, time/batch = 0.006\n",
      "2185/3300 (epoch 66), train_loss = -2.828, time/batch = 0.007\n",
      "2186/3300 (epoch 66), train_loss = -3.824, time/batch = 0.009\n",
      "2187/3300 (epoch 66), train_loss = -3.938, time/batch = 0.006\n",
      "2188/3300 (epoch 66), train_loss = -4.061, time/batch = 0.006\n",
      "2189/3300 (epoch 66), train_loss = -4.022, time/batch = 0.006\n",
      "2190/3300 (epoch 66), train_loss = -3.770, time/batch = 0.006\n",
      "2191/3300 (epoch 66), train_loss = -4.123, time/batch = 0.006\n",
      "2192/3300 (epoch 66), train_loss = -3.701, time/batch = 0.008\n",
      "2193/3300 (epoch 66), train_loss = -4.091, time/batch = 0.006\n",
      "2194/3300 (epoch 66), train_loss = -3.240, time/batch = 0.006\n",
      "2195/3300 (epoch 66), train_loss = -3.870, time/batch = 0.008\n",
      "2196/3300 (epoch 66), train_loss = -3.923, time/batch = 0.006\n",
      "2197/3300 (epoch 66), train_loss = -3.347, time/batch = 0.006\n",
      "2198/3300 (epoch 66), train_loss = -4.177, time/batch = 0.007\n",
      "2199/3300 (epoch 66), train_loss = -4.432, time/batch = 0.006\n",
      "2200/3300 (epoch 66), train_loss = -4.361, time/batch = 0.008\n",
      "2201/3300 (epoch 66), train_loss = -4.056, time/batch = 0.006\n",
      "2202/3300 (epoch 66), train_loss = -4.401, time/batch = 0.006\n",
      "2203/3300 (epoch 66), train_loss = -4.799, time/batch = 0.006\n",
      "2204/3300 (epoch 66), train_loss = -4.184, time/batch = 0.006\n",
      "2205/3300 (epoch 66), train_loss = -4.130, time/batch = 0.007\n",
      "2206/3300 (epoch 66), train_loss = -4.312, time/batch = 0.006\n",
      "2207/3300 (epoch 66), train_loss = -4.753, time/batch = 0.006\n",
      "2208/3300 (epoch 66), train_loss = -4.067, time/batch = 0.006\n",
      "2209/3300 (epoch 66), train_loss = -3.914, time/batch = 0.007\n",
      "2210/3300 (epoch 66), train_loss = -4.172, time/batch = 0.007\n",
      "2211/3300 (epoch 67), train_loss = -1.068, time/batch = 0.006\n",
      "2212/3300 (epoch 67), train_loss = -2.019, time/batch = 0.006\n",
      "2213/3300 (epoch 67), train_loss = -2.184, time/batch = 0.009\n",
      "2214/3300 (epoch 67), train_loss = -2.091, time/batch = 0.007\n",
      "2215/3300 (epoch 67), train_loss = -1.693, time/batch = 0.008\n",
      "2216/3300 (epoch 67), train_loss = -2.209, time/batch = 0.007\n",
      "2217/3300 (epoch 67), train_loss = -1.665, time/batch = 0.008\n",
      "2218/3300 (epoch 67), train_loss = -3.109, time/batch = 0.007\n",
      "2219/3300 (epoch 67), train_loss = -3.954, time/batch = 0.006\n",
      "2220/3300 (epoch 67), train_loss = -3.894, time/batch = 0.006\n",
      "2221/3300 (epoch 67), train_loss = -4.045, time/batch = 0.007\n",
      "2222/3300 (epoch 67), train_loss = -3.932, time/batch = 0.006\n",
      "2223/3300 (epoch 67), train_loss = -4.082, time/batch = 0.007\n",
      "2224/3300 (epoch 67), train_loss = -4.436, time/batch = 0.006\n",
      "2225/3300 (epoch 67), train_loss = -3.842, time/batch = 0.007\n",
      "2226/3300 (epoch 67), train_loss = -4.165, time/batch = 0.006\n",
      "2227/3300 (epoch 67), train_loss = -3.913, time/batch = 0.008\n",
      "2228/3300 (epoch 67), train_loss = -3.812, time/batch = 0.006\n",
      "2229/3300 (epoch 67), train_loss = -3.430, time/batch = 0.006\n",
      "2230/3300 (epoch 67), train_loss = -3.683, time/batch = 0.007\n",
      "2231/3300 (epoch 67), train_loss = -4.028, time/batch = 0.006\n",
      "2232/3300 (epoch 67), train_loss = -4.471, time/batch = 0.008\n",
      "2233/3300 (epoch 67), train_loss = -4.432, time/batch = 0.006\n",
      "2234/3300 (epoch 67), train_loss = -3.503, time/batch = 0.006\n",
      "2235/3300 (epoch 67), train_loss = -4.945, time/batch = 0.008\n",
      "2236/3300 (epoch 67), train_loss = -4.948, time/batch = 0.006\n",
      "2237/3300 (epoch 67), train_loss = -4.010, time/batch = 0.006\n",
      "2238/3300 (epoch 67), train_loss = -4.133, time/batch = 0.006\n",
      "2239/3300 (epoch 67), train_loss = -4.289, time/batch = 0.006\n",
      "2240/3300 (epoch 67), train_loss = -5.079, time/batch = 0.006\n",
      "2241/3300 (epoch 67), train_loss = -3.986, time/batch = 0.006\n",
      "2242/3300 (epoch 67), train_loss = -4.831, time/batch = 0.006\n",
      "2243/3300 (epoch 67), train_loss = -4.166, time/batch = 0.007\n",
      "2244/3300 (epoch 68), train_loss = -1.163, time/batch = 0.006\n",
      "2245/3300 (epoch 68), train_loss = -1.883, time/batch = 0.006\n",
      "2246/3300 (epoch 68), train_loss = -2.482, time/batch = 0.006\n",
      "2247/3300 (epoch 68), train_loss = -2.217, time/batch = 0.006\n",
      "2248/3300 (epoch 68), train_loss = -1.589, time/batch = 0.007\n",
      "2249/3300 (epoch 68), train_loss = -1.621, time/batch = 0.007\n",
      "2250/3300 (epoch 68), train_loss = -2.116, time/batch = 0.006\n",
      "2251/3300 (epoch 68), train_loss = -2.411, time/batch = 0.007\n",
      "2252/3300 (epoch 68), train_loss = -4.029, time/batch = 0.006\n",
      "2253/3300 (epoch 68), train_loss = -3.993, time/batch = 0.006\n",
      "2254/3300 (epoch 68), train_loss = -4.123, time/batch = 0.006\n",
      "2255/3300 (epoch 68), train_loss = -3.968, time/batch = 0.006\n",
      "2256/3300 (epoch 68), train_loss = -3.643, time/batch = 0.006\n",
      "2257/3300 (epoch 68), train_loss = -4.393, time/batch = 0.006\n",
      "2258/3300 (epoch 68), train_loss = -3.893, time/batch = 0.006\n",
      "2259/3300 (epoch 68), train_loss = -4.079, time/batch = 0.006\n",
      "2260/3300 (epoch 68), train_loss = -4.265, time/batch = 0.006\n",
      "2261/3300 (epoch 68), train_loss = -3.758, time/batch = 0.006\n",
      "2262/3300 (epoch 68), train_loss = -3.886, time/batch = 0.006\n",
      "2263/3300 (epoch 68), train_loss = -3.741, time/batch = 0.006\n",
      "2264/3300 (epoch 68), train_loss = -4.009, time/batch = 0.006\n",
      "2265/3300 (epoch 68), train_loss = -4.560, time/batch = 0.007\n",
      "2266/3300 (epoch 68), train_loss = -4.210, time/batch = 0.006\n",
      "2267/3300 (epoch 68), train_loss = -3.989, time/batch = 0.008\n",
      "2268/3300 (epoch 68), train_loss = -4.550, time/batch = 0.006\n",
      "2269/3300 (epoch 68), train_loss = -4.117, time/batch = 0.007\n",
      "2270/3300 (epoch 68), train_loss = -3.825, time/batch = 0.007\n",
      "2271/3300 (epoch 68), train_loss = -5.028, time/batch = 0.006\n",
      "2272/3300 (epoch 68), train_loss = -3.601, time/batch = 0.008\n",
      "2273/3300 (epoch 68), train_loss = -4.201, time/batch = 0.006\n",
      "2274/3300 (epoch 68), train_loss = -4.309, time/batch = 0.007\n",
      "2275/3300 (epoch 68), train_loss = -3.901, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/3300 (epoch 68), train_loss = -4.446, time/batch = 0.007\n",
      "2277/3300 (epoch 69), train_loss = -1.144, time/batch = 0.006\n",
      "2278/3300 (epoch 69), train_loss = -2.304, time/batch = 0.006\n",
      "2279/3300 (epoch 69), train_loss = -2.612, time/batch = 0.007\n",
      "2280/3300 (epoch 69), train_loss = -2.077, time/batch = 0.007\n",
      "2281/3300 (epoch 69), train_loss = -2.575, time/batch = 0.006\n",
      "2282/3300 (epoch 69), train_loss = 1.882, time/batch = 0.008\n",
      "2283/3300 (epoch 69), train_loss = -0.873, time/batch = 0.006\n",
      "2284/3300 (epoch 69), train_loss = -1.986, time/batch = 0.007\n",
      "2285/3300 (epoch 69), train_loss = -2.176, time/batch = 0.007\n",
      "2286/3300 (epoch 69), train_loss = -4.107, time/batch = 0.007\n",
      "2287/3300 (epoch 69), train_loss = -4.020, time/batch = 0.006\n",
      "2288/3300 (epoch 69), train_loss = -4.037, time/batch = 0.006\n",
      "2289/3300 (epoch 69), train_loss = -4.100, time/batch = 0.006\n",
      "2290/3300 (epoch 69), train_loss = -3.859, time/batch = 0.007\n",
      "2291/3300 (epoch 69), train_loss = -4.247, time/batch = 0.006\n",
      "2292/3300 (epoch 69), train_loss = -4.073, time/batch = 0.006\n",
      "2293/3300 (epoch 69), train_loss = -3.645, time/batch = 0.006\n",
      "2294/3300 (epoch 69), train_loss = -4.028, time/batch = 0.006\n",
      "2295/3300 (epoch 69), train_loss = -3.435, time/batch = 0.006\n",
      "2296/3300 (epoch 69), train_loss = -3.628, time/batch = 0.006\n",
      "2297/3300 (epoch 69), train_loss = -4.144, time/batch = 0.006\n",
      "2298/3300 (epoch 69), train_loss = -4.007, time/batch = 0.006\n",
      "2299/3300 (epoch 69), train_loss = -4.413, time/batch = 0.006\n",
      "2300/3300 (epoch 69), train_loss = -4.400, time/batch = 0.006\n",
      "2301/3300 (epoch 69), train_loss = -4.080, time/batch = 0.006\n",
      "2302/3300 (epoch 69), train_loss = -4.999, time/batch = 0.007\n",
      "2303/3300 (epoch 69), train_loss = -5.020, time/batch = 0.006\n",
      "2304/3300 (epoch 69), train_loss = -5.068, time/batch = 0.007\n",
      "2305/3300 (epoch 69), train_loss = -5.074, time/batch = 0.009\n",
      "2306/3300 (epoch 69), train_loss = -5.152, time/batch = 0.007\n",
      "2307/3300 (epoch 69), train_loss = -5.072, time/batch = 0.007\n",
      "2308/3300 (epoch 69), train_loss = -5.245, time/batch = 0.011\n",
      "2309/3300 (epoch 69), train_loss = -4.944, time/batch = 0.006\n",
      "2310/3300 (epoch 70), train_loss = -1.099, time/batch = 0.006\n",
      "2311/3300 (epoch 70), train_loss = -2.090, time/batch = 0.009\n",
      "2312/3300 (epoch 70), train_loss = -2.343, time/batch = 0.006\n",
      "2313/3300 (epoch 70), train_loss = -2.310, time/batch = 0.006\n",
      "2314/3300 (epoch 70), train_loss = -0.207, time/batch = 0.007\n",
      "2315/3300 (epoch 70), train_loss = -1.081, time/batch = 0.007\n",
      "2316/3300 (epoch 70), train_loss = -1.801, time/batch = 0.007\n",
      "2317/3300 (epoch 70), train_loss = -3.224, time/batch = 0.007\n",
      "2318/3300 (epoch 70), train_loss = -4.069, time/batch = 0.006\n",
      "2319/3300 (epoch 70), train_loss = -3.748, time/batch = 0.007\n",
      "2320/3300 (epoch 70), train_loss = -4.040, time/batch = 0.006\n",
      "2321/3300 (epoch 70), train_loss = -4.312, time/batch = 0.008\n",
      "2322/3300 (epoch 70), train_loss = -3.138, time/batch = 0.007\n",
      "2323/3300 (epoch 70), train_loss = -4.263, time/batch = 0.006\n",
      "2324/3300 (epoch 70), train_loss = -4.003, time/batch = 0.006\n",
      "2325/3300 (epoch 70), train_loss = -3.929, time/batch = 0.007\n",
      "2326/3300 (epoch 70), train_loss = -3.910, time/batch = 0.007\n",
      "2327/3300 (epoch 70), train_loss = -3.584, time/batch = 0.006\n",
      "2328/3300 (epoch 70), train_loss = -3.594, time/batch = 0.008\n",
      "2329/3300 (epoch 70), train_loss = -4.249, time/batch = 0.006\n",
      "2330/3300 (epoch 70), train_loss = -4.582, time/batch = 0.007\n",
      "2331/3300 (epoch 70), train_loss = -4.621, time/batch = 0.007\n",
      "2332/3300 (epoch 70), train_loss = -4.444, time/batch = 0.007\n",
      "2333/3300 (epoch 70), train_loss = -4.005, time/batch = 0.006\n",
      "2334/3300 (epoch 70), train_loss = -4.247, time/batch = 0.007\n",
      "2335/3300 (epoch 70), train_loss = -4.984, time/batch = 0.007\n",
      "2336/3300 (epoch 70), train_loss = -5.122, time/batch = 0.007\n",
      "2337/3300 (epoch 70), train_loss = -5.144, time/batch = 0.006\n",
      "2338/3300 (epoch 70), train_loss = -5.114, time/batch = 0.009\n",
      "2339/3300 (epoch 70), train_loss = -4.841, time/batch = 0.006\n",
      "2340/3300 (epoch 70), train_loss = -3.655, time/batch = 0.008\n",
      "2341/3300 (epoch 70), train_loss = -4.174, time/batch = 0.006\n",
      "2342/3300 (epoch 70), train_loss = -5.014, time/batch = 0.008\n",
      "2343/3300 (epoch 71), train_loss = -1.219, time/batch = 0.006\n",
      "2344/3300 (epoch 71), train_loss = -2.217, time/batch = 0.007\n",
      "2345/3300 (epoch 71), train_loss = -2.496, time/batch = 0.007\n",
      "2346/3300 (epoch 71), train_loss = -2.495, time/batch = 0.009\n",
      "2347/3300 (epoch 71), train_loss = -1.469, time/batch = 0.007\n",
      "2348/3300 (epoch 71), train_loss = -1.391, time/batch = 0.006\n",
      "2349/3300 (epoch 71), train_loss = -1.374, time/batch = 0.007\n",
      "2350/3300 (epoch 71), train_loss = -1.677, time/batch = 0.006\n",
      "2351/3300 (epoch 71), train_loss = -3.512, time/batch = 0.008\n",
      "2352/3300 (epoch 71), train_loss = -3.707, time/batch = 0.007\n",
      "2353/3300 (epoch 71), train_loss = -3.927, time/batch = 0.007\n",
      "2354/3300 (epoch 71), train_loss = -4.016, time/batch = 0.008\n",
      "2355/3300 (epoch 71), train_loss = -3.849, time/batch = 0.008\n",
      "2356/3300 (epoch 71), train_loss = -4.365, time/batch = 0.007\n",
      "2357/3300 (epoch 71), train_loss = -4.361, time/batch = 0.007\n",
      "2358/3300 (epoch 71), train_loss = -4.066, time/batch = 0.006\n",
      "2359/3300 (epoch 71), train_loss = -4.075, time/batch = 0.007\n",
      "2360/3300 (epoch 71), train_loss = -3.868, time/batch = 0.008\n",
      "2361/3300 (epoch 71), train_loss = -3.549, time/batch = 0.007\n",
      "2362/3300 (epoch 71), train_loss = -3.921, time/batch = 0.006\n",
      "2363/3300 (epoch 71), train_loss = -3.769, time/batch = 0.008\n",
      "2364/3300 (epoch 71), train_loss = -4.411, time/batch = 0.006\n",
      "2365/3300 (epoch 71), train_loss = -3.958, time/batch = 0.007\n",
      "2366/3300 (epoch 71), train_loss = -5.094, time/batch = 0.007\n",
      "2367/3300 (epoch 71), train_loss = -4.942, time/batch = 0.007\n",
      "2368/3300 (epoch 71), train_loss = -5.217, time/batch = 0.007\n",
      "2369/3300 (epoch 71), train_loss = -4.085, time/batch = 0.006\n",
      "2370/3300 (epoch 71), train_loss = -4.587, time/batch = 0.007\n",
      "2371/3300 (epoch 71), train_loss = -5.199, time/batch = 0.006\n",
      "2372/3300 (epoch 71), train_loss = -5.319, time/batch = 0.007\n",
      "2373/3300 (epoch 71), train_loss = -4.343, time/batch = 0.007\n",
      "2374/3300 (epoch 71), train_loss = -3.997, time/batch = 0.007\n",
      "2375/3300 (epoch 71), train_loss = -4.393, time/batch = 0.007\n",
      "2376/3300 (epoch 72), train_loss = -1.197, time/batch = 0.006\n",
      "2377/3300 (epoch 72), train_loss = -2.120, time/batch = 0.008\n",
      "2378/3300 (epoch 72), train_loss = -2.366, time/batch = 0.006\n",
      "2379/3300 (epoch 72), train_loss = -2.041, time/batch = 0.008\n",
      "2380/3300 (epoch 72), train_loss = -1.694, time/batch = 0.007\n",
      "2381/3300 (epoch 72), train_loss = -1.022, time/batch = 0.006\n",
      "2382/3300 (epoch 72), train_loss = -1.385, time/batch = 0.008\n",
      "2383/3300 (epoch 72), train_loss = -2.109, time/batch = 0.006\n",
      "2384/3300 (epoch 72), train_loss = -4.025, time/batch = 0.006\n",
      "2385/3300 (epoch 72), train_loss = -3.678, time/batch = 0.007\n",
      "2386/3300 (epoch 72), train_loss = -3.895, time/batch = 0.006\n",
      "2387/3300 (epoch 72), train_loss = -3.894, time/batch = 0.007\n",
      "2388/3300 (epoch 72), train_loss = -3.862, time/batch = 0.007\n",
      "2389/3300 (epoch 72), train_loss = -3.966, time/batch = 0.007\n",
      "2390/3300 (epoch 72), train_loss = -4.255, time/batch = 0.008\n",
      "2391/3300 (epoch 72), train_loss = -3.932, time/batch = 0.006\n",
      "2392/3300 (epoch 72), train_loss = -4.173, time/batch = 0.007\n",
      "2393/3300 (epoch 72), train_loss = -3.997, time/batch = 0.007\n",
      "2394/3300 (epoch 72), train_loss = -3.876, time/batch = 0.008\n",
      "2395/3300 (epoch 72), train_loss = -3.580, time/batch = 0.007\n",
      "2396/3300 (epoch 72), train_loss = -3.894, time/batch = 0.009\n",
      "2397/3300 (epoch 72), train_loss = -4.293, time/batch = 0.007\n",
      "2398/3300 (epoch 72), train_loss = -4.053, time/batch = 0.006\n",
      "2399/3300 (epoch 72), train_loss = -4.745, time/batch = 0.007\n",
      "2400/3300 (epoch 72), train_loss = -4.165, time/batch = 0.007\n",
      "2401/3300 (epoch 72), train_loss = -4.224, time/batch = 0.007\n",
      "2402/3300 (epoch 72), train_loss = -5.039, time/batch = 0.006\n",
      "2403/3300 (epoch 72), train_loss = -4.863, time/batch = 0.009\n",
      "2404/3300 (epoch 72), train_loss = -3.925, time/batch = 0.006\n",
      "2405/3300 (epoch 72), train_loss = -4.203, time/batch = 0.007\n",
      "2406/3300 (epoch 72), train_loss = -4.368, time/batch = 0.008\n",
      "2407/3300 (epoch 72), train_loss = -3.806, time/batch = 0.008\n",
      "2408/3300 (epoch 72), train_loss = -4.443, time/batch = 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2409/3300 (epoch 73), train_loss = -1.074, time/batch = 0.008\n",
      "2410/3300 (epoch 73), train_loss = -2.415, time/batch = 0.006\n",
      "2411/3300 (epoch 73), train_loss = -2.658, time/batch = 0.007\n",
      "2412/3300 (epoch 73), train_loss = -2.414, time/batch = 0.008\n",
      "2413/3300 (epoch 73), train_loss = -1.965, time/batch = 0.009\n",
      "2414/3300 (epoch 73), train_loss = -0.885, time/batch = 0.006\n",
      "2415/3300 (epoch 73), train_loss = -0.948, time/batch = 0.007\n",
      "2416/3300 (epoch 73), train_loss = -1.566, time/batch = 0.007\n",
      "2417/3300 (epoch 73), train_loss = -2.769, time/batch = 0.006\n",
      "2418/3300 (epoch 73), train_loss = -3.185, time/batch = 0.007\n",
      "2419/3300 (epoch 73), train_loss = -3.699, time/batch = 0.007\n",
      "2420/3300 (epoch 73), train_loss = -3.859, time/batch = 0.007\n",
      "2421/3300 (epoch 73), train_loss = -4.193, time/batch = 0.007\n",
      "2422/3300 (epoch 73), train_loss = -4.469, time/batch = 0.006\n",
      "2423/3300 (epoch 73), train_loss = -3.427, time/batch = 0.008\n",
      "2424/3300 (epoch 73), train_loss = -4.060, time/batch = 0.006\n",
      "2425/3300 (epoch 73), train_loss = -4.180, time/batch = 0.008\n",
      "2426/3300 (epoch 73), train_loss = -3.691, time/batch = 0.007\n",
      "2427/3300 (epoch 73), train_loss = -3.957, time/batch = 0.009\n",
      "2428/3300 (epoch 73), train_loss = -4.197, time/batch = 0.007\n",
      "2429/3300 (epoch 73), train_loss = -3.918, time/batch = 0.006\n",
      "2430/3300 (epoch 73), train_loss = -4.871, time/batch = 0.007\n",
      "2431/3300 (epoch 73), train_loss = -5.143, time/batch = 0.007\n",
      "2432/3300 (epoch 73), train_loss = -5.132, time/batch = 0.008\n",
      "2433/3300 (epoch 73), train_loss = -5.256, time/batch = 0.006\n",
      "2434/3300 (epoch 73), train_loss = -5.111, time/batch = 0.007\n",
      "2435/3300 (epoch 73), train_loss = -4.628, time/batch = 0.007\n",
      "2436/3300 (epoch 73), train_loss = -3.858, time/batch = 0.007\n",
      "2437/3300 (epoch 73), train_loss = -4.454, time/batch = 0.007\n",
      "2438/3300 (epoch 73), train_loss = -4.966, time/batch = 0.007\n",
      "2439/3300 (epoch 73), train_loss = -4.394, time/batch = 0.007\n",
      "2440/3300 (epoch 73), train_loss = -3.884, time/batch = 0.006\n",
      "2441/3300 (epoch 73), train_loss = -4.302, time/batch = 0.009\n",
      "2442/3300 (epoch 74), train_loss = -1.150, time/batch = 0.006\n",
      "2443/3300 (epoch 74), train_loss = -2.128, time/batch = 0.006\n",
      "2444/3300 (epoch 74), train_loss = -2.531, time/batch = 0.007\n",
      "2445/3300 (epoch 74), train_loss = -2.223, time/batch = 0.006\n",
      "2446/3300 (epoch 74), train_loss = -0.862, time/batch = 0.007\n",
      "2447/3300 (epoch 74), train_loss = -1.074, time/batch = 0.007\n",
      "2448/3300 (epoch 74), train_loss = -1.154, time/batch = 0.008\n",
      "2449/3300 (epoch 74), train_loss = -3.000, time/batch = 0.007\n",
      "2450/3300 (epoch 74), train_loss = -3.951, time/batch = 0.006\n",
      "2451/3300 (epoch 74), train_loss = -3.849, time/batch = 0.007\n",
      "2452/3300 (epoch 74), train_loss = -4.292, time/batch = 0.006\n",
      "2453/3300 (epoch 74), train_loss = -4.247, time/batch = 0.007\n",
      "2454/3300 (epoch 74), train_loss = -3.649, time/batch = 0.007\n",
      "2455/3300 (epoch 74), train_loss = -4.713, time/batch = 0.007\n",
      "2456/3300 (epoch 74), train_loss = -3.976, time/batch = 0.007\n",
      "2457/3300 (epoch 74), train_loss = -3.967, time/batch = 0.006\n",
      "2458/3300 (epoch 74), train_loss = -4.086, time/batch = 0.008\n",
      "2459/3300 (epoch 74), train_loss = -3.886, time/batch = 0.006\n",
      "2460/3300 (epoch 74), train_loss = -4.227, time/batch = 0.008\n",
      "2461/3300 (epoch 74), train_loss = -3.918, time/batch = 0.008\n",
      "2462/3300 (epoch 74), train_loss = -4.438, time/batch = 0.006\n",
      "2463/3300 (epoch 74), train_loss = -4.432, time/batch = 0.007\n",
      "2464/3300 (epoch 74), train_loss = -3.994, time/batch = 0.007\n",
      "2465/3300 (epoch 74), train_loss = -4.842, time/batch = 0.010\n",
      "2466/3300 (epoch 74), train_loss = -5.096, time/batch = 0.007\n",
      "2467/3300 (epoch 74), train_loss = -5.151, time/batch = 0.008\n",
      "2468/3300 (epoch 74), train_loss = -5.186, time/batch = 0.006\n",
      "2469/3300 (epoch 74), train_loss = -4.807, time/batch = 0.009\n",
      "2470/3300 (epoch 74), train_loss = -4.570, time/batch = 0.007\n",
      "2471/3300 (epoch 74), train_loss = -3.769, time/batch = 0.008\n",
      "2472/3300 (epoch 74), train_loss = -4.240, time/batch = 0.006\n",
      "2473/3300 (epoch 74), train_loss = -5.285, time/batch = 0.006\n",
      "2474/3300 (epoch 74), train_loss = -4.388, time/batch = 0.007\n",
      "2475/3300 (epoch 75), train_loss = -1.206, time/batch = 0.006\n",
      "2476/3300 (epoch 75), train_loss = -2.224, time/batch = 0.007\n",
      "2477/3300 (epoch 75), train_loss = -2.404, time/batch = 0.007\n",
      "2478/3300 (epoch 75), train_loss = -2.726, time/batch = 0.007\n",
      "2479/3300 (epoch 75), train_loss = -1.109, time/batch = 0.006\n",
      "2480/3300 (epoch 75), train_loss = -0.322, time/batch = 0.007\n",
      "2481/3300 (epoch 75), train_loss = -1.585, time/batch = 0.007\n",
      "2482/3300 (epoch 75), train_loss = -1.257, time/batch = 0.006\n",
      "2483/3300 (epoch 75), train_loss = -3.043, time/batch = 0.008\n",
      "2484/3300 (epoch 75), train_loss = -4.533, time/batch = 0.006\n",
      "2485/3300 (epoch 75), train_loss = -4.440, time/batch = 0.006\n",
      "2486/3300 (epoch 75), train_loss = -3.964, time/batch = 0.007\n",
      "2487/3300 (epoch 75), train_loss = -4.264, time/batch = 0.006\n",
      "2488/3300 (epoch 75), train_loss = -4.074, time/batch = 0.008\n",
      "2489/3300 (epoch 75), train_loss = -4.274, time/batch = 0.008\n",
      "2490/3300 (epoch 75), train_loss = -4.692, time/batch = 0.007\n",
      "2491/3300 (epoch 75), train_loss = -4.045, time/batch = 0.007\n",
      "2492/3300 (epoch 75), train_loss = -4.131, time/batch = 0.007\n",
      "2493/3300 (epoch 75), train_loss = -3.918, time/batch = 0.007\n",
      "2494/3300 (epoch 75), train_loss = -4.161, time/batch = 0.006\n",
      "2495/3300 (epoch 75), train_loss = -3.276, time/batch = 0.006\n",
      "2496/3300 (epoch 75), train_loss = -4.143, time/batch = 0.007\n",
      "2497/3300 (epoch 75), train_loss = -4.040, time/batch = 0.007\n",
      "2498/3300 (epoch 75), train_loss = -4.169, time/batch = 0.008\n",
      "2499/3300 (epoch 75), train_loss = -5.116, time/batch = 0.006\n",
      "2500/3300 (epoch 75), train_loss = -5.075, time/batch = 0.007\n",
      "2501/3300 (epoch 75), train_loss = -4.977, time/batch = 0.007\n",
      "2502/3300 (epoch 75), train_loss = -4.278, time/batch = 0.009\n",
      "2503/3300 (epoch 75), train_loss = -3.615, time/batch = 0.006\n",
      "2504/3300 (epoch 75), train_loss = -4.217, time/batch = 0.008\n",
      "2505/3300 (epoch 75), train_loss = -5.221, time/batch = 0.006\n",
      "2506/3300 (epoch 75), train_loss = -5.278, time/batch = 0.006\n",
      "2507/3300 (epoch 75), train_loss = -5.197, time/batch = 0.007\n",
      "2508/3300 (epoch 76), train_loss = -1.112, time/batch = 0.006\n",
      "2509/3300 (epoch 76), train_loss = -2.096, time/batch = 0.007\n",
      "2510/3300 (epoch 76), train_loss = -2.487, time/batch = 0.007\n",
      "2511/3300 (epoch 76), train_loss = -1.902, time/batch = 0.008\n",
      "2512/3300 (epoch 76), train_loss = -1.340, time/batch = 0.007\n",
      "2513/3300 (epoch 76), train_loss = -1.268, time/batch = 0.007\n",
      "2514/3300 (epoch 76), train_loss = -1.765, time/batch = 0.007\n",
      "2515/3300 (epoch 76), train_loss = -1.879, time/batch = 0.006\n",
      "2516/3300 (epoch 76), train_loss = -4.413, time/batch = 0.008\n",
      "2517/3300 (epoch 76), train_loss = -4.161, time/batch = 0.007\n",
      "2518/3300 (epoch 76), train_loss = -4.154, time/batch = 0.009\n",
      "2519/3300 (epoch 76), train_loss = -3.897, time/batch = 0.007\n",
      "2520/3300 (epoch 76), train_loss = -3.997, time/batch = 0.008\n",
      "2521/3300 (epoch 76), train_loss = -4.253, time/batch = 0.007\n",
      "2522/3300 (epoch 76), train_loss = -3.896, time/batch = 0.008\n",
      "2523/3300 (epoch 76), train_loss = -4.139, time/batch = 0.007\n",
      "2524/3300 (epoch 76), train_loss = -3.552, time/batch = 0.007\n",
      "2525/3300 (epoch 76), train_loss = -3.874, time/batch = 0.008\n",
      "2526/3300 (epoch 76), train_loss = -4.105, time/batch = 0.006\n",
      "2527/3300 (epoch 76), train_loss = -3.644, time/batch = 0.008\n",
      "2528/3300 (epoch 76), train_loss = -3.824, time/batch = 0.007\n",
      "2529/3300 (epoch 76), train_loss = -4.679, time/batch = 0.007\n",
      "2530/3300 (epoch 76), train_loss = -4.832, time/batch = 0.007\n",
      "2531/3300 (epoch 76), train_loss = -4.150, time/batch = 0.008\n",
      "2532/3300 (epoch 76), train_loss = -4.230, time/batch = 0.007\n",
      "2533/3300 (epoch 76), train_loss = -4.602, time/batch = 0.007\n",
      "2534/3300 (epoch 76), train_loss = -4.857, time/batch = 0.008\n",
      "2535/3300 (epoch 76), train_loss = -3.726, time/batch = 0.006\n",
      "2536/3300 (epoch 76), train_loss = -3.963, time/batch = 0.009\n",
      "2537/3300 (epoch 76), train_loss = -4.002, time/batch = 0.006\n",
      "2538/3300 (epoch 76), train_loss = -3.635, time/batch = 0.007\n",
      "2539/3300 (epoch 76), train_loss = -4.301, time/batch = 0.007\n",
      "2540/3300 (epoch 76), train_loss = -4.270, time/batch = 0.006\n",
      "2541/3300 (epoch 77), train_loss = -1.116, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2542/3300 (epoch 77), train_loss = -2.082, time/batch = 0.008\n",
      "2543/3300 (epoch 77), train_loss = -2.319, time/batch = 0.008\n",
      "2544/3300 (epoch 77), train_loss = -2.027, time/batch = 0.007\n",
      "2545/3300 (epoch 77), train_loss = -1.324, time/batch = 0.009\n",
      "2546/3300 (epoch 77), train_loss = -1.390, time/batch = 0.007\n",
      "2547/3300 (epoch 77), train_loss = -1.826, time/batch = 0.009\n",
      "2548/3300 (epoch 77), train_loss = -2.109, time/batch = 0.007\n",
      "2549/3300 (epoch 77), train_loss = -4.200, time/batch = 0.007\n",
      "2550/3300 (epoch 77), train_loss = -3.915, time/batch = 0.007\n",
      "2551/3300 (epoch 77), train_loss = -4.295, time/batch = 0.006\n",
      "2552/3300 (epoch 77), train_loss = -3.953, time/batch = 0.008\n",
      "2553/3300 (epoch 77), train_loss = -4.142, time/batch = 0.006\n",
      "2554/3300 (epoch 77), train_loss = -4.545, time/batch = 0.007\n",
      "2555/3300 (epoch 77), train_loss = -3.764, time/batch = 0.008\n",
      "2556/3300 (epoch 77), train_loss = -4.302, time/batch = 0.007\n",
      "2557/3300 (epoch 77), train_loss = -4.410, time/batch = 0.008\n",
      "2558/3300 (epoch 77), train_loss = -3.692, time/batch = 0.006\n",
      "2559/3300 (epoch 77), train_loss = -3.390, time/batch = 0.010\n",
      "2560/3300 (epoch 77), train_loss = -4.127, time/batch = 0.006\n",
      "2561/3300 (epoch 77), train_loss = -4.061, time/batch = 0.008\n",
      "2562/3300 (epoch 77), train_loss = -4.547, time/batch = 0.007\n",
      "2563/3300 (epoch 77), train_loss = -3.936, time/batch = 0.007\n",
      "2564/3300 (epoch 77), train_loss = -4.507, time/batch = 0.007\n",
      "2565/3300 (epoch 77), train_loss = -4.922, time/batch = 0.006\n",
      "2566/3300 (epoch 77), train_loss = -4.434, time/batch = 0.008\n",
      "2567/3300 (epoch 77), train_loss = -3.554, time/batch = 0.006\n",
      "2568/3300 (epoch 77), train_loss = -4.733, time/batch = 0.008\n",
      "2569/3300 (epoch 77), train_loss = -5.304, time/batch = 0.006\n",
      "2570/3300 (epoch 77), train_loss = -4.493, time/batch = 0.007\n",
      "2571/3300 (epoch 77), train_loss = -3.837, time/batch = 0.007\n",
      "2572/3300 (epoch 77), train_loss = -4.258, time/batch = 0.006\n",
      "2573/3300 (epoch 77), train_loss = -4.457, time/batch = 0.008\n",
      "2574/3300 (epoch 78), train_loss = -1.198, time/batch = 0.006\n",
      "2575/3300 (epoch 78), train_loss = -2.106, time/batch = 0.009\n",
      "2576/3300 (epoch 78), train_loss = -2.462, time/batch = 0.007\n",
      "2577/3300 (epoch 78), train_loss = -1.822, time/batch = 0.008\n",
      "2578/3300 (epoch 78), train_loss = -0.920, time/batch = 0.007\n",
      "2579/3300 (epoch 78), train_loss = -1.108, time/batch = 0.009\n",
      "2580/3300 (epoch 78), train_loss = -1.646, time/batch = 0.007\n",
      "2581/3300 (epoch 78), train_loss = -1.468, time/batch = 0.006\n",
      "2582/3300 (epoch 78), train_loss = -4.032, time/batch = 0.007\n",
      "2583/3300 (epoch 78), train_loss = -4.073, time/batch = 0.006\n",
      "2584/3300 (epoch 78), train_loss = -4.110, time/batch = 0.007\n",
      "2585/3300 (epoch 78), train_loss = -4.090, time/batch = 0.007\n",
      "2586/3300 (epoch 78), train_loss = -4.118, time/batch = 0.009\n",
      "2587/3300 (epoch 78), train_loss = -4.245, time/batch = 0.011\n",
      "2588/3300 (epoch 78), train_loss = -4.328, time/batch = 0.009\n",
      "2589/3300 (epoch 78), train_loss = -4.012, time/batch = 0.007\n",
      "2590/3300 (epoch 78), train_loss = -4.248, time/batch = 0.008\n",
      "2591/3300 (epoch 78), train_loss = -3.724, time/batch = 0.006\n",
      "2592/3300 (epoch 78), train_loss = -3.577, time/batch = 0.010\n",
      "2593/3300 (epoch 78), train_loss = -3.977, time/batch = 0.007\n",
      "2594/3300 (epoch 78), train_loss = -4.230, time/batch = 0.009\n",
      "2595/3300 (epoch 78), train_loss = -4.193, time/batch = 0.008\n",
      "2596/3300 (epoch 78), train_loss = -3.832, time/batch = 0.008\n",
      "2597/3300 (epoch 78), train_loss = -5.005, time/batch = 0.008\n",
      "2598/3300 (epoch 78), train_loss = -5.065, time/batch = 0.006\n",
      "2599/3300 (epoch 78), train_loss = -4.726, time/batch = 0.008\n",
      "2600/3300 (epoch 78), train_loss = -3.988, time/batch = 0.006\n",
      "2601/3300 (epoch 78), train_loss = -4.193, time/batch = 0.008\n",
      "2602/3300 (epoch 78), train_loss = -4.751, time/batch = 0.007\n",
      "2603/3300 (epoch 78), train_loss = -3.740, time/batch = 0.009\n",
      "2604/3300 (epoch 78), train_loss = -4.382, time/batch = 0.007\n",
      "2605/3300 (epoch 78), train_loss = -3.794, time/batch = 0.006\n",
      "2606/3300 (epoch 78), train_loss = -4.318, time/batch = 0.007\n",
      "2607/3300 (epoch 79), train_loss = -1.163, time/batch = 0.006\n",
      "2608/3300 (epoch 79), train_loss = -1.895, time/batch = 0.008\n",
      "2609/3300 (epoch 79), train_loss = -2.337, time/batch = 0.006\n",
      "2610/3300 (epoch 79), train_loss = -2.440, time/batch = 0.009\n",
      "2611/3300 (epoch 79), train_loss = -1.500, time/batch = 0.006\n",
      "2612/3300 (epoch 79), train_loss = -0.443, time/batch = 0.007\n",
      "2613/3300 (epoch 79), train_loss = -1.666, time/batch = 0.007\n",
      "2614/3300 (epoch 79), train_loss = -1.112, time/batch = 0.008\n",
      "2615/3300 (epoch 79), train_loss = -3.508, time/batch = 0.007\n",
      "2616/3300 (epoch 79), train_loss = -3.763, time/batch = 0.007\n",
      "2617/3300 (epoch 79), train_loss = -3.892, time/batch = 0.010\n",
      "2618/3300 (epoch 79), train_loss = -3.912, time/batch = 0.007\n",
      "2619/3300 (epoch 79), train_loss = -4.195, time/batch = 0.009\n",
      "2620/3300 (epoch 79), train_loss = -4.228, time/batch = 0.006\n",
      "2621/3300 (epoch 79), train_loss = -3.979, time/batch = 0.008\n",
      "2622/3300 (epoch 79), train_loss = -4.237, time/batch = 0.007\n",
      "2623/3300 (epoch 79), train_loss = -3.886, time/batch = 0.007\n",
      "2624/3300 (epoch 79), train_loss = -3.895, time/batch = 0.007\n",
      "2625/3300 (epoch 79), train_loss = -4.171, time/batch = 0.008\n",
      "2626/3300 (epoch 79), train_loss = -4.311, time/batch = 0.007\n",
      "2627/3300 (epoch 79), train_loss = -4.330, time/batch = 0.007\n",
      "2628/3300 (epoch 79), train_loss = -4.481, time/batch = 0.008\n",
      "2629/3300 (epoch 79), train_loss = -4.164, time/batch = 0.009\n",
      "2630/3300 (epoch 79), train_loss = -4.747, time/batch = 0.007\n",
      "2631/3300 (epoch 79), train_loss = -5.039, time/batch = 0.007\n",
      "2632/3300 (epoch 79), train_loss = -5.067, time/batch = 0.007\n",
      "2633/3300 (epoch 79), train_loss = -5.140, time/batch = 0.006\n",
      "2634/3300 (epoch 79), train_loss = -5.169, time/batch = 0.007\n",
      "2635/3300 (epoch 79), train_loss = -5.157, time/batch = 0.008\n",
      "2636/3300 (epoch 79), train_loss = -3.946, time/batch = 0.006\n",
      "2637/3300 (epoch 79), train_loss = -4.340, time/batch = 0.007\n",
      "2638/3300 (epoch 79), train_loss = -4.406, time/batch = 0.007\n",
      "2639/3300 (epoch 79), train_loss = -4.750, time/batch = 0.007\n",
      "2640/3300 (epoch 80), train_loss = -1.150, time/batch = 0.006\n",
      "2641/3300 (epoch 80), train_loss = -2.141, time/batch = 0.006\n",
      "2642/3300 (epoch 80), train_loss = -2.268, time/batch = 0.007\n",
      "2643/3300 (epoch 80), train_loss = -2.292, time/batch = 0.006\n",
      "2644/3300 (epoch 80), train_loss = -1.494, time/batch = 0.007\n",
      "2645/3300 (epoch 80), train_loss = -0.867, time/batch = 0.007\n",
      "2646/3300 (epoch 80), train_loss = -1.441, time/batch = 0.007\n",
      "2647/3300 (epoch 80), train_loss = -1.708, time/batch = 0.007\n",
      "2648/3300 (epoch 80), train_loss = -4.191, time/batch = 0.007\n",
      "2649/3300 (epoch 80), train_loss = -4.249, time/batch = 0.007\n",
      "2650/3300 (epoch 80), train_loss = -4.268, time/batch = 0.007\n",
      "2651/3300 (epoch 80), train_loss = -4.153, time/batch = 0.009\n",
      "2652/3300 (epoch 80), train_loss = -3.978, time/batch = 0.007\n",
      "2653/3300 (epoch 80), train_loss = -4.411, time/batch = 0.006\n",
      "2654/3300 (epoch 80), train_loss = -4.308, time/batch = 0.007\n",
      "2655/3300 (epoch 80), train_loss = -4.088, time/batch = 0.006\n",
      "2656/3300 (epoch 80), train_loss = -4.284, time/batch = 0.008\n",
      "2657/3300 (epoch 80), train_loss = -3.746, time/batch = 0.007\n",
      "2658/3300 (epoch 80), train_loss = -3.479, time/batch = 0.009\n",
      "2659/3300 (epoch 80), train_loss = -3.824, time/batch = 0.007\n",
      "2660/3300 (epoch 80), train_loss = -4.235, time/batch = 0.009\n",
      "2661/3300 (epoch 80), train_loss = -4.559, time/batch = 0.007\n",
      "2662/3300 (epoch 80), train_loss = -3.715, time/batch = 0.010\n",
      "2663/3300 (epoch 80), train_loss = -4.966, time/batch = 0.007\n",
      "2664/3300 (epoch 80), train_loss = -5.148, time/batch = 0.009\n",
      "2665/3300 (epoch 80), train_loss = -5.213, time/batch = 0.007\n",
      "2666/3300 (epoch 80), train_loss = -4.739, time/batch = 0.008\n",
      "2667/3300 (epoch 80), train_loss = -4.292, time/batch = 0.006\n",
      "2668/3300 (epoch 80), train_loss = -4.188, time/batch = 0.007\n",
      "2669/3300 (epoch 80), train_loss = -5.131, time/batch = 0.007\n",
      "2670/3300 (epoch 80), train_loss = -3.807, time/batch = 0.007\n",
      "2671/3300 (epoch 80), train_loss = -4.864, time/batch = 0.008\n",
      "2672/3300 (epoch 80), train_loss = -5.031, time/batch = 0.007\n",
      "2673/3300 (epoch 81), train_loss = -1.174, time/batch = 0.006\n",
      "2674/3300 (epoch 81), train_loss = -2.030, time/batch = 0.006\n",
      "2675/3300 (epoch 81), train_loss = -2.339, time/batch = 0.008\n",
      "2676/3300 (epoch 81), train_loss = -1.741, time/batch = 0.006\n",
      "2677/3300 (epoch 81), train_loss = -0.488, time/batch = 0.008\n",
      "2678/3300 (epoch 81), train_loss = -0.790, time/batch = 0.007\n",
      "2679/3300 (epoch 81), train_loss = -1.483, time/batch = 0.007\n",
      "2680/3300 (epoch 81), train_loss = -2.710, time/batch = 0.007\n",
      "2681/3300 (epoch 81), train_loss = -4.049, time/batch = 0.007\n",
      "2682/3300 (epoch 81), train_loss = -4.022, time/batch = 0.007\n",
      "2683/3300 (epoch 81), train_loss = -4.156, time/batch = 0.009\n",
      "2684/3300 (epoch 81), train_loss = -4.023, time/batch = 0.008\n",
      "2685/3300 (epoch 81), train_loss = -4.633, time/batch = 0.007\n",
      "2686/3300 (epoch 81), train_loss = -4.358, time/batch = 0.007\n",
      "2687/3300 (epoch 81), train_loss = -3.971, time/batch = 0.006\n",
      "2688/3300 (epoch 81), train_loss = -4.227, time/batch = 0.008\n",
      "2689/3300 (epoch 81), train_loss = -3.887, time/batch = 0.007\n",
      "2690/3300 (epoch 81), train_loss = -3.914, time/batch = 0.007\n",
      "2691/3300 (epoch 81), train_loss = -4.135, time/batch = 0.010\n",
      "2692/3300 (epoch 81), train_loss = -4.325, time/batch = 0.006\n",
      "2693/3300 (epoch 81), train_loss = -3.618, time/batch = 0.008\n",
      "2694/3300 (epoch 81), train_loss = -4.324, time/batch = 0.007\n",
      "2695/3300 (epoch 81), train_loss = -5.120, time/batch = 0.009\n",
      "2696/3300 (epoch 81), train_loss = -5.209, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2697/3300 (epoch 81), train_loss = -5.200, time/batch = 0.006\n",
      "2698/3300 (epoch 81), train_loss = -4.937, time/batch = 0.008\n",
      "2699/3300 (epoch 81), train_loss = -4.127, time/batch = 0.006\n",
      "2700/3300 (epoch 81), train_loss = -4.354, time/batch = 0.007\n",
      "2701/3300 (epoch 81), train_loss = -4.959, time/batch = 0.006\n",
      "2702/3300 (epoch 81), train_loss = -5.383, time/batch = 0.006\n",
      "2703/3300 (epoch 81), train_loss = -5.484, time/batch = 0.007\n",
      "2704/3300 (epoch 81), train_loss = -5.326, time/batch = 0.007\n",
      "2705/3300 (epoch 81), train_loss = -4.450, time/batch = 0.007\n",
      "2706/3300 (epoch 82), train_loss = -1.117, time/batch = 0.006\n",
      "2707/3300 (epoch 82), train_loss = -2.416, time/batch = 0.008\n",
      "2708/3300 (epoch 82), train_loss = -2.493, time/batch = 0.006\n",
      "2709/3300 (epoch 82), train_loss = -1.647, time/batch = 0.009\n",
      "2710/3300 (epoch 82), train_loss = -1.700, time/batch = 0.006\n",
      "2711/3300 (epoch 82), train_loss = 1.278, time/batch = 0.006\n",
      "2712/3300 (epoch 82), train_loss = -0.227, time/batch = 0.007\n",
      "2713/3300 (epoch 82), train_loss = -0.327, time/batch = 0.006\n",
      "2714/3300 (epoch 82), train_loss = -3.889, time/batch = 0.009\n",
      "2715/3300 (epoch 82), train_loss = -4.324, time/batch = 0.007\n",
      "2716/3300 (epoch 82), train_loss = -3.941, time/batch = 0.007\n",
      "2717/3300 (epoch 82), train_loss = -4.092, time/batch = 0.006\n",
      "2718/3300 (epoch 82), train_loss = -3.905, time/batch = 0.007\n",
      "2719/3300 (epoch 82), train_loss = -4.087, time/batch = 0.007\n",
      "2720/3300 (epoch 82), train_loss = -4.537, time/batch = 0.006\n",
      "2721/3300 (epoch 82), train_loss = -4.240, time/batch = 0.007\n",
      "2722/3300 (epoch 82), train_loss = -4.415, time/batch = 0.006\n",
      "2723/3300 (epoch 82), train_loss = -3.038, time/batch = 0.006\n",
      "2724/3300 (epoch 82), train_loss = -3.786, time/batch = 0.007\n",
      "2725/3300 (epoch 82), train_loss = -3.879, time/batch = 0.006\n",
      "2726/3300 (epoch 82), train_loss = -4.278, time/batch = 0.006\n",
      "2727/3300 (epoch 82), train_loss = -3.904, time/batch = 0.006\n",
      "2728/3300 (epoch 82), train_loss = -4.989, time/batch = 0.006\n",
      "2729/3300 (epoch 82), train_loss = -4.659, time/batch = 0.008\n",
      "2730/3300 (epoch 82), train_loss = -4.104, time/batch = 0.007\n",
      "2731/3300 (epoch 82), train_loss = -4.017, time/batch = 0.008\n",
      "2732/3300 (epoch 82), train_loss = -4.312, time/batch = 0.007\n",
      "2733/3300 (epoch 82), train_loss = -5.098, time/batch = 0.007\n",
      "2734/3300 (epoch 82), train_loss = -5.438, time/batch = 0.008\n",
      "2735/3300 (epoch 82), train_loss = -5.158, time/batch = 0.006\n",
      "2736/3300 (epoch 82), train_loss = -3.650, time/batch = 0.010\n",
      "2737/3300 (epoch 82), train_loss = -4.325, time/batch = 0.006\n",
      "2738/3300 (epoch 82), train_loss = -4.311, time/batch = 0.006\n",
      "2739/3300 (epoch 83), train_loss = -1.170, time/batch = 0.006\n",
      "2740/3300 (epoch 83), train_loss = -2.103, time/batch = 0.007\n",
      "2741/3300 (epoch 83), train_loss = -2.335, time/batch = 0.007\n",
      "2742/3300 (epoch 83), train_loss = -1.688, time/batch = 0.007\n",
      "2743/3300 (epoch 83), train_loss = -0.340, time/batch = 0.007\n",
      "2744/3300 (epoch 83), train_loss = -0.925, time/batch = 0.007\n",
      "2745/3300 (epoch 83), train_loss = -1.218, time/batch = 0.007\n",
      "2746/3300 (epoch 83), train_loss = -2.636, time/batch = 0.006\n",
      "2747/3300 (epoch 83), train_loss = -3.882, time/batch = 0.006\n",
      "2748/3300 (epoch 83), train_loss = -4.106, time/batch = 0.006\n",
      "2749/3300 (epoch 83), train_loss = -3.883, time/batch = 0.006\n",
      "2750/3300 (epoch 83), train_loss = -4.126, time/batch = 0.006\n",
      "2751/3300 (epoch 83), train_loss = -4.560, time/batch = 0.008\n",
      "2752/3300 (epoch 83), train_loss = -4.539, time/batch = 0.009\n",
      "2753/3300 (epoch 83), train_loss = -4.269, time/batch = 0.007\n",
      "2754/3300 (epoch 83), train_loss = -4.185, time/batch = 0.006\n",
      "2755/3300 (epoch 83), train_loss = -3.828, time/batch = 0.008\n",
      "2756/3300 (epoch 83), train_loss = -3.584, time/batch = 0.007\n",
      "2757/3300 (epoch 83), train_loss = -4.212, time/batch = 0.008\n",
      "2758/3300 (epoch 83), train_loss = -4.105, time/batch = 0.007\n",
      "2759/3300 (epoch 83), train_loss = -4.031, time/batch = 0.009\n",
      "2760/3300 (epoch 83), train_loss = -4.434, time/batch = 0.006\n",
      "2761/3300 (epoch 83), train_loss = -4.104, time/batch = 0.006\n",
      "2762/3300 (epoch 83), train_loss = -3.950, time/batch = 0.007\n",
      "2763/3300 (epoch 83), train_loss = -5.187, time/batch = 0.006\n",
      "2764/3300 (epoch 83), train_loss = -4.587, time/batch = 0.008\n",
      "2765/3300 (epoch 83), train_loss = -3.950, time/batch = 0.006\n",
      "2766/3300 (epoch 83), train_loss = -4.739, time/batch = 0.009\n",
      "2767/3300 (epoch 83), train_loss = -3.885, time/batch = 0.007\n",
      "2768/3300 (epoch 83), train_loss = -4.183, time/batch = 0.006\n",
      "2769/3300 (epoch 83), train_loss = -4.154, time/batch = 0.007\n",
      "2770/3300 (epoch 83), train_loss = -4.436, time/batch = 0.007\n",
      "2771/3300 (epoch 83), train_loss = -4.093, time/batch = 0.007\n",
      "2772/3300 (epoch 84), train_loss = -1.152, time/batch = 0.006\n",
      "2773/3300 (epoch 84), train_loss = -2.011, time/batch = 0.006\n",
      "2774/3300 (epoch 84), train_loss = -2.364, time/batch = 0.006\n",
      "2775/3300 (epoch 84), train_loss = -1.704, time/batch = 0.007\n",
      "2776/3300 (epoch 84), train_loss = -1.280, time/batch = 0.006\n",
      "2777/3300 (epoch 84), train_loss = -0.670, time/batch = 0.007\n",
      "2778/3300 (epoch 84), train_loss = -1.144, time/batch = 0.006\n",
      "2779/3300 (epoch 84), train_loss = -1.991, time/batch = 0.007\n",
      "2780/3300 (epoch 84), train_loss = -4.520, time/batch = 0.006\n",
      "2781/3300 (epoch 84), train_loss = -3.607, time/batch = 0.007\n",
      "2782/3300 (epoch 84), train_loss = -4.320, time/batch = 0.006\n",
      "2783/3300 (epoch 84), train_loss = -4.096, time/batch = 0.010\n",
      "2784/3300 (epoch 84), train_loss = -4.189, time/batch = 0.006\n",
      "2785/3300 (epoch 84), train_loss = -4.472, time/batch = 0.007\n",
      "2786/3300 (epoch 84), train_loss = -4.481, time/batch = 0.009\n",
      "2787/3300 (epoch 84), train_loss = -4.086, time/batch = 0.008\n",
      "2788/3300 (epoch 84), train_loss = -4.012, time/batch = 0.007\n",
      "2789/3300 (epoch 84), train_loss = -4.417, time/batch = 0.006\n",
      "2790/3300 (epoch 84), train_loss = -3.968, time/batch = 0.007\n",
      "2791/3300 (epoch 84), train_loss = -3.696, time/batch = 0.006\n",
      "2792/3300 (epoch 84), train_loss = -4.064, time/batch = 0.008\n",
      "2793/3300 (epoch 84), train_loss = -4.623, time/batch = 0.006\n",
      "2794/3300 (epoch 84), train_loss = -4.245, time/batch = 0.009\n",
      "2795/3300 (epoch 84), train_loss = -4.866, time/batch = 0.007\n",
      "2796/3300 (epoch 84), train_loss = -5.201, time/batch = 0.007\n",
      "2797/3300 (epoch 84), train_loss = -4.921, time/batch = 0.008\n",
      "2798/3300 (epoch 84), train_loss = -4.800, time/batch = 0.007\n",
      "2799/3300 (epoch 84), train_loss = -4.161, time/batch = 0.008\n",
      "2800/3300 (epoch 84), train_loss = -3.931, time/batch = 0.006\n",
      "2801/3300 (epoch 84), train_loss = -5.089, time/batch = 0.007\n",
      "2802/3300 (epoch 84), train_loss = -5.408, time/batch = 0.006\n",
      "2803/3300 (epoch 84), train_loss = -4.470, time/batch = 0.006\n",
      "2804/3300 (epoch 84), train_loss = -3.959, time/batch = 0.006\n",
      "2805/3300 (epoch 85), train_loss = -1.154, time/batch = 0.006\n",
      "2806/3300 (epoch 85), train_loss = -2.091, time/batch = 0.006\n",
      "2807/3300 (epoch 85), train_loss = -2.286, time/batch = 0.006\n",
      "2808/3300 (epoch 85), train_loss = -2.006, time/batch = 0.007\n",
      "2809/3300 (epoch 85), train_loss = -1.087, time/batch = 0.008\n",
      "2810/3300 (epoch 85), train_loss = -0.060, time/batch = 0.006\n",
      "2811/3300 (epoch 85), train_loss = -0.540, time/batch = 0.009\n",
      "2812/3300 (epoch 85), train_loss = -2.136, time/batch = 0.007\n",
      "2813/3300 (epoch 85), train_loss = -4.443, time/batch = 0.009\n",
      "2814/3300 (epoch 85), train_loss = -4.024, time/batch = 0.007\n",
      "2815/3300 (epoch 85), train_loss = -4.230, time/batch = 0.009\n",
      "2816/3300 (epoch 85), train_loss = -3.933, time/batch = 0.007\n",
      "2817/3300 (epoch 85), train_loss = -4.045, time/batch = 0.007\n",
      "2818/3300 (epoch 85), train_loss = -4.420, time/batch = 0.008\n",
      "2819/3300 (epoch 85), train_loss = -3.780, time/batch = 0.008\n",
      "2820/3300 (epoch 85), train_loss = -4.419, time/batch = 0.007\n",
      "2821/3300 (epoch 85), train_loss = -4.058, time/batch = 0.006\n",
      "2822/3300 (epoch 85), train_loss = -3.702, time/batch = 0.007\n",
      "2823/3300 (epoch 85), train_loss = -4.185, time/batch = 0.007\n",
      "2824/3300 (epoch 85), train_loss = -4.059, time/batch = 0.008\n",
      "2825/3300 (epoch 85), train_loss = -4.279, time/batch = 0.006\n",
      "2826/3300 (epoch 85), train_loss = -4.421, time/batch = 0.006\n",
      "2827/3300 (epoch 85), train_loss = -4.335, time/batch = 0.006\n",
      "2828/3300 (epoch 85), train_loss = -5.152, time/batch = 0.006\n",
      "2829/3300 (epoch 85), train_loss = -5.188, time/batch = 0.006\n",
      "2830/3300 (epoch 85), train_loss = -5.310, time/batch = 0.006\n",
      "2831/3300 (epoch 85), train_loss = -4.337, time/batch = 0.006\n",
      "2832/3300 (epoch 85), train_loss = -4.608, time/batch = 0.006\n",
      "2833/3300 (epoch 85), train_loss = -3.660, time/batch = 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2834/3300 (epoch 85), train_loss = -4.463, time/batch = 0.007\n",
      "2835/3300 (epoch 85), train_loss = -5.239, time/batch = 0.007\n",
      "2836/3300 (epoch 85), train_loss = -5.371, time/batch = 0.006\n",
      "2837/3300 (epoch 85), train_loss = -5.493, time/batch = 0.010\n",
      "2838/3300 (epoch 86), train_loss = -1.109, time/batch = 0.006\n",
      "2839/3300 (epoch 86), train_loss = -1.959, time/batch = 0.008\n",
      "2840/3300 (epoch 86), train_loss = -2.292, time/batch = 0.007\n",
      "2841/3300 (epoch 86), train_loss = -2.136, time/batch = 0.008\n",
      "2842/3300 (epoch 86), train_loss = -0.690, time/batch = 0.007\n",
      "2843/3300 (epoch 86), train_loss = 0.823, time/batch = 0.008\n",
      "2844/3300 (epoch 86), train_loss = -0.655, time/batch = 0.007\n",
      "2845/3300 (epoch 86), train_loss = -0.233, time/batch = 0.010\n",
      "2846/3300 (epoch 86), train_loss = -3.156, time/batch = 0.008\n",
      "2847/3300 (epoch 86), train_loss = -4.158, time/batch = 0.007\n",
      "2848/3300 (epoch 86), train_loss = -4.314, time/batch = 0.008\n",
      "2849/3300 (epoch 86), train_loss = -4.130, time/batch = 0.007\n",
      "2850/3300 (epoch 86), train_loss = -4.292, time/batch = 0.007\n",
      "2851/3300 (epoch 86), train_loss = -4.344, time/batch = 0.007\n",
      "2852/3300 (epoch 86), train_loss = -4.579, time/batch = 0.007\n",
      "2853/3300 (epoch 86), train_loss = -4.423, time/batch = 0.007\n",
      "2854/3300 (epoch 86), train_loss = -4.665, time/batch = 0.006\n",
      "2855/3300 (epoch 86), train_loss = -4.049, time/batch = 0.007\n",
      "2856/3300 (epoch 86), train_loss = -3.289, time/batch = 0.006\n",
      "2857/3300 (epoch 86), train_loss = -4.134, time/batch = 0.006\n",
      "2858/3300 (epoch 86), train_loss = -4.496, time/batch = 0.007\n",
      "2859/3300 (epoch 86), train_loss = -4.154, time/batch = 0.006\n",
      "2860/3300 (epoch 86), train_loss = -4.266, time/batch = 0.006\n",
      "2861/3300 (epoch 86), train_loss = -4.167, time/batch = 0.006\n",
      "2862/3300 (epoch 86), train_loss = -5.266, time/batch = 0.006\n",
      "2863/3300 (epoch 86), train_loss = -4.975, time/batch = 0.007\n",
      "2864/3300 (epoch 86), train_loss = -4.561, time/batch = 0.006\n",
      "2865/3300 (epoch 86), train_loss = -3.546, time/batch = 0.008\n",
      "2866/3300 (epoch 86), train_loss = -4.479, time/batch = 0.006\n",
      "2867/3300 (epoch 86), train_loss = -5.152, time/batch = 0.008\n",
      "2868/3300 (epoch 86), train_loss = -5.399, time/batch = 0.007\n",
      "2869/3300 (epoch 86), train_loss = -4.538, time/batch = 0.008\n",
      "2870/3300 (epoch 86), train_loss = -4.295, time/batch = 0.007\n",
      "2871/3300 (epoch 87), train_loss = -1.110, time/batch = 0.006\n",
      "2872/3300 (epoch 87), train_loss = -2.344, time/batch = 0.008\n",
      "2873/3300 (epoch 87), train_loss = -2.164, time/batch = 0.007\n",
      "2874/3300 (epoch 87), train_loss = -1.715, time/batch = 0.008\n",
      "2875/3300 (epoch 87), train_loss = -1.672, time/batch = 0.006\n",
      "2876/3300 (epoch 87), train_loss = 1.765, time/batch = 0.008\n",
      "2877/3300 (epoch 87), train_loss = 0.214, time/batch = 0.007\n",
      "2878/3300 (epoch 87), train_loss = 0.464, time/batch = 0.008\n",
      "2879/3300 (epoch 87), train_loss = -2.560, time/batch = 0.007\n",
      "2880/3300 (epoch 87), train_loss = -4.767, time/batch = 0.008\n",
      "2881/3300 (epoch 87), train_loss = -4.176, time/batch = 0.007\n",
      "2882/3300 (epoch 87), train_loss = -4.196, time/batch = 0.006\n",
      "2883/3300 (epoch 87), train_loss = -4.238, time/batch = 0.006\n",
      "2884/3300 (epoch 87), train_loss = -4.166, time/batch = 0.007\n",
      "2885/3300 (epoch 87), train_loss = -4.512, time/batch = 0.007\n",
      "2886/3300 (epoch 87), train_loss = -3.840, time/batch = 0.007\n",
      "2887/3300 (epoch 87), train_loss = -4.378, time/batch = 0.006\n",
      "2888/3300 (epoch 87), train_loss = -4.484, time/batch = 0.006\n",
      "2889/3300 (epoch 87), train_loss = -3.953, time/batch = 0.007\n",
      "2890/3300 (epoch 87), train_loss = -3.393, time/batch = 0.007\n",
      "2891/3300 (epoch 87), train_loss = -4.224, time/batch = 0.008\n",
      "2892/3300 (epoch 87), train_loss = -4.149, time/batch = 0.007\n",
      "2893/3300 (epoch 87), train_loss = -4.587, time/batch = 0.007\n",
      "2894/3300 (epoch 87), train_loss = -4.180, time/batch = 0.006\n",
      "2895/3300 (epoch 87), train_loss = -4.775, time/batch = 0.009\n",
      "2896/3300 (epoch 87), train_loss = -5.275, time/batch = 0.007\n",
      "2897/3300 (epoch 87), train_loss = -5.314, time/batch = 0.007\n",
      "2898/3300 (epoch 87), train_loss = -5.316, time/batch = 0.007\n",
      "2899/3300 (epoch 87), train_loss = -5.330, time/batch = 0.007\n",
      "2900/3300 (epoch 87), train_loss = -4.765, time/batch = 0.008\n",
      "2901/3300 (epoch 87), train_loss = -3.711, time/batch = 0.006\n",
      "2902/3300 (epoch 87), train_loss = -4.269, time/batch = 0.009\n",
      "2903/3300 (epoch 87), train_loss = -4.817, time/batch = 0.007\n",
      "2904/3300 (epoch 88), train_loss = -1.147, time/batch = 0.007\n",
      "2905/3300 (epoch 88), train_loss = -2.199, time/batch = 0.006\n",
      "2906/3300 (epoch 88), train_loss = -2.196, time/batch = 0.007\n",
      "2907/3300 (epoch 88), train_loss = -2.560, time/batch = 0.006\n",
      "2908/3300 (epoch 88), train_loss = -1.736, time/batch = 0.006\n",
      "2909/3300 (epoch 88), train_loss = 1.247, time/batch = 0.007\n",
      "2910/3300 (epoch 88), train_loss = 0.348, time/batch = 0.007\n",
      "2911/3300 (epoch 88), train_loss = -0.333, time/batch = 0.006\n",
      "2912/3300 (epoch 88), train_loss = -2.080, time/batch = 0.006\n",
      "2913/3300 (epoch 88), train_loss = -2.724, time/batch = 0.008\n",
      "2914/3300 (epoch 88), train_loss = -4.203, time/batch = 0.006\n",
      "2915/3300 (epoch 88), train_loss = -4.276, time/batch = 0.007\n",
      "2916/3300 (epoch 88), train_loss = -4.269, time/batch = 0.009\n",
      "2917/3300 (epoch 88), train_loss = -4.423, time/batch = 0.007\n",
      "2918/3300 (epoch 88), train_loss = -4.395, time/batch = 0.007\n",
      "2919/3300 (epoch 88), train_loss = -4.121, time/batch = 0.008\n",
      "2920/3300 (epoch 88), train_loss = -4.181, time/batch = 0.009\n",
      "2921/3300 (epoch 88), train_loss = -3.828, time/batch = 0.007\n",
      "2922/3300 (epoch 88), train_loss = -3.669, time/batch = 0.007\n",
      "2923/3300 (epoch 88), train_loss = -4.038, time/batch = 0.008\n",
      "2924/3300 (epoch 88), train_loss = -4.143, time/batch = 0.007\n",
      "2925/3300 (epoch 88), train_loss = -4.660, time/batch = 0.007\n",
      "2926/3300 (epoch 88), train_loss = -4.124, time/batch = 0.007\n",
      "2927/3300 (epoch 88), train_loss = -4.556, time/batch = 0.011\n",
      "2928/3300 (epoch 88), train_loss = -5.174, time/batch = 0.007\n",
      "2929/3300 (epoch 88), train_loss = -5.223, time/batch = 0.007\n",
      "2930/3300 (epoch 88), train_loss = -5.296, time/batch = 0.007\n",
      "2931/3300 (epoch 88), train_loss = -5.280, time/batch = 0.006\n",
      "2932/3300 (epoch 88), train_loss = -5.351, time/batch = 0.007\n",
      "2933/3300 (epoch 88), train_loss = -5.361, time/batch = 0.006\n",
      "2934/3300 (epoch 88), train_loss = -5.318, time/batch = 0.009\n",
      "2935/3300 (epoch 88), train_loss = -5.252, time/batch = 0.006\n",
      "2936/3300 (epoch 88), train_loss = -4.180, time/batch = 0.006\n",
      "2937/3300 (epoch 89), train_loss = -1.188, time/batch = 0.006\n",
      "2938/3300 (epoch 89), train_loss = -2.376, time/batch = 0.006\n",
      "2939/3300 (epoch 89), train_loss = -2.286, time/batch = 0.007\n",
      "2940/3300 (epoch 89), train_loss = -2.023, time/batch = 0.006\n",
      "2941/3300 (epoch 89), train_loss = -0.697, time/batch = 0.006\n",
      "2942/3300 (epoch 89), train_loss = -0.000, time/batch = 0.007\n",
      "2943/3300 (epoch 89), train_loss = -0.468, time/batch = 0.006\n",
      "2944/3300 (epoch 89), train_loss = -0.705, time/batch = 0.008\n",
      "2945/3300 (epoch 89), train_loss = -2.859, time/batch = 0.006\n",
      "2946/3300 (epoch 89), train_loss = -3.692, time/batch = 0.007\n",
      "2947/3300 (epoch 89), train_loss = -4.283, time/batch = 0.007\n",
      "2948/3300 (epoch 89), train_loss = -4.015, time/batch = 0.006\n",
      "2949/3300 (epoch 89), train_loss = -4.210, time/batch = 0.009\n",
      "2950/3300 (epoch 89), train_loss = -4.443, time/batch = 0.006\n",
      "2951/3300 (epoch 89), train_loss = -4.481, time/batch = 0.007\n",
      "2952/3300 (epoch 89), train_loss = -4.139, time/batch = 0.007\n",
      "2953/3300 (epoch 89), train_loss = -4.232, time/batch = 0.007\n",
      "2954/3300 (epoch 89), train_loss = -4.350, time/batch = 0.007\n",
      "2955/3300 (epoch 89), train_loss = -3.324, time/batch = 0.007\n",
      "2956/3300 (epoch 89), train_loss = -3.913, time/batch = 0.007\n",
      "2957/3300 (epoch 89), train_loss = -4.145, time/batch = 0.006\n",
      "2958/3300 (epoch 89), train_loss = -4.210, time/batch = 0.008\n",
      "2959/3300 (epoch 89), train_loss = -4.213, time/batch = 0.007\n",
      "2960/3300 (epoch 89), train_loss = -4.552, time/batch = 0.006\n",
      "2961/3300 (epoch 89), train_loss = -4.856, time/batch = 0.008\n",
      "2962/3300 (epoch 89), train_loss = -3.266, time/batch = 0.006\n",
      "2963/3300 (epoch 89), train_loss = -4.627, time/batch = 0.007\n",
      "2964/3300 (epoch 89), train_loss = -5.234, time/batch = 0.006\n",
      "2965/3300 (epoch 89), train_loss = -5.442, time/batch = 0.006\n",
      "2966/3300 (epoch 89), train_loss = -5.235, time/batch = 0.006\n",
      "2967/3300 (epoch 89), train_loss = -4.318, time/batch = 0.006\n",
      "2968/3300 (epoch 89), train_loss = -4.348, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2969/3300 (epoch 89), train_loss = -4.507, time/batch = 0.006\n",
      "2970/3300 (epoch 90), train_loss = -1.165, time/batch = 0.008\n",
      "2971/3300 (epoch 90), train_loss = -2.338, time/batch = 0.007\n",
      "2972/3300 (epoch 90), train_loss = -2.027, time/batch = 0.006\n",
      "2973/3300 (epoch 90), train_loss = -2.343, time/batch = 0.010\n",
      "2974/3300 (epoch 90), train_loss = -2.120, time/batch = 0.006\n",
      "2975/3300 (epoch 90), train_loss = 0.802, time/batch = 0.009\n",
      "2976/3300 (epoch 90), train_loss = 0.068, time/batch = 0.006\n",
      "2977/3300 (epoch 90), train_loss = 0.846, time/batch = 0.008\n",
      "2978/3300 (epoch 90), train_loss = -2.587, time/batch = 0.007\n",
      "2979/3300 (epoch 90), train_loss = -4.067, time/batch = 0.008\n",
      "2980/3300 (epoch 90), train_loss = -4.300, time/batch = 0.007\n",
      "2981/3300 (epoch 90), train_loss = -4.323, time/batch = 0.007\n",
      "2982/3300 (epoch 90), train_loss = -4.150, time/batch = 0.008\n",
      "2983/3300 (epoch 90), train_loss = -4.566, time/batch = 0.006\n",
      "2984/3300 (epoch 90), train_loss = -3.816, time/batch = 0.006\n",
      "2985/3300 (epoch 90), train_loss = -4.443, time/batch = 0.007\n",
      "2986/3300 (epoch 90), train_loss = -3.712, time/batch = 0.007\n",
      "2987/3300 (epoch 90), train_loss = -4.233, time/batch = 0.008\n",
      "2988/3300 (epoch 90), train_loss = -4.118, time/batch = 0.007\n",
      "2989/3300 (epoch 90), train_loss = -4.013, time/batch = 0.006\n",
      "2990/3300 (epoch 90), train_loss = -4.475, time/batch = 0.006\n",
      "2991/3300 (epoch 90), train_loss = -4.516, time/batch = 0.007\n",
      "2992/3300 (epoch 90), train_loss = -4.197, time/batch = 0.007\n",
      "2993/3300 (epoch 90), train_loss = -5.178, time/batch = 0.006\n",
      "2994/3300 (epoch 90), train_loss = -5.174, time/batch = 0.006\n",
      "2995/3300 (epoch 90), train_loss = -3.836, time/batch = 0.006\n",
      "2996/3300 (epoch 90), train_loss = -4.455, time/batch = 0.009\n",
      "2997/3300 (epoch 90), train_loss = -5.336, time/batch = 0.006\n",
      "2998/3300 (epoch 90), train_loss = -5.430, time/batch = 0.006\n",
      "2999/3300 (epoch 90), train_loss = -5.470, time/batch = 0.007\n",
      "3000/3300 (epoch 90), train_loss = -5.452, time/batch = 0.006\n",
      "3001/3300 (epoch 90), train_loss = -5.500, time/batch = 0.007\n",
      "3002/3300 (epoch 90), train_loss = -4.159, time/batch = 0.007\n",
      "3003/3300 (epoch 91), train_loss = -1.150, time/batch = 0.006\n",
      "3004/3300 (epoch 91), train_loss = -2.017, time/batch = 0.008\n",
      "3005/3300 (epoch 91), train_loss = -2.444, time/batch = 0.007\n",
      "3006/3300 (epoch 91), train_loss = -2.052, time/batch = 0.009\n",
      "3007/3300 (epoch 91), train_loss = -0.834, time/batch = 0.007\n",
      "3008/3300 (epoch 91), train_loss = -0.909, time/batch = 0.009\n",
      "3009/3300 (epoch 91), train_loss = -0.414, time/batch = 0.006\n",
      "3010/3300 (epoch 91), train_loss = -0.115, time/batch = 0.009\n",
      "3011/3300 (epoch 91), train_loss = -3.555, time/batch = 0.007\n",
      "3012/3300 (epoch 91), train_loss = -3.859, time/batch = 0.007\n",
      "3013/3300 (epoch 91), train_loss = -4.301, time/batch = 0.007\n",
      "3014/3300 (epoch 91), train_loss = -4.032, time/batch = 0.006\n",
      "3015/3300 (epoch 91), train_loss = -4.122, time/batch = 0.008\n",
      "3016/3300 (epoch 91), train_loss = -4.611, time/batch = 0.006\n",
      "3017/3300 (epoch 91), train_loss = -4.302, time/batch = 0.007\n",
      "3018/3300 (epoch 91), train_loss = -4.181, time/batch = 0.007\n",
      "3019/3300 (epoch 91), train_loss = -4.155, time/batch = 0.006\n",
      "3020/3300 (epoch 91), train_loss = -3.575, time/batch = 0.007\n",
      "3021/3300 (epoch 91), train_loss = -3.903, time/batch = 0.006\n",
      "3022/3300 (epoch 91), train_loss = -4.260, time/batch = 0.006\n",
      "3023/3300 (epoch 91), train_loss = -4.613, time/batch = 0.007\n",
      "3024/3300 (epoch 91), train_loss = -4.156, time/batch = 0.007\n",
      "3025/3300 (epoch 91), train_loss = -4.329, time/batch = 0.006\n",
      "3026/3300 (epoch 91), train_loss = -5.171, time/batch = 0.007\n",
      "3027/3300 (epoch 91), train_loss = -5.213, time/batch = 0.008\n",
      "3028/3300 (epoch 91), train_loss = -5.294, time/batch = 0.006\n",
      "3029/3300 (epoch 91), train_loss = -5.292, time/batch = 0.006\n",
      "3030/3300 (epoch 91), train_loss = -5.205, time/batch = 0.007\n",
      "3031/3300 (epoch 91), train_loss = -4.294, time/batch = 0.006\n",
      "3032/3300 (epoch 91), train_loss = -4.104, time/batch = 0.007\n",
      "3033/3300 (epoch 91), train_loss = -5.238, time/batch = 0.007\n",
      "3034/3300 (epoch 91), train_loss = -3.838, time/batch = 0.009\n",
      "3035/3300 (epoch 91), train_loss = -4.362, time/batch = 0.007\n",
      "3036/3300 (epoch 92), train_loss = -1.119, time/batch = 0.007\n",
      "3037/3300 (epoch 92), train_loss = -2.292, time/batch = 0.008\n",
      "3038/3300 (epoch 92), train_loss = -2.170, time/batch = 0.006\n",
      "3039/3300 (epoch 92), train_loss = -2.131, time/batch = 0.008\n",
      "3040/3300 (epoch 92), train_loss = -1.735, time/batch = 0.006\n",
      "3041/3300 (epoch 92), train_loss = 0.435, time/batch = 0.008\n",
      "3042/3300 (epoch 92), train_loss = 0.138, time/batch = 0.007\n",
      "3043/3300 (epoch 92), train_loss = 1.497, time/batch = 0.008\n",
      "3044/3300 (epoch 92), train_loss = -4.176, time/batch = 0.007\n",
      "3045/3300 (epoch 92), train_loss = -4.034, time/batch = 0.007\n",
      "3046/3300 (epoch 92), train_loss = -4.243, time/batch = 0.007\n",
      "3047/3300 (epoch 92), train_loss = -4.038, time/batch = 0.006\n",
      "3048/3300 (epoch 92), train_loss = -4.515, time/batch = 0.006\n",
      "3049/3300 (epoch 92), train_loss = -4.263, time/batch = 0.007\n",
      "3050/3300 (epoch 92), train_loss = -3.918, time/batch = 0.006\n",
      "3051/3300 (epoch 92), train_loss = -4.236, time/batch = 0.010\n",
      "3052/3300 (epoch 92), train_loss = -3.535, time/batch = 0.006\n",
      "3053/3300 (epoch 92), train_loss = -3.176, time/batch = 0.008\n",
      "3054/3300 (epoch 92), train_loss = -4.153, time/batch = 0.008\n",
      "3055/3300 (epoch 92), train_loss = -4.195, time/batch = 0.010\n",
      "3056/3300 (epoch 92), train_loss = -4.594, time/batch = 0.007\n",
      "3057/3300 (epoch 92), train_loss = -4.825, time/batch = 0.008\n",
      "3058/3300 (epoch 92), train_loss = -4.685, time/batch = 0.007\n",
      "3059/3300 (epoch 92), train_loss = -4.231, time/batch = 0.010\n",
      "3060/3300 (epoch 92), train_loss = -5.250, time/batch = 0.007\n",
      "3061/3300 (epoch 92), train_loss = -5.329, time/batch = 0.007\n",
      "3062/3300 (epoch 92), train_loss = -5.356, time/batch = 0.008\n",
      "3063/3300 (epoch 92), train_loss = -5.411, time/batch = 0.009\n",
      "3064/3300 (epoch 92), train_loss = -5.308, time/batch = 0.006\n",
      "3065/3300 (epoch 92), train_loss = -4.653, time/batch = 0.009\n",
      "3066/3300 (epoch 92), train_loss = -3.945, time/batch = 0.007\n",
      "3067/3300 (epoch 92), train_loss = -4.990, time/batch = 0.007\n",
      "3068/3300 (epoch 92), train_loss = -5.564, time/batch = 0.007\n",
      "3069/3300 (epoch 93), train_loss = -1.170, time/batch = 0.006\n",
      "3070/3300 (epoch 93), train_loss = -2.320, time/batch = 0.006\n",
      "3071/3300 (epoch 93), train_loss = -2.336, time/batch = 0.006\n",
      "3072/3300 (epoch 93), train_loss = -2.018, time/batch = 0.006\n",
      "3073/3300 (epoch 93), train_loss = -1.267, time/batch = 0.006\n",
      "3074/3300 (epoch 93), train_loss = 0.103, time/batch = 0.007\n",
      "3075/3300 (epoch 93), train_loss = -0.392, time/batch = 0.007\n",
      "3076/3300 (epoch 93), train_loss = 1.049, time/batch = 0.007\n",
      "3077/3300 (epoch 93), train_loss = -3.120, time/batch = 0.010\n",
      "3078/3300 (epoch 93), train_loss = -4.216, time/batch = 0.006\n",
      "3079/3300 (epoch 93), train_loss = -4.205, time/batch = 0.007\n",
      "3080/3300 (epoch 93), train_loss = -4.239, time/batch = 0.007\n",
      "3081/3300 (epoch 93), train_loss = -4.248, time/batch = 0.006\n",
      "3082/3300 (epoch 93), train_loss = -4.447, time/batch = 0.007\n",
      "3083/3300 (epoch 93), train_loss = -4.027, time/batch = 0.006\n",
      "3084/3300 (epoch 93), train_loss = -4.190, time/batch = 0.007\n",
      "3085/3300 (epoch 93), train_loss = -3.895, time/batch = 0.007\n",
      "3086/3300 (epoch 93), train_loss = -3.743, time/batch = 0.007\n",
      "3087/3300 (epoch 93), train_loss = -4.220, time/batch = 0.010\n",
      "3088/3300 (epoch 93), train_loss = -4.287, time/batch = 0.006\n",
      "3089/3300 (epoch 93), train_loss = -4.331, time/batch = 0.010\n",
      "3090/3300 (epoch 93), train_loss = -4.833, time/batch = 0.007\n",
      "3091/3300 (epoch 93), train_loss = -5.307, time/batch = 0.007\n",
      "3092/3300 (epoch 93), train_loss = -5.315, time/batch = 0.006\n",
      "3093/3300 (epoch 93), train_loss = -5.469, time/batch = 0.006\n",
      "3094/3300 (epoch 93), train_loss = -4.333, time/batch = 0.007\n",
      "3095/3300 (epoch 93), train_loss = -4.169, time/batch = 0.006\n",
      "3096/3300 (epoch 93), train_loss = -4.474, time/batch = 0.009\n",
      "3097/3300 (epoch 93), train_loss = -5.582, time/batch = 0.007\n",
      "3098/3300 (epoch 93), train_loss = -4.103, time/batch = 0.009\n",
      "3099/3300 (epoch 93), train_loss = -3.989, time/batch = 0.006\n",
      "3100/3300 (epoch 93), train_loss = -4.548, time/batch = 0.007\n",
      "3101/3300 (epoch 93), train_loss = -3.835, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3102/3300 (epoch 94), train_loss = -1.220, time/batch = 0.006\n",
      "3103/3300 (epoch 94), train_loss = -2.196, time/batch = 0.008\n",
      "3104/3300 (epoch 94), train_loss = -2.140, time/batch = 0.007\n",
      "3105/3300 (epoch 94), train_loss = -1.674, time/batch = 0.008\n",
      "3106/3300 (epoch 94), train_loss = -0.886, time/batch = 0.008\n",
      "3107/3300 (epoch 94), train_loss = 0.134, time/batch = 0.009\n",
      "3108/3300 (epoch 94), train_loss = -0.503, time/batch = 0.007\n",
      "3109/3300 (epoch 94), train_loss = 0.067, time/batch = 0.009\n",
      "3110/3300 (epoch 94), train_loss = -3.618, time/batch = 0.006\n",
      "3111/3300 (epoch 94), train_loss = -4.224, time/batch = 0.010\n",
      "3112/3300 (epoch 94), train_loss = -4.108, time/batch = 0.007\n",
      "3113/3300 (epoch 94), train_loss = -4.568, time/batch = 0.008\n",
      "3114/3300 (epoch 94), train_loss = -4.133, time/batch = 0.006\n",
      "3115/3300 (epoch 94), train_loss = -4.091, time/batch = 0.006\n",
      "3116/3300 (epoch 94), train_loss = -4.501, time/batch = 0.008\n",
      "3117/3300 (epoch 94), train_loss = -4.349, time/batch = 0.007\n",
      "3118/3300 (epoch 94), train_loss = -3.950, time/batch = 0.009\n",
      "3119/3300 (epoch 94), train_loss = -4.308, time/batch = 0.008\n",
      "3120/3300 (epoch 94), train_loss = -4.209, time/batch = 0.008\n",
      "3121/3300 (epoch 94), train_loss = -3.774, time/batch = 0.007\n",
      "3122/3300 (epoch 94), train_loss = -4.017, time/batch = 0.008\n",
      "3123/3300 (epoch 94), train_loss = -4.424, time/batch = 0.006\n",
      "3124/3300 (epoch 94), train_loss = -4.326, time/batch = 0.006\n",
      "3125/3300 (epoch 94), train_loss = -4.483, time/batch = 0.007\n",
      "3126/3300 (epoch 94), train_loss = -5.259, time/batch = 0.007\n",
      "3127/3300 (epoch 94), train_loss = -5.380, time/batch = 0.006\n",
      "3128/3300 (epoch 94), train_loss = -5.404, time/batch = 0.008\n",
      "3129/3300 (epoch 94), train_loss = -4.819, time/batch = 0.006\n",
      "3130/3300 (epoch 94), train_loss = -3.946, time/batch = 0.006\n",
      "3131/3300 (epoch 94), train_loss = -4.778, time/batch = 0.006\n",
      "3132/3300 (epoch 94), train_loss = -5.322, time/batch = 0.006\n",
      "3133/3300 (epoch 94), train_loss = -5.587, time/batch = 0.006\n",
      "3134/3300 (epoch 94), train_loss = -3.262, time/batch = 0.007\n",
      "3135/3300 (epoch 95), train_loss = -1.239, time/batch = 0.006\n",
      "3136/3300 (epoch 95), train_loss = -2.195, time/batch = 0.007\n",
      "3137/3300 (epoch 95), train_loss = -2.161, time/batch = 0.008\n",
      "3138/3300 (epoch 95), train_loss = -2.403, time/batch = 0.006\n",
      "3139/3300 (epoch 95), train_loss = -1.067, time/batch = 0.009\n",
      "3140/3300 (epoch 95), train_loss = 1.063, time/batch = 0.006\n",
      "3141/3300 (epoch 95), train_loss = 0.034, time/batch = 0.010\n",
      "3142/3300 (epoch 95), train_loss = 0.522, time/batch = 0.006\n",
      "3143/3300 (epoch 95), train_loss = -3.265, time/batch = 0.008\n",
      "3144/3300 (epoch 95), train_loss = -3.981, time/batch = 0.007\n",
      "3145/3300 (epoch 95), train_loss = -4.034, time/batch = 0.007\n",
      "3146/3300 (epoch 95), train_loss = -4.159, time/batch = 0.008\n",
      "3147/3300 (epoch 95), train_loss = -4.389, time/batch = 0.007\n",
      "3148/3300 (epoch 95), train_loss = -4.477, time/batch = 0.007\n",
      "3149/3300 (epoch 95), train_loss = -4.107, time/batch = 0.007\n",
      "3150/3300 (epoch 95), train_loss = -4.116, time/batch = 0.006\n",
      "3151/3300 (epoch 95), train_loss = -3.877, time/batch = 0.006\n",
      "3152/3300 (epoch 95), train_loss = -3.922, time/batch = 0.006\n",
      "3153/3300 (epoch 95), train_loss = -4.320, time/batch = 0.007\n",
      "3154/3300 (epoch 95), train_loss = -4.480, time/batch = 0.006\n",
      "3155/3300 (epoch 95), train_loss = -4.730, time/batch = 0.007\n",
      "3156/3300 (epoch 95), train_loss = -4.406, time/batch = 0.006\n",
      "3157/3300 (epoch 95), train_loss = -4.493, time/batch = 0.006\n",
      "3158/3300 (epoch 95), train_loss = -4.776, time/batch = 0.007\n",
      "3159/3300 (epoch 95), train_loss = -4.185, time/batch = 0.007\n",
      "3160/3300 (epoch 95), train_loss = -4.388, time/batch = 0.009\n",
      "3161/3300 (epoch 95), train_loss = -5.116, time/batch = 0.007\n",
      "3162/3300 (epoch 95), train_loss = -3.719, time/batch = 0.006\n",
      "3163/3300 (epoch 95), train_loss = -4.320, time/batch = 0.008\n",
      "3164/3300 (epoch 95), train_loss = -4.369, time/batch = 0.006\n",
      "3165/3300 (epoch 95), train_loss = -4.162, time/batch = 0.008\n",
      "3166/3300 (epoch 95), train_loss = -4.623, time/batch = 0.006\n",
      "3167/3300 (epoch 95), train_loss = -4.366, time/batch = 0.006\n",
      "3168/3300 (epoch 96), train_loss = -1.186, time/batch = 0.006\n",
      "3169/3300 (epoch 96), train_loss = -2.179, time/batch = 0.006\n",
      "3170/3300 (epoch 96), train_loss = -2.104, time/batch = 0.008\n",
      "3171/3300 (epoch 96), train_loss = -1.533, time/batch = 0.007\n",
      "3172/3300 (epoch 96), train_loss = -1.025, time/batch = 0.008\n",
      "3173/3300 (epoch 96), train_loss = -0.237, time/batch = 0.007\n",
      "3174/3300 (epoch 96), train_loss = -0.166, time/batch = 0.008\n",
      "3175/3300 (epoch 96), train_loss = 0.738, time/batch = 0.006\n",
      "3176/3300 (epoch 96), train_loss = -4.614, time/batch = 0.007\n",
      "3177/3300 (epoch 96), train_loss = -4.481, time/batch = 0.007\n",
      "3178/3300 (epoch 96), train_loss = -4.100, time/batch = 0.007\n",
      "3179/3300 (epoch 96), train_loss = -4.391, time/batch = 0.006\n",
      "3180/3300 (epoch 96), train_loss = -4.126, time/batch = 0.007\n",
      "3181/3300 (epoch 96), train_loss = -4.125, time/batch = 0.006\n",
      "3182/3300 (epoch 96), train_loss = -4.034, time/batch = 0.006\n",
      "3183/3300 (epoch 96), train_loss = -4.544, time/batch = 0.007\n",
      "3184/3300 (epoch 96), train_loss = -4.152, time/batch = 0.006\n",
      "3185/3300 (epoch 96), train_loss = -4.508, time/batch = 0.007\n",
      "3186/3300 (epoch 96), train_loss = -3.843, time/batch = 0.008\n",
      "3187/3300 (epoch 96), train_loss = -3.463, time/batch = 0.006\n",
      "3188/3300 (epoch 96), train_loss = -4.399, time/batch = 0.007\n",
      "3189/3300 (epoch 96), train_loss = -4.168, time/batch = 0.007\n",
      "3190/3300 (epoch 96), train_loss = -4.231, time/batch = 0.007\n",
      "3191/3300 (epoch 96), train_loss = -4.662, time/batch = 0.009\n",
      "3192/3300 (epoch 96), train_loss = -4.079, time/batch = 0.007\n",
      "3193/3300 (epoch 96), train_loss = -5.299, time/batch = 0.009\n",
      "3194/3300 (epoch 96), train_loss = -5.305, time/batch = 0.006\n",
      "3195/3300 (epoch 96), train_loss = -4.960, time/batch = 0.006\n",
      "3196/3300 (epoch 96), train_loss = -4.511, time/batch = 0.007\n",
      "3197/3300 (epoch 96), train_loss = -4.398, time/batch = 0.006\n",
      "3198/3300 (epoch 96), train_loss = -4.830, time/batch = 0.008\n",
      "3199/3300 (epoch 96), train_loss = -5.489, time/batch = 0.006\n",
      "3200/3300 (epoch 96), train_loss = -5.045, time/batch = 0.008\n",
      "3201/3300 (epoch 97), train_loss = -1.185, time/batch = 0.006\n",
      "3202/3300 (epoch 97), train_loss = -2.427, time/batch = 0.007\n",
      "3203/3300 (epoch 97), train_loss = -2.131, time/batch = 0.007\n",
      "3204/3300 (epoch 97), train_loss = -2.596, time/batch = 0.006\n",
      "3205/3300 (epoch 97), train_loss = -0.830, time/batch = 0.006\n",
      "3206/3300 (epoch 97), train_loss = -0.096, time/batch = 0.007\n",
      "3207/3300 (epoch 97), train_loss = 0.166, time/batch = 0.007\n",
      "3208/3300 (epoch 97), train_loss = -0.684, time/batch = 0.006\n",
      "3209/3300 (epoch 97), train_loss = -1.683, time/batch = 0.007\n",
      "3210/3300 (epoch 97), train_loss = -4.338, time/batch = 0.006\n",
      "3211/3300 (epoch 97), train_loss = -4.079, time/batch = 0.006\n",
      "3212/3300 (epoch 97), train_loss = -4.266, time/batch = 0.009\n",
      "3213/3300 (epoch 97), train_loss = -4.115, time/batch = 0.006\n",
      "3214/3300 (epoch 97), train_loss = -4.271, time/batch = 0.006\n",
      "3215/3300 (epoch 97), train_loss = -4.780, time/batch = 0.008\n",
      "3216/3300 (epoch 97), train_loss = -4.291, time/batch = 0.006\n",
      "3217/3300 (epoch 97), train_loss = -4.143, time/batch = 0.009\n",
      "3218/3300 (epoch 97), train_loss = -4.150, time/batch = 0.006\n",
      "3219/3300 (epoch 97), train_loss = -3.098, time/batch = 0.009\n",
      "3220/3300 (epoch 97), train_loss = -3.977, time/batch = 0.006\n",
      "3221/3300 (epoch 97), train_loss = -4.031, time/batch = 0.007\n",
      "3222/3300 (epoch 97), train_loss = -4.243, time/batch = 0.008\n",
      "3223/3300 (epoch 97), train_loss = -4.151, time/batch = 0.006\n",
      "3224/3300 (epoch 97), train_loss = -4.692, time/batch = 0.008\n",
      "3225/3300 (epoch 97), train_loss = -4.594, time/batch = 0.006\n",
      "3226/3300 (epoch 97), train_loss = -4.537, time/batch = 0.008\n",
      "3227/3300 (epoch 97), train_loss = -5.228, time/batch = 0.007\n",
      "3228/3300 (epoch 97), train_loss = -5.180, time/batch = 0.008\n",
      "3229/3300 (epoch 97), train_loss = -4.758, time/batch = 0.006\n",
      "3230/3300 (epoch 97), train_loss = -3.352, time/batch = 0.006\n",
      "3231/3300 (epoch 97), train_loss = -4.220, time/batch = 0.007\n",
      "3232/3300 (epoch 97), train_loss = -4.978, time/batch = 0.006\n",
      "3233/3300 (epoch 97), train_loss = -5.577, time/batch = 0.007\n",
      "3234/3300 (epoch 98), train_loss = -1.208, time/batch = 0.006\n",
      "3235/3300 (epoch 98), train_loss = -2.328, time/batch = 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3236/3300 (epoch 98), train_loss = -2.406, time/batch = 0.008\n",
      "3237/3300 (epoch 98), train_loss = -1.502, time/batch = 0.007\n",
      "3238/3300 (epoch 98), train_loss = -0.709, time/batch = 0.008\n",
      "3239/3300 (epoch 98), train_loss = 0.690, time/batch = 0.007\n",
      "3240/3300 (epoch 98), train_loss = 0.651, time/batch = 0.008\n",
      "3241/3300 (epoch 98), train_loss = -0.143, time/batch = 0.006\n",
      "3242/3300 (epoch 98), train_loss = -2.447, time/batch = 0.007\n",
      "3243/3300 (epoch 98), train_loss = -3.386, time/batch = 0.007\n",
      "3244/3300 (epoch 98), train_loss = -4.427, time/batch = 0.006\n",
      "3245/3300 (epoch 98), train_loss = -4.175, time/batch = 0.007\n",
      "3246/3300 (epoch 98), train_loss = -4.025, time/batch = 0.006\n",
      "3247/3300 (epoch 98), train_loss = -4.400, time/batch = 0.007\n",
      "3248/3300 (epoch 98), train_loss = -4.372, time/batch = 0.007\n",
      "3249/3300 (epoch 98), train_loss = -4.213, time/batch = 0.007\n",
      "3250/3300 (epoch 98), train_loss = -4.322, time/batch = 0.007\n",
      "3251/3300 (epoch 98), train_loss = -3.005, time/batch = 0.007\n",
      "3252/3300 (epoch 98), train_loss = -3.950, time/batch = 0.008\n",
      "3253/3300 (epoch 98), train_loss = -4.086, time/batch = 0.007\n",
      "3254/3300 (epoch 98), train_loss = -4.329, time/batch = 0.008\n",
      "3255/3300 (epoch 98), train_loss = -4.514, time/batch = 0.007\n",
      "3256/3300 (epoch 98), train_loss = -3.888, time/batch = 0.011\n",
      "3257/3300 (epoch 98), train_loss = -5.346, time/batch = 0.006\n",
      "3258/3300 (epoch 98), train_loss = -5.366, time/batch = 0.008\n",
      "3259/3300 (epoch 98), train_loss = -5.360, time/batch = 0.007\n",
      "3260/3300 (epoch 98), train_loss = -4.041, time/batch = 0.006\n",
      "3261/3300 (epoch 98), train_loss = -4.020, time/batch = 0.006\n",
      "3262/3300 (epoch 98), train_loss = -4.975, time/batch = 0.007\n",
      "3263/3300 (epoch 98), train_loss = -4.876, time/batch = 0.006\n",
      "3264/3300 (epoch 98), train_loss = -3.589, time/batch = 0.006\n",
      "3265/3300 (epoch 98), train_loss = -4.746, time/batch = 0.009\n",
      "3266/3300 (epoch 98), train_loss = -4.496, time/batch = 0.006\n",
      "3267/3300 (epoch 99), train_loss = -1.140, time/batch = 0.006\n",
      "3268/3300 (epoch 99), train_loss = -2.202, time/batch = 0.008\n",
      "3269/3300 (epoch 99), train_loss = -2.351, time/batch = 0.006\n",
      "3270/3300 (epoch 99), train_loss = -2.381, time/batch = 0.009\n",
      "3271/3300 (epoch 99), train_loss = -1.828, time/batch = 0.006\n",
      "3272/3300 (epoch 99), train_loss = 0.381, time/batch = 0.011\n",
      "3273/3300 (epoch 99), train_loss = 1.786, time/batch = 0.006\n",
      "3274/3300 (epoch 99), train_loss = -0.065, time/batch = 0.007\n",
      "3275/3300 (epoch 99), train_loss = 0.519, time/batch = 0.007\n",
      "3276/3300 (epoch 99), train_loss = -4.397, time/batch = 0.007\n",
      "3277/3300 (epoch 99), train_loss = -3.740, time/batch = 0.007\n",
      "3278/3300 (epoch 99), train_loss = -4.389, time/batch = 0.006\n",
      "3279/3300 (epoch 99), train_loss = -4.027, time/batch = 0.008\n",
      "3280/3300 (epoch 99), train_loss = -4.479, time/batch = 0.007\n",
      "3281/3300 (epoch 99), train_loss = -4.671, time/batch = 0.007\n",
      "3282/3300 (epoch 99), train_loss = -4.174, time/batch = 0.007\n",
      "3283/3300 (epoch 99), train_loss = -4.242, time/batch = 0.008\n",
      "3284/3300 (epoch 99), train_loss = -4.264, time/batch = 0.008\n",
      "3285/3300 (epoch 99), train_loss = -3.701, time/batch = 0.007\n",
      "3286/3300 (epoch 99), train_loss = -3.184, time/batch = 0.006\n",
      "3287/3300 (epoch 99), train_loss = -4.214, time/batch = 0.006\n",
      "3288/3300 (epoch 99), train_loss = -4.066, time/batch = 0.007\n",
      "3289/3300 (epoch 99), train_loss = -4.432, time/batch = 0.006\n",
      "3290/3300 (epoch 99), train_loss = -4.402, time/batch = 0.007\n",
      "3291/3300 (epoch 99), train_loss = -4.571, time/batch = 0.006\n",
      "3292/3300 (epoch 99), train_loss = -5.316, time/batch = 0.006\n",
      "3293/3300 (epoch 99), train_loss = -5.368, time/batch = 0.006\n",
      "3294/3300 (epoch 99), train_loss = -5.432, time/batch = 0.007\n",
      "3295/3300 (epoch 99), train_loss = -5.365, time/batch = 0.006\n",
      "3296/3300 (epoch 99), train_loss = -4.671, time/batch = 0.010\n",
      "3297/3300 (epoch 99), train_loss = -3.194, time/batch = 0.006\n",
      "3298/3300 (epoch 99), train_loss = -4.160, time/batch = 0.007\n",
      "3299/3300 (epoch 99), train_loss = -4.281, time/batch = 0.006\n"
     ]
    }
   ],
   "source": [
    "for e in range(NUM_EPOCHS):\n",
    "    # Assign the learning rate (decayed acc. to the epoch number)\n",
    "    lstm.sess.run(tf.assign(lstm.lr, lstm.learning_rate * (DECAY_RATE ** e)))\n",
    "    # Reset the pointers in the data loader object\n",
    "    pointer = data_tools.reset_batch_pointer()\n",
    "    # Get the initial cell state of the LSTM\n",
    "    state = lstm.sess.run(lstm.initial_state)\n",
    "    \n",
    "    # For each batch in this epoch\n",
    "    for b in range(num_batches):\n",
    "        start = time.time()\n",
    "        # Get the source and target data of the current batch\n",
    "        # x has the source data, y has the target data\n",
    "        x, y, pointer = data_tools.next_batch(loaded_data, pointer, BATCH_SIZE, SEQUENCE_LENGTH)\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Feed the source, target data and the initial LSTM state to the model\n",
    "        feed = {lstm.input_data: x[:, :, 1:], lstm.target_data: y[:, :, 1:], lstm.initial_state: state}\n",
    "        # Fetch the loss of the model on this batch, the final LSTM state from the session\n",
    "        train_loss, state, _ = lstm.sess.run([lstm.cost, lstm.final_state, lstm.train_op], feed)\n",
    "        # Toc\n",
    "        end = time.time()\n",
    "        # Print epoch, batch, loss and time taken\n",
    "        print(\n",
    "            \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\n",
    "            .format(\n",
    "                e * num_batches + b,\n",
    "                NUM_EPOCHS * num_batches,\n",
    "                e,\n",
    "                train_loss, end - start))\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "lstm.save_json(os.path.join(SAVE_PATH, \"params.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "OBSERVED_LENGTH = 4\n",
    "PREDICTED_LENGTH = 4\n",
    "SEQUENCE_LENGTH = OBSERVED_LENGTH + PREDICTED_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/seq_hotel\"\n",
    "agentsData, statistics, peds_in_frame = data_tools.mil_to_pixels(directory)\n",
    "data, num_batches = data_tools.load_preprocessed(agentsData, BATCH_SIZE, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfully reset\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "lstm = BasicLSTM(batch_size=1, sequence_length=1)\n",
    "lstm.load_json(os.path.join(SAVE_PATH, \"params.json\"))\n",
    "\n",
    "state = lstm.sess.run(lstm.initial_state)\n",
    "pointer = data_tools.reset_batch_pointer()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "total_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trajectory number :  1 out of  461  trajectories\n",
      "Processed trajectory number :  2 out of  461  trajectories\n",
      "Processed trajectory number :  3 out of  461  trajectories\n",
      "Processed trajectory number :  4 out of  461  trajectories\n",
      "Processed trajectory number :  5 out of  461  trajectories\n",
      "Processed trajectory number :  6 out of  461  trajectories\n",
      "Processed trajectory number :  7 out of  461  trajectories\n",
      "Processed trajectory number :  8 out of  461  trajectories\n",
      "Processed trajectory number :  9 out of  461  trajectories\n",
      "Processed trajectory number :  10 out of  461  trajectories\n",
      "Processed trajectory number :  11 out of  461  trajectories\n",
      "Processed trajectory number :  12 out of  461  trajectories\n",
      "Processed trajectory number :  13 out of  461  trajectories\n",
      "Processed trajectory number :  14 out of  461  trajectories\n",
      "Processed trajectory number :  15 out of  461  trajectories\n",
      "Processed trajectory number :  16 out of  461  trajectories\n",
      "Processed trajectory number :  17 out of  461  trajectories\n",
      "Processed trajectory number :  18 out of  461  trajectories\n",
      "Processed trajectory number :  19 out of  461  trajectories\n",
      "Processed trajectory number :  20 out of  461  trajectories\n",
      "Processed trajectory number :  21 out of  461  trajectories\n",
      "Processed trajectory number :  22 out of  461  trajectories\n",
      "Processed trajectory number :  23 out of  461  trajectories\n",
      "Processed trajectory number :  24 out of  461  trajectories\n",
      "Processed trajectory number :  25 out of  461  trajectories\n",
      "Processed trajectory number :  26 out of  461  trajectories\n",
      "Processed trajectory number :  27 out of  461  trajectories\n",
      "Processed trajectory number :  28 out of  461  trajectories\n",
      "Processed trajectory number :  29 out of  461  trajectories\n",
      "Processed trajectory number :  30 out of  461  trajectories\n",
      "Processed trajectory number :  31 out of  461  trajectories\n",
      "Processed trajectory number :  32 out of  461  trajectories\n",
      "Processed trajectory number :  33 out of  461  trajectories\n",
      "Processed trajectory number :  34 out of  461  trajectories\n",
      "Processed trajectory number :  35 out of  461  trajectories\n",
      "Processed trajectory number :  36 out of  461  trajectories\n",
      "Processed trajectory number :  37 out of  461  trajectories\n",
      "Processed trajectory number :  38 out of  461  trajectories\n",
      "Processed trajectory number :  39 out of  461  trajectories\n",
      "Processed trajectory number :  40 out of  461  trajectories\n",
      "Processed trajectory number :  41 out of  461  trajectories\n",
      "Processed trajectory number :  42 out of  461  trajectories\n",
      "Processed trajectory number :  43 out of  461  trajectories\n",
      "Processed trajectory number :  44 out of  461  trajectories\n",
      "Processed trajectory number :  45 out of  461  trajectories\n",
      "Processed trajectory number :  46 out of  461  trajectories\n",
      "Processed trajectory number :  47 out of  461  trajectories\n",
      "Processed trajectory number :  48 out of  461  trajectories\n",
      "Processed trajectory number :  49 out of  461  trajectories\n",
      "Processed trajectory number :  50 out of  461  trajectories\n",
      "Processed trajectory number :  51 out of  461  trajectories\n",
      "Processed trajectory number :  52 out of  461  trajectories\n",
      "Processed trajectory number :  53 out of  461  trajectories\n",
      "Processed trajectory number :  54 out of  461  trajectories\n",
      "Processed trajectory number :  55 out of  461  trajectories\n",
      "Processed trajectory number :  56 out of  461  trajectories\n",
      "Processed trajectory number :  57 out of  461  trajectories\n",
      "Processed trajectory number :  58 out of  461  trajectories\n",
      "Processed trajectory number :  59 out of  461  trajectories\n",
      "Processed trajectory number :  60 out of  461  trajectories\n",
      "Processed trajectory number :  61 out of  461  trajectories\n",
      "Processed trajectory number :  62 out of  461  trajectories\n",
      "Processed trajectory number :  63 out of  461  trajectories\n",
      "Processed trajectory number :  64 out of  461  trajectories\n",
      "Processed trajectory number :  65 out of  461  trajectories\n",
      "Processed trajectory number :  66 out of  461  trajectories\n",
      "Processed trajectory number :  67 out of  461  trajectories\n",
      "Processed trajectory number :  68 out of  461  trajectories\n",
      "Processed trajectory number :  69 out of  461  trajectories\n",
      "Processed trajectory number :  70 out of  461  trajectories\n",
      "Processed trajectory number :  71 out of  461  trajectories\n",
      "Processed trajectory number :  72 out of  461  trajectories\n",
      "Processed trajectory number :  73 out of  461  trajectories\n",
      "Processed trajectory number :  74 out of  461  trajectories\n",
      "Processed trajectory number :  75 out of  461  trajectories\n",
      "Processed trajectory number :  76 out of  461  trajectories\n",
      "Processed trajectory number :  77 out of  461  trajectories\n",
      "Processed trajectory number :  78 out of  461  trajectories\n",
      "Processed trajectory number :  79 out of  461  trajectories\n",
      "Processed trajectory number :  80 out of  461  trajectories\n",
      "Processed trajectory number :  81 out of  461  trajectories\n",
      "Processed trajectory number :  82 out of  461  trajectories\n",
      "Processed trajectory number :  83 out of  461  trajectories\n",
      "Processed trajectory number :  84 out of  461  trajectories\n",
      "Processed trajectory number :  85 out of  461  trajectories\n",
      "Processed trajectory number :  86 out of  461  trajectories\n",
      "Processed trajectory number :  87 out of  461  trajectories\n",
      "Processed trajectory number :  88 out of  461  trajectories\n",
      "Processed trajectory number :  89 out of  461  trajectories\n",
      "Processed trajectory number :  90 out of  461  trajectories\n",
      "Processed trajectory number :  91 out of  461  trajectories\n",
      "Processed trajectory number :  92 out of  461  trajectories\n",
      "Processed trajectory number :  93 out of  461  trajectories\n",
      "Processed trajectory number :  94 out of  461  trajectories\n",
      "Processed trajectory number :  95 out of  461  trajectories\n",
      "Processed trajectory number :  96 out of  461  trajectories\n",
      "Processed trajectory number :  97 out of  461  trajectories\n",
      "Processed trajectory number :  98 out of  461  trajectories\n",
      "Processed trajectory number :  99 out of  461  trajectories\n",
      "Processed trajectory number :  100 out of  461  trajectories\n",
      "Processed trajectory number :  101 out of  461  trajectories\n",
      "Processed trajectory number :  102 out of  461  trajectories\n",
      "Processed trajectory number :  103 out of  461  trajectories\n",
      "Processed trajectory number :  104 out of  461  trajectories\n",
      "Processed trajectory number :  105 out of  461  trajectories\n",
      "Processed trajectory number :  106 out of  461  trajectories\n",
      "Processed trajectory number :  107 out of  461  trajectories\n",
      "Processed trajectory number :  108 out of  461  trajectories\n",
      "Processed trajectory number :  109 out of  461  trajectories\n",
      "Processed trajectory number :  110 out of  461  trajectories\n",
      "Processed trajectory number :  111 out of  461  trajectories\n",
      "Processed trajectory number :  112 out of  461  trajectories\n",
      "Processed trajectory number :  113 out of  461  trajectories\n",
      "Processed trajectory number :  114 out of  461  trajectories\n",
      "Processed trajectory number :  115 out of  461  trajectories\n",
      "Processed trajectory number :  116 out of  461  trajectories\n",
      "Processed trajectory number :  117 out of  461  trajectories\n",
      "Processed trajectory number :  118 out of  461  trajectories\n",
      "Processed trajectory number :  119 out of  461  trajectories\n",
      "Processed trajectory number :  120 out of  461  trajectories\n",
      "Processed trajectory number :  121 out of  461  trajectories\n",
      "Processed trajectory number :  122 out of  461  trajectories\n",
      "Processed trajectory number :  123 out of  461  trajectories\n",
      "Processed trajectory number :  124 out of  461  trajectories\n",
      "Processed trajectory number :  125 out of  461  trajectories\n",
      "Processed trajectory number :  126 out of  461  trajectories\n",
      "Processed trajectory number :  127 out of  461  trajectories\n",
      "Processed trajectory number :  128 out of  461  trajectories\n",
      "Processed trajectory number :  129 out of  461  trajectories\n",
      "Processed trajectory number :  130 out of  461  trajectories\n",
      "Processed trajectory number :  131 out of  461  trajectories\n",
      "Processed trajectory number :  132 out of  461  trajectories\n",
      "Processed trajectory number :  133 out of  461  trajectories\n",
      "Processed trajectory number :  134 out of  461  trajectories\n",
      "Processed trajectory number :  135 out of  461  trajectories\n",
      "Processed trajectory number :  136 out of  461  trajectories\n",
      "Processed trajectory number :  137 out of  461  trajectories\n",
      "Processed trajectory number :  138 out of  461  trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trajectory number :  139 out of  461  trajectories\n",
      "Processed trajectory number :  140 out of  461  trajectories\n",
      "Processed trajectory number :  141 out of  461  trajectories\n",
      "Processed trajectory number :  142 out of  461  trajectories\n",
      "Processed trajectory number :  143 out of  461  trajectories\n",
      "Processed trajectory number :  144 out of  461  trajectories\n",
      "Processed trajectory number :  145 out of  461  trajectories\n",
      "Processed trajectory number :  146 out of  461  trajectories\n",
      "Processed trajectory number :  147 out of  461  trajectories\n",
      "Processed trajectory number :  148 out of  461  trajectories\n",
      "Processed trajectory number :  149 out of  461  trajectories\n",
      "Processed trajectory number :  150 out of  461  trajectories\n",
      "Processed trajectory number :  151 out of  461  trajectories\n",
      "Processed trajectory number :  152 out of  461  trajectories\n",
      "Processed trajectory number :  153 out of  461  trajectories\n",
      "Processed trajectory number :  154 out of  461  trajectories\n",
      "Processed trajectory number :  155 out of  461  trajectories\n",
      "Processed trajectory number :  156 out of  461  trajectories\n",
      "Processed trajectory number :  157 out of  461  trajectories\n",
      "Processed trajectory number :  158 out of  461  trajectories\n",
      "Processed trajectory number :  159 out of  461  trajectories\n",
      "Processed trajectory number :  160 out of  461  trajectories\n",
      "Processed trajectory number :  161 out of  461  trajectories\n",
      "Processed trajectory number :  162 out of  461  trajectories\n",
      "Processed trajectory number :  163 out of  461  trajectories\n",
      "Processed trajectory number :  164 out of  461  trajectories\n",
      "Processed trajectory number :  165 out of  461  trajectories\n",
      "Processed trajectory number :  166 out of  461  trajectories\n",
      "Processed trajectory number :  167 out of  461  trajectories\n",
      "Processed trajectory number :  168 out of  461  trajectories\n",
      "Processed trajectory number :  169 out of  461  trajectories\n",
      "Processed trajectory number :  170 out of  461  trajectories\n",
      "Processed trajectory number :  171 out of  461  trajectories\n",
      "Processed trajectory number :  172 out of  461  trajectories\n",
      "Processed trajectory number :  173 out of  461  trajectories\n",
      "Processed trajectory number :  174 out of  461  trajectories\n",
      "Processed trajectory number :  175 out of  461  trajectories\n",
      "Processed trajectory number :  176 out of  461  trajectories\n",
      "Processed trajectory number :  177 out of  461  trajectories\n",
      "Processed trajectory number :  178 out of  461  trajectories\n",
      "Processed trajectory number :  179 out of  461  trajectories\n",
      "Processed trajectory number :  180 out of  461  trajectories\n",
      "Processed trajectory number :  181 out of  461  trajectories\n",
      "Processed trajectory number :  182 out of  461  trajectories\n",
      "Processed trajectory number :  183 out of  461  trajectories\n",
      "Processed trajectory number :  184 out of  461  trajectories\n",
      "Processed trajectory number :  185 out of  461  trajectories\n",
      "Processed trajectory number :  186 out of  461  trajectories\n",
      "Processed trajectory number :  187 out of  461  trajectories\n",
      "Processed trajectory number :  188 out of  461  trajectories\n",
      "Processed trajectory number :  189 out of  461  trajectories\n",
      "Processed trajectory number :  190 out of  461  trajectories\n",
      "Processed trajectory number :  191 out of  461  trajectories\n",
      "Processed trajectory number :  192 out of  461  trajectories\n",
      "Processed trajectory number :  193 out of  461  trajectories\n",
      "Processed trajectory number :  194 out of  461  trajectories\n",
      "Processed trajectory number :  195 out of  461  trajectories\n",
      "Processed trajectory number :  196 out of  461  trajectories\n",
      "Processed trajectory number :  197 out of  461  trajectories\n",
      "Processed trajectory number :  198 out of  461  trajectories\n",
      "Processed trajectory number :  199 out of  461  trajectories\n",
      "Processed trajectory number :  200 out of  461  trajectories\n",
      "Processed trajectory number :  201 out of  461  trajectories\n",
      "Processed trajectory number :  202 out of  461  trajectories\n",
      "Processed trajectory number :  203 out of  461  trajectories\n",
      "Processed trajectory number :  204 out of  461  trajectories\n",
      "Processed trajectory number :  205 out of  461  trajectories\n",
      "Processed trajectory number :  206 out of  461  trajectories\n",
      "Processed trajectory number :  207 out of  461  trajectories\n",
      "Processed trajectory number :  208 out of  461  trajectories\n",
      "Processed trajectory number :  209 out of  461  trajectories\n",
      "Processed trajectory number :  210 out of  461  trajectories\n",
      "Processed trajectory number :  211 out of  461  trajectories\n",
      "Processed trajectory number :  212 out of  461  trajectories\n",
      "Processed trajectory number :  213 out of  461  trajectories\n",
      "Processed trajectory number :  214 out of  461  trajectories\n",
      "Processed trajectory number :  215 out of  461  trajectories\n",
      "Processed trajectory number :  216 out of  461  trajectories\n",
      "Processed trajectory number :  217 out of  461  trajectories\n",
      "Processed trajectory number :  218 out of  461  trajectories\n",
      "Processed trajectory number :  219 out of  461  trajectories\n",
      "Processed trajectory number :  220 out of  461  trajectories\n",
      "Processed trajectory number :  221 out of  461  trajectories\n",
      "Processed trajectory number :  222 out of  461  trajectories\n",
      "Processed trajectory number :  223 out of  461  trajectories\n",
      "Processed trajectory number :  224 out of  461  trajectories\n",
      "Processed trajectory number :  225 out of  461  trajectories\n",
      "Processed trajectory number :  226 out of  461  trajectories\n",
      "Processed trajectory number :  227 out of  461  trajectories\n",
      "Processed trajectory number :  228 out of  461  trajectories\n",
      "Processed trajectory number :  229 out of  461  trajectories\n",
      "Processed trajectory number :  230 out of  461  trajectories\n",
      "Processed trajectory number :  231 out of  461  trajectories\n",
      "Processed trajectory number :  232 out of  461  trajectories\n",
      "Processed trajectory number :  233 out of  461  trajectories\n",
      "Processed trajectory number :  234 out of  461  trajectories\n",
      "Processed trajectory number :  235 out of  461  trajectories\n",
      "Processed trajectory number :  236 out of  461  trajectories\n",
      "Processed trajectory number :  237 out of  461  trajectories\n",
      "Processed trajectory number :  238 out of  461  trajectories\n",
      "Processed trajectory number :  239 out of  461  trajectories\n",
      "Processed trajectory number :  240 out of  461  trajectories\n",
      "Processed trajectory number :  241 out of  461  trajectories\n",
      "Processed trajectory number :  242 out of  461  trajectories\n",
      "Processed trajectory number :  243 out of  461  trajectories\n",
      "Processed trajectory number :  244 out of  461  trajectories\n",
      "Processed trajectory number :  245 out of  461  trajectories\n",
      "Processed trajectory number :  246 out of  461  trajectories\n",
      "Processed trajectory number :  247 out of  461  trajectories\n",
      "Processed trajectory number :  248 out of  461  trajectories\n",
      "Processed trajectory number :  249 out of  461  trajectories\n",
      "Processed trajectory number :  250 out of  461  trajectories\n",
      "Processed trajectory number :  251 out of  461  trajectories\n",
      "Processed trajectory number :  252 out of  461  trajectories\n",
      "Processed trajectory number :  253 out of  461  trajectories\n",
      "Processed trajectory number :  254 out of  461  trajectories\n",
      "Processed trajectory number :  255 out of  461  trajectories\n",
      "Processed trajectory number :  256 out of  461  trajectories\n",
      "Processed trajectory number :  257 out of  461  trajectories\n",
      "Processed trajectory number :  258 out of  461  trajectories\n",
      "Processed trajectory number :  259 out of  461  trajectories\n",
      "Processed trajectory number :  260 out of  461  trajectories\n",
      "Processed trajectory number :  261 out of  461  trajectories\n",
      "Processed trajectory number :  262 out of  461  trajectories\n",
      "Processed trajectory number :  263 out of  461  trajectories\n",
      "Processed trajectory number :  264 out of  461  trajectories\n",
      "Processed trajectory number :  265 out of  461  trajectories\n",
      "Processed trajectory number :  266 out of  461  trajectories\n",
      "Processed trajectory number :  267 out of  461  trajectories\n",
      "Processed trajectory number :  268 out of  461  trajectories\n",
      "Processed trajectory number :  269 out of  461  trajectories\n",
      "Processed trajectory number :  270 out of  461  trajectories\n",
      "Processed trajectory number :  271 out of  461  trajectories\n",
      "Processed trajectory number :  272 out of  461  trajectories\n",
      "Processed trajectory number :  273 out of  461  trajectories\n",
      "Processed trajectory number :  274 out of  461  trajectories\n",
      "Processed trajectory number :  275 out of  461  trajectories\n",
      "Processed trajectory number :  276 out of  461  trajectories\n",
      "Processed trajectory number :  277 out of  461  trajectories\n",
      "Processed trajectory number :  278 out of  461  trajectories\n",
      "Processed trajectory number :  279 out of  461  trajectories\n",
      "Processed trajectory number :  280 out of  461  trajectories\n",
      "Processed trajectory number :  281 out of  461  trajectories\n",
      "Processed trajectory number :  282 out of  461  trajectories\n",
      "Processed trajectory number :  283 out of  461  trajectories\n",
      "Processed trajectory number :  284 out of  461  trajectories\n",
      "Processed trajectory number :  285 out of  461  trajectories\n",
      "Processed trajectory number :  286 out of  461  trajectories\n",
      "Processed trajectory number :  287 out of  461  trajectories\n",
      "Processed trajectory number :  288 out of  461  trajectories\n",
      "Processed trajectory number :  289 out of  461  trajectories\n",
      "Processed trajectory number :  290 out of  461  trajectories\n",
      "Processed trajectory number :  291 out of  461  trajectories\n",
      "Processed trajectory number :  292 out of  461  trajectories\n",
      "Processed trajectory number :  293 out of  461  trajectories\n",
      "Processed trajectory number :  294 out of  461  trajectories\n",
      "Processed trajectory number :  295 out of  461  trajectories\n",
      "Processed trajectory number :  296 out of  461  trajectories\n",
      "Processed trajectory number :  297 out of  461  trajectories\n",
      "Processed trajectory number :  298 out of  461  trajectories\n",
      "Processed trajectory number :  299 out of  461  trajectories\n",
      "Processed trajectory number :  300 out of  461  trajectories\n",
      "Processed trajectory number :  301 out of  461  trajectories\n",
      "Processed trajectory number :  302 out of  461  trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trajectory number :  303 out of  461  trajectories\n",
      "Processed trajectory number :  304 out of  461  trajectories\n",
      "Processed trajectory number :  305 out of  461  trajectories\n",
      "Processed trajectory number :  306 out of  461  trajectories\n",
      "Processed trajectory number :  307 out of  461  trajectories\n",
      "Processed trajectory number :  308 out of  461  trajectories\n",
      "Processed trajectory number :  309 out of  461  trajectories\n",
      "Processed trajectory number :  310 out of  461  trajectories\n",
      "Processed trajectory number :  311 out of  461  trajectories\n",
      "Processed trajectory number :  312 out of  461  trajectories\n",
      "Processed trajectory number :  313 out of  461  trajectories\n",
      "Processed trajectory number :  314 out of  461  trajectories\n",
      "Processed trajectory number :  315 out of  461  trajectories\n",
      "Processed trajectory number :  316 out of  461  trajectories\n",
      "Processed trajectory number :  317 out of  461  trajectories\n",
      "Processed trajectory number :  318 out of  461  trajectories\n",
      "Processed trajectory number :  319 out of  461  trajectories\n",
      "Processed trajectory number :  320 out of  461  trajectories\n",
      "Processed trajectory number :  321 out of  461  trajectories\n",
      "Processed trajectory number :  322 out of  461  trajectories\n",
      "Processed trajectory number :  323 out of  461  trajectories\n",
      "Processed trajectory number :  324 out of  461  trajectories\n",
      "Processed trajectory number :  325 out of  461  trajectories\n",
      "Processed trajectory number :  326 out of  461  trajectories\n",
      "Processed trajectory number :  327 out of  461  trajectories\n",
      "Processed trajectory number :  328 out of  461  trajectories\n",
      "Processed trajectory number :  329 out of  461  trajectories\n",
      "Processed trajectory number :  330 out of  461  trajectories\n",
      "Processed trajectory number :  331 out of  461  trajectories\n",
      "Processed trajectory number :  332 out of  461  trajectories\n",
      "Processed trajectory number :  333 out of  461  trajectories\n",
      "Processed trajectory number :  334 out of  461  trajectories\n",
      "Processed trajectory number :  335 out of  461  trajectories\n",
      "Processed trajectory number :  336 out of  461  trajectories\n",
      "Processed trajectory number :  337 out of  461  trajectories\n",
      "Processed trajectory number :  338 out of  461  trajectories\n",
      "Processed trajectory number :  339 out of  461  trajectories\n",
      "Processed trajectory number :  340 out of  461  trajectories\n",
      "Processed trajectory number :  341 out of  461  trajectories\n",
      "Processed trajectory number :  342 out of  461  trajectories\n",
      "Processed trajectory number :  343 out of  461  trajectories\n",
      "Processed trajectory number :  344 out of  461  trajectories\n",
      "Processed trajectory number :  345 out of  461  trajectories\n",
      "Processed trajectory number :  346 out of  461  trajectories\n",
      "Processed trajectory number :  347 out of  461  trajectories\n",
      "Processed trajectory number :  348 out of  461  trajectories\n",
      "Processed trajectory number :  349 out of  461  trajectories\n",
      "Processed trajectory number :  350 out of  461  trajectories\n",
      "Processed trajectory number :  351 out of  461  trajectories\n",
      "Processed trajectory number :  352 out of  461  trajectories\n",
      "Processed trajectory number :  353 out of  461  trajectories\n",
      "Processed trajectory number :  354 out of  461  trajectories\n",
      "Processed trajectory number :  355 out of  461  trajectories\n",
      "Processed trajectory number :  356 out of  461  trajectories\n",
      "Processed trajectory number :  357 out of  461  trajectories\n",
      "Processed trajectory number :  358 out of  461  trajectories\n",
      "Processed trajectory number :  359 out of  461  trajectories\n",
      "Processed trajectory number :  360 out of  461  trajectories\n",
      "Processed trajectory number :  361 out of  461  trajectories\n",
      "Processed trajectory number :  362 out of  461  trajectories\n",
      "Processed trajectory number :  363 out of  461  trajectories\n",
      "Processed trajectory number :  364 out of  461  trajectories\n",
      "Processed trajectory number :  365 out of  461  trajectories\n",
      "Processed trajectory number :  366 out of  461  trajectories\n",
      "Processed trajectory number :  367 out of  461  trajectories\n",
      "Processed trajectory number :  368 out of  461  trajectories\n",
      "Processed trajectory number :  369 out of  461  trajectories\n",
      "Processed trajectory number :  370 out of  461  trajectories\n",
      "Processed trajectory number :  371 out of  461  trajectories\n",
      "Processed trajectory number :  372 out of  461  trajectories\n",
      "Processed trajectory number :  373 out of  461  trajectories\n",
      "Processed trajectory number :  374 out of  461  trajectories\n",
      "Processed trajectory number :  375 out of  461  trajectories\n",
      "Processed trajectory number :  376 out of  461  trajectories\n",
      "Processed trajectory number :  377 out of  461  trajectories\n",
      "Processed trajectory number :  378 out of  461  trajectories\n",
      "Processed trajectory number :  379 out of  461  trajectories\n",
      "Processed trajectory number :  380 out of  461  trajectories\n",
      "Processed trajectory number :  381 out of  461  trajectories\n",
      "Processed trajectory number :  382 out of  461  trajectories\n",
      "Processed trajectory number :  383 out of  461  trajectories\n",
      "Processed trajectory number :  384 out of  461  trajectories\n",
      "Processed trajectory number :  385 out of  461  trajectories\n",
      "Processed trajectory number :  386 out of  461  trajectories\n",
      "Processed trajectory number :  387 out of  461  trajectories\n",
      "Processed trajectory number :  388 out of  461  trajectories\n",
      "Processed trajectory number :  389 out of  461  trajectories\n",
      "Processed trajectory number :  390 out of  461  trajectories\n",
      "Processed trajectory number :  391 out of  461  trajectories\n",
      "Processed trajectory number :  392 out of  461  trajectories\n",
      "Processed trajectory number :  393 out of  461  trajectories\n",
      "Processed trajectory number :  394 out of  461  trajectories\n",
      "Processed trajectory number :  395 out of  461  trajectories\n",
      "Processed trajectory number :  396 out of  461  trajectories\n",
      "Processed trajectory number :  397 out of  461  trajectories\n",
      "Processed trajectory number :  398 out of  461  trajectories\n",
      "Processed trajectory number :  399 out of  461  trajectories\n",
      "Processed trajectory number :  400 out of  461  trajectories\n",
      "Processed trajectory number :  401 out of  461  trajectories\n",
      "Processed trajectory number :  402 out of  461  trajectories\n",
      "Processed trajectory number :  403 out of  461  trajectories\n",
      "Processed trajectory number :  404 out of  461  trajectories\n",
      "Processed trajectory number :  405 out of  461  trajectories\n",
      "Processed trajectory number :  406 out of  461  trajectories\n",
      "Processed trajectory number :  407 out of  461  trajectories\n",
      "Processed trajectory number :  408 out of  461  trajectories\n",
      "Processed trajectory number :  409 out of  461  trajectories\n",
      "Processed trajectory number :  410 out of  461  trajectories\n",
      "Processed trajectory number :  411 out of  461  trajectories\n",
      "Processed trajectory number :  412 out of  461  trajectories\n",
      "Processed trajectory number :  413 out of  461  trajectories\n",
      "Processed trajectory number :  414 out of  461  trajectories\n",
      "Processed trajectory number :  415 out of  461  trajectories\n",
      "Processed trajectory number :  416 out of  461  trajectories\n",
      "Processed trajectory number :  417 out of  461  trajectories\n",
      "Processed trajectory number :  418 out of  461  trajectories\n",
      "Processed trajectory number :  419 out of  461  trajectories\n",
      "Processed trajectory number :  420 out of  461  trajectories\n",
      "Processed trajectory number :  421 out of  461  trajectories\n",
      "Processed trajectory number :  422 out of  461  trajectories\n",
      "Processed trajectory number :  423 out of  461  trajectories\n",
      "Processed trajectory number :  424 out of  461  trajectories\n",
      "Processed trajectory number :  425 out of  461  trajectories\n",
      "Processed trajectory number :  426 out of  461  trajectories\n",
      "Processed trajectory number :  427 out of  461  trajectories\n",
      "Processed trajectory number :  428 out of  461  trajectories\n",
      "Processed trajectory number :  429 out of  461  trajectories\n",
      "Processed trajectory number :  430 out of  461  trajectories\n",
      "Processed trajectory number :  431 out of  461  trajectories\n",
      "Processed trajectory number :  432 out of  461  trajectories\n",
      "Processed trajectory number :  433 out of  461  trajectories\n",
      "Processed trajectory number :  434 out of  461  trajectories\n",
      "Processed trajectory number :  435 out of  461  trajectories\n",
      "Processed trajectory number :  436 out of  461  trajectories\n",
      "Processed trajectory number :  437 out of  461  trajectories\n",
      "Processed trajectory number :  438 out of  461  trajectories\n",
      "Processed trajectory number :  439 out of  461  trajectories\n",
      "Processed trajectory number :  440 out of  461  trajectories\n",
      "Processed trajectory number :  441 out of  461  trajectories\n",
      "Processed trajectory number :  442 out of  461  trajectories\n",
      "Processed trajectory number :  443 out of  461  trajectories\n",
      "Processed trajectory number :  444 out of  461  trajectories\n",
      "Processed trajectory number :  445 out of  461  trajectories\n",
      "Processed trajectory number :  446 out of  461  trajectories\n",
      "Processed trajectory number :  447 out of  461  trajectories\n",
      "Processed trajectory number :  448 out of  461  trajectories\n",
      "Processed trajectory number :  449 out of  461  trajectories\n",
      "Processed trajectory number :  450 out of  461  trajectories\n",
      "Processed trajectory number :  451 out of  461  trajectories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trajectory number :  452 out of  461  trajectories\n",
      "Processed trajectory number :  453 out of  461  trajectories\n",
      "Processed trajectory number :  454 out of  461  trajectories\n",
      "Processed trajectory number :  455 out of  461  trajectories\n",
      "Processed trajectory number :  456 out of  461  trajectories\n",
      "Processed trajectory number :  457 out of  461  trajectories\n",
      "Processed trajectory number :  458 out of  461  trajectories\n",
      "Processed trajectory number :  459 out of  461  trajectories\n",
      "Processed trajectory number :  460 out of  461  trajectories\n",
      "Processed trajectory number :  461 out of  461  trajectories\n",
      "Total mean error of the model is  0.09261851848153513\n"
     ]
    }
   ],
   "source": [
    "for b in range(num_batches):\n",
    "    start = time.time()\n",
    "    # Get the source and target data of the current batch\n",
    "    # x has the source data, y has the target data\n",
    "    x, y, pointer = data_tools.next_batch(data, pointer, BATCH_SIZE, SEQUENCE_LENGTH)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    for _ in range(1):\n",
    "        obs_traj = x[0,:OBSERVED_LENGTH, 1:]\n",
    "        for position in obs_traj[:-1]:\n",
    "            # Create the input data tensor\n",
    "            input_data_tensor = np.zeros((1, 1, 2), dtype=np.float32)\n",
    "            input_data_tensor[0, 0, 0] = position[0]  # x\n",
    "            input_data_tensor[0, 0, 1] = position[1]  # y\n",
    "\n",
    "            # Create the feed dict\n",
    "            feed = {lstm.input_data: input_data_tensor, lstm.initial_state: state}\n",
    "            # Get the final state after processing the current position\n",
    "            [state] = lstm.sess.run([lstm.final_state], feed)\n",
    "\n",
    "        returned_traj = obs_traj\n",
    "        last_position = obs_traj[-1]\n",
    "\n",
    "        prev_data = np.zeros((1, 1, 2), dtype=np.float32)\n",
    "        prev_data[0, 0, 0] = last_position[0]  # x\n",
    "        prev_data[0, 0, 1] = last_position[1]  # y\n",
    "\n",
    "        prev_target_data = np.reshape(x[0][obs_traj.shape[0], 1:], (1, 1, 2))\n",
    "        for t in range(PREDICTED_LENGTH):\n",
    "            feed = {lstm.input_data: prev_data, lstm.initial_state: state, lstm.target_data: prev_target_data}\n",
    "            [o_mux, o_muy, o_sx, o_sy, o_corr, state, cost] = lstm.sess.run(\n",
    "                [lstm.mux, lstm.muy, lstm.sx, lstm.sy, lstm.corr, lstm.final_state, lstm.cost], feed)\n",
    "\n",
    "            \n",
    "            next_x, next_y = distributions.sample_2d_normal(o_mux, o_muy, o_sx, o_sy, o_corr)\n",
    "            returned_traj = np.vstack((returned_traj, [next_x, next_y]))\n",
    "\n",
    "            prev_data[0, 0, 0] = next_x\n",
    "            prev_data[0, 0, 1] = next_y\n",
    "\n",
    "        complete_traj = returned_traj\n",
    "\n",
    "    total_error += distributions.get_mean_error(complete_traj, x[0, :, 1:], OBSERVED_LENGTH)\n",
    "    print(\"Processed trajectory number : \", b+1, \"out of \", num_batches, \" trajectories\")\n",
    "\n",
    "print(\"Total mean error of the model is \", total_error/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqname = \"seq_hotel\"\n",
    "videopath = os.path.join(\"../data/seq_hotel\", seqname+\".avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation.visual(x, complete_traj, statistics, x[0][0][0], videopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
