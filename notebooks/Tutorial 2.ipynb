{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Trajectory Prediction using LSTMs (cont'd)\n",
    "\n",
    "### Quick demo of using the Agents LSTM model\n",
    "\n",
    "This Notebook aims to show how we can utilise the implemented model in this repository.\n",
    "\n",
    "### Initialisation\n",
    "\n",
    "We begin by importing everything necessary including all datasets we will use for training, followed by assigning all constant variables we will need for training the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alice/miniconda/envs/traj/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.lstm import reset_graph\n",
    "import utils.data_tools as data_tools\n",
    "import utils.visualisation as visualisation\n",
    "import utils.distributions as distributions\n",
    "\n",
    "from models.agent_lstm import AgentLSTM\n",
    "from models.agent_lstm import reset_graph\n",
    "\n",
    "\n",
    "training_directories = ['../data/eth/univ',\n",
    "                 '../data/ucy/zara/zara01',\n",
    "                 '../data/ucy/zara/zara02']\n",
    "dataset_names = ['univ', 'zara01', 'zara02']\n",
    "\n",
    "DEFAULT_SEED = 12345\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 100\n",
    "DECAY_RATE = 0.95\n",
    "SEQUENCE_LENGTH = 8\n",
    "MAX_NUM_AGENTS = 40\n",
    "SAVE_PATH = \"../save\"\n",
    "RND = np.random.RandomState(DEFAULT_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preparing the data and model\n",
    "Before training, we need to preprocess and load our data. It is always good practice to reset the graph on Tensorflow in order to avoid interference with ran in parallel instances of the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "96\n",
      "116\n",
      "graph successfully reset\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x6412796d8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "Frame number 0\n",
      "Frame number 1\n",
      "Frame number 2\n",
      "Frame number 3\n",
      "Frame number 4\n",
      "Frame number 5\n",
      "Frame number 6\n",
      "Frame number 7\n"
     ]
    }
   ],
   "source": [
    "loaded_data, frames_list, dataset_indices = data_tools.preprocess_frames(training_directories)\n",
    "num_batches = data_tools.load_preprocessed_frames(loaded_data, BATCH_SIZE, SEQUENCE_LENGTH)\n",
    "\n",
    "reset_graph()\n",
    "lstm = AgentLSTM(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    max_num_agents=MAX_NUM_AGENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In order to train the network, we will begin by initialising a session, and then for as long as there are batches left, we will take a new one and run our model, at each such step the model updates its parameters. We repeat this process for a chosen in advance number of epochs.\n",
    "\n",
    "Although not necessary, we can dedect the time it takes us to process a single batch. We will print the average result over 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):\n",
    "    # Reset the pointers\n",
    "    pointer = data_tools.reset_batch_pointer()\n",
    "    dataset_pointer = data_tools.reset_data_set_pointer()\n",
    "\n",
    "    # Assign the learning rate (decayed acc. to the epoch number)\n",
    "    lstm.sess.run(tf.assign(lstm.lr, lstm.learning_rate * (DECAY_RATE ** e)))\n",
    "    # For each batch in this epoch\n",
    "    for b in range(num_batches):\n",
    "        start = time.time() # Tic\n",
    "        # Get the source and target data of the current batch\n",
    "        # x has the source data, y has the target data\n",
    "        x, y, d, f, pointer, dataset_pointer = data_tools.next_batch_frame(\n",
    "            loaded_data, frames_list, pointer, dataset_pointer, BATCH_SIZE, SEQUENCE_LENGTH, dataset_names, MAX_NUM_AGENTS, rnd=RND)\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        train_loss = 0\n",
    "        for batch in range(BATCH_SIZE):\n",
    "            x_batch, y_batch = x[batch], y[batch]\n",
    "\n",
    "            # Feed the source, target data and the initial LSTM state to the model\n",
    "            feed = {\n",
    "                lstm.input_data: x_batch,\n",
    "                lstm.target_data: y_batch\n",
    "            }\n",
    "            # Fetch the loss of the model on this batch,\n",
    "            # the final LSTM state from the session\n",
    "            cur_train_loss, _ = lstm.sess.run(\n",
    "                [lstm.cost, lstm.train_op], feed)\n",
    "            train_loss += cur_train_loss\n",
    "\n",
    "        end = time.time() # Toc\n",
    "        train_loss = train_loss / BATCH_SIZE\n",
    "\n",
    "        cur_time = end - start\n",
    "        step = e * num_batches + b\n",
    "\n",
    "        avg_time += cur_time\n",
    "        avg_loss += train_loss\n",
    "\n",
    "        # Print epoch, batch, loss and time taken\n",
    "        if (step%99) == 0:\n",
    "            print(\n",
    "                \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\n",
    "                .format(\n",
    "                    step,\n",
    "                    NUM_EPOCHS * num_batches,\n",
    "                    e,\n",
    "                    avg_loss/99.0, avg_time/99.0))\n",
    "            \n",
    "            avg_time = 0\n",
    "            avg_loss = 0\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "# Save parameters after the network is trained\n",
    "lstm.save_json(os.path.join(SAVE_PATH, \"params_agent.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "In order to test we are no longer interested in obtaining entire batches but we need to consider single entries.\n",
    "Moreover, we need to first observe part of the trajectory in order to make a prediction. Thus, we redefine some of the variables from above as follows.\n",
    "\n",
    "We then take the test dataset, preprocess it and load it in a relevant format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "OBSERVED_LENGTH = 4\n",
    "PREDICTED_LENGTH = 4\n",
    "SEQUENCE_LENGTH = OBSERVED_LENGTH + PREDICTED_LENGTH\n",
    "\n",
    "test_directory = [\"../data/eth/hotel\"]\n",
    "dataset_names = ['hotel']\n",
    "loaded_data, frames_list, dataset_indices = data_tools.preprocess_frames(test_directory)\n",
    "num_batches = data_tools.load_preprocessed_frames(loaded_data, BATCH_SIZE, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We define a model with a sequence length of 1 since we will be predicting for each step individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfully reset\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x10a6f2ba8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "Frame number 0\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "lstm = AgentLSTM(batch_size=1, sequence_length=1, mode='infer')\n",
    "lstm.load_json(os.path.join(SAVE_PATH, \"params_agent.json\"))\n",
    "\n",
    "pointer = data_tools.reset_batch_pointer()\n",
    "dataset_pointer = data_tools.reset_data_set_pointer()\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "total_error = 0\n",
    "initial_states = lstm.sess.run(lstm.LSTM_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "For a given trajectory, the idea is to simply update the cell state at each step using the final cell state value from our previous prediction.\n",
    "\n",
    "We then measure the performance of the network through the average displacement error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trajectory number :  10 out of  258  trajectories\n",
      "Processed trajectory number :  20 out of  258  trajectories\n",
      "Processed trajectory number :  30 out of  258  trajectories\n",
      "Processed trajectory number :  40 out of  258  trajectories\n",
      "Processed trajectory number :  50 out of  258  trajectories\n",
      "Processed trajectory number :  60 out of  258  trajectories\n",
      "Processed trajectory number :  70 out of  258  trajectories\n",
      "Processed trajectory number :  80 out of  258  trajectories\n",
      "Processed trajectory number :  90 out of  258  trajectories\n",
      "Processed trajectory number :  100 out of  258  trajectories\n",
      "Processed trajectory number :  110 out of  258  trajectories\n",
      "Processed trajectory number :  120 out of  258  trajectories\n",
      "Processed trajectory number :  130 out of  258  trajectories\n",
      "Processed trajectory number :  140 out of  258  trajectories\n",
      "Processed trajectory number :  150 out of  258  trajectories\n",
      "Processed trajectory number :  160 out of  258  trajectories\n",
      "Processed trajectory number :  170 out of  258  trajectories\n",
      "Processed trajectory number :  180 out of  258  trajectories\n",
      "Processed trajectory number :  190 out of  258  trajectories\n",
      "Processed trajectory number :  200 out of  258  trajectories\n",
      "Processed trajectory number :  210 out of  258  trajectories\n",
      "Processed trajectory number :  220 out of  258  trajectories\n",
      "Processed trajectory number :  230 out of  258  trajectories\n",
      "Processed trajectory number :  240 out of  258  trajectories\n",
      "Processed trajectory number :  250 out of  258  trajectories\n",
      "Processed trajectory number :  258 out of  258  trajectories\n",
      "Total mean error of the model is  0.02060686562214788\n"
     ]
    }
   ],
   "source": [
    "for b in range(num_batches):\n",
    "    x, y, d, f, pointer, dataset_pointer = data_tools.next_batch_frame(\n",
    "            loaded_data, frames_list, pointer, dataset_pointer, BATCH_SIZE, SEQUENCE_LENGTH, dataset_names, MAX_NUM_AGENTS, random_update=False, rnd=RND)\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    obs_traj = x[0,:OBSERVED_LENGTH]\n",
    "    states = initial_states\n",
    "    for idx, position in enumerate(obs_traj[:-1]):\n",
    "        # Create the input data tensor\n",
    "        input_data_tensor = np.reshape(position, (1, MAX_NUM_AGENTS, 3))\n",
    "        target_data_tensor = np.reshape(obs_traj[idx+1], (1, MAX_NUM_AGENTS, 3))\n",
    "        # Create the feed dict\n",
    "        feed = {lstm.input_data: input_data_tensor, lstm.target_data: target_data_tensor, lstm.LSTM_states: states}\n",
    "        # Get the final state after processing the current position\n",
    "        [states, cost] = lstm.sess.run([lstm.final_states, lstm.cost], feed)\n",
    "\n",
    "    returned_traj = obs_traj\n",
    "    last_position = obs_traj[-1]\n",
    "\n",
    "    prev_data = np.reshape(last_position, (1, MAX_NUM_AGENTS, 3))\n",
    "    prev_target_data = np.reshape(x[0][obs_traj.shape[0]], (1, MAX_NUM_AGENTS, 3))\n",
    "    for t in range(PREDICTED_LENGTH):\n",
    "        feed = {\n",
    "            lstm.input_data: prev_data,\n",
    "            lstm.LSTM_states: states,\n",
    "            lstm.target_data: prev_target_data}\n",
    "\n",
    "        [output, states] = lstm.sess.run(\n",
    "            [lstm.final_output, lstm.final_states], feed)\n",
    "        newpos = np.zeros((1, MAX_NUM_AGENTS, 3))\n",
    "        for a_index, a_output in enumerate(output):\n",
    "            [o_mux, o_muy, o_sx, o_sy, o_corr] = np.split(a_output[0], 5, 0)\n",
    "            mux, muy, sx, sy, corr = [o_mux], [o_muy], [np.exp(o_sx)], [np.exp(o_sy)], [np.tanh(o_corr)]\n",
    "            next_x, next_y = distributions.sample_2d_normal(mux, muy, sx, sy, corr)\n",
    "            newpos[0, a_index, :] = [prev_data[0, a_index, 0], next_x, next_y]\n",
    "                \n",
    "        returned_traj = np.vstack((returned_traj, newpos))\n",
    "        prev_data = newpos\n",
    "        if t != PREDICTED_LENGTH - 1:\n",
    "            prev_target_data = np.reshape(x[0][obs_traj.shape[0] + t + 1], (1, MAX_NUM_AGENTS, 3))\n",
    "\n",
    "    complete_traj = returned_traj\n",
    "\n",
    "    total_error += distributions.get_mean_error_perframe(complete_traj, x[0], OBSERVED_LENGTH, MAX_NUM_AGENTS)\n",
    "    if (b+1) % 10 == 0:\n",
    "        print(\"Processed trajectory number : \", b+1, \"out of \", num_batches, \" trajectories\")\n",
    "\n",
    "print(\"Processed trajectory number : \", b+1, \"out of \", num_batches, \" trajectories\")\n",
    "print(\"Total mean error of the model is \", total_error/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
